{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME.bak","path":"CNAME.bak","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/muse.js","path":"js/src/schemes/muse.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1}],"Cache":[{"_id":"themes/next/.all-contributorsrc","hash":"e32dc4075e304af04b98d0726d489081bea722c0","modified":1548959308971},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1548959308971},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1548959308971},{"_id":"themes/next/.eslintrc.json","hash":"cc5f297f0322672fe3f684f823bc4659e4a54c41","modified":1548959308971},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1548959308971},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1548959308971},{"_id":"themes/next/_config.yml","hash":"bfc318002bf17bc3702be32e43d91bf34d04a640","modified":1548959308971},{"_id":"themes/next/.travis.yml","hash":"3d1dc928c4a97933e64379cfde749dedf62f252c","modified":1548959308971},{"_id":"themes/next/LICENSE.md","hash":"18144d8ed58c75af66cb419d54f3f63374cd5c5b","modified":1548959308971},{"_id":"themes/next/gulpfile.coffee","hash":"48d2f9fa88a4210308fc41cc7d3f6d53989f71b7","modified":1548959308971},{"_id":"themes/next/package.json","hash":"c791b45d1e6fde11a1e1e11ba5a6ced1f5ba0fce","modified":1548959308971},{"_id":"themes/next/README.md","hash":"b4f780a96b0e5d3737eb93bc00da6de91f042c4b","modified":1548959308971},{"_id":"themes/next/bower.json","hash":"09628558259cf990fac43ed1f5ef9edae73f124b","modified":1548959308971},{"_id":"themes/next/crowdin.yml","hash":"e026078448c77dcdd9ef50256bb6635a8f83dca6","modified":1548959308971},{"_id":"source/CNAME.bak","hash":"129860cef99c0898751d415efbaea935b420fc31","modified":1548958388996},{"_id":"themes/next/scripts/merge-configs.js","hash":"33afe97284d34542015d358a720823feeebef120","modified":1548959308979},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1548959308979},{"_id":"themes/next/docs/ALGOLIA-SEARCH.md","hash":"141e989844d0b5ae2e09fb162a280715afb39b0d","modified":1548959308975},{"_id":"themes/next/docs/AUTHORS.md","hash":"7b24be2891167bdedb9284a682c2344ec63e50b5","modified":1548959308975},{"_id":"themes/next/docs/INSTALLATION.md","hash":"2bbdd6c1751b2b42ce9b9335da420c6026a483e9","modified":1548959308975},{"_id":"themes/next/docs/AGPL3.md","hash":"0d2b8c5fa8a614723be0767cc3bca39c49578036","modified":1548959308975},{"_id":"themes/next/docs/LEANCLOUD-COUNTER-SECURITY.md","hash":"212a36d57495990b5f56e46ca8dce1d76c199660","modified":1548959308975},{"_id":"themes/next/docs/DATA-FILES.md","hash":"8e1962dd3e1b700169b3ae5bba43992f100651ce","modified":1548959308975},{"_id":"themes/next/docs/LICENSE.txt","hash":"368bf2c29d70f27d8726dd914f1b3211cae4bbab","modified":1548959308975},{"_id":"themes/next/languages/de.yml","hash":"fb478c5040a4e58a4c1ad5fb52a91e5983d65a3a","modified":1548959308975},{"_id":"themes/next/languages/default.yml","hash":"c540c3a0d7db2d4239293c8783881962640b6c34","modified":1548959308975},{"_id":"themes/next/languages/en.yml","hash":"c540c3a0d7db2d4239293c8783881962640b6c34","modified":1548959308975},{"_id":"themes/next/languages/fr.yml","hash":"0162a85ae4175e66882a9ead1249fedb89200467","modified":1548959308975},{"_id":"themes/next/languages/id.yml","hash":"e7fb582e117a0785036dcdbb853a6551263d6aa6","modified":1548959308975},{"_id":"themes/next/docs/MATH.md","hash":"e6023505dcccaef0b856102543585a13fc6af0b1","modified":1548959308975},{"_id":"themes/next/docs/UPDATE-FROM-5.1.X.md","hash":"ad57c168d12ba01cf144a1ea0627b2ffd1847d3e","modified":1548959308975},{"_id":"themes/next/languages/it.yml","hash":"62ef41d0a9a3816939cb4d93a524e6930ab9c517","modified":1548959308975},{"_id":"themes/next/languages/ja.yml","hash":"e331b15b1fda0f2285d25853f834682ab8dc3c39","modified":1548959308975},{"_id":"themes/next/languages/ko.yml","hash":"fae155018ae0efdf68669b2c7dd3f959c2e45cc9","modified":1548959308975},{"_id":"themes/next/languages/nl.yml","hash":"bb9ce8adfa5ee94bc6b5fac6ad24ba4605d180d3","modified":1548959308975},{"_id":"themes/next/languages/pt-BR.yml","hash":"bfc80c8a363fa2e8dde38ea2bc85cd19e15ab653","modified":1548959308975},{"_id":"themes/next/languages/ru.yml","hash":"db0644e738d2306ac38567aa183ca3e859a3980f","modified":1548959308975},{"_id":"themes/next/languages/pt.yml","hash":"3cb51937d13ff12fcce747f972ccb664840a9ef3","modified":1548959308975},{"_id":"themes/next/languages/tr.yml","hash":"c5f0c20743b1dd52ccb256050b1397d023e6bcd9","modified":1548959308975},{"_id":"themes/next/languages/uk.yml","hash":"1eb59e581568da9a81d6e20541b4ada5fc1c55c0","modified":1548959308975},{"_id":"themes/next/languages/zh-CN.yml","hash":"fbbf3a0b664ae8e927c700b0a813692b94345156","modified":1548959308975},{"_id":"themes/next/languages/vi.yml","hash":"8da921dd8335dd676efce31bf75fdd4af7ce6448","modified":1548959308975},{"_id":"themes/next/languages/zh-TW.yml","hash":"6e6d2cd8f4244cb1b349b94904cb4770935acefd","modified":1548959308975},{"_id":"themes/next/languages/zh-HK.yml","hash":"7903b96912c605e630fb695534012501b2fad805","modified":1548959308975},{"_id":"themes/next/layout/category.swig","hash":"5d955284a42f802a48560b4452c80906a5d1da02","modified":1548959308975},{"_id":"themes/next/layout/archive.swig","hash":"2b6450c6b6d2bcbcd123ad9f59922a5e323d77a5","modified":1548959308975},{"_id":"themes/next/layout/index.swig","hash":"c2a3896c64e96790edc10426ef586b6186a87f46","modified":1548959308975},{"_id":"themes/next/layout/page.swig","hash":"2d0e80e8a4dcba665704882b9dc5858c187acc31","modified":1548959308975},{"_id":"themes/next/layout/post.swig","hash":"f74929fd792541916eb25c2addfb35431be071ba","modified":1548959308975},{"_id":"themes/next/layout/schedule.swig","hash":"3268dd3d90d8b0e142cfa1a2ebb23355baeda148","modified":1548959308975},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1548959308975},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1548959308975},{"_id":"themes/next/layout/_layout.swig","hash":"665a6874ec7f7f49f743165cc50da67380d67711","modified":1548959308975},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1548959308975},{"_id":"source/categories/index.md","hash":"a7060385493c0ef7292a902b6d1e84466090c73f","modified":1548958388996},{"_id":"themes/next/layout/tag.swig","hash":"ba402ce8fd55e80b240e019e8d8c48949b194373","modified":1548959308975},{"_id":"source/tags/index.md","hash":"d431ee6b73ece40f1a1328d2a9f9dafbe395b2ce","modified":1548958388996},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308975},{"_id":"themes/next/scripts/helpers/engine.js","hash":"60eb1554456d9d0e5afc4a2d16f1580a0aa02da8","modified":1548959308979},{"_id":"themes/next/scripts/helpers/next-url.js","hash":"15582e823d228c0b2288543c1eb460c40afad29b","modified":1548959308979},{"_id":"themes/next/scripts/tags/button.js","hash":"08d5dfe05335f57d3e8392a74315766dafa52538","modified":1548959308979},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"f13430d9d1c9773b390787c2f046bb1f12a79878","modified":1548959308979},{"_id":"themes/next/scripts/tags/exturl.js","hash":"7ded3e7a78380b32de3e12f156e0978ef5c2890a","modified":1548959308979},{"_id":"themes/next/scripts/tags/full-image.js","hash":"22de989163c4678278c8a112160be6977f570234","modified":1548959308979},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"4775fffa526f1f7b40aa1f1c0a171dbcf5963df7","modified":1548959308979},{"_id":"themes/next/scripts/tags/include-raw.js","hash":"5db59d56f4f4082382bf1c16722e6c383892b0c5","modified":1548959308979},{"_id":"themes/next/scripts/tags/label.js","hash":"76735c88cfba2e53649387a7fa5176706c2d3c0c","modified":1548959308979},{"_id":"themes/next/scripts/tags/note.js","hash":"84ce2d2c0646baafc82083e261b093b1c515f63c","modified":1548959308979},{"_id":"themes/next/scripts/tags/tabs.js","hash":"8b1e9043db8f19ea4a12c473b3f729bd3b5bcb0e","modified":1548959308979},{"_id":"themes/next/docs/ru/DATA-FILES.md","hash":"d6d20f60f77a76c77f8e65d0c9adbd79d0274557","modified":1548959308975},{"_id":"themes/next/docs/ru/INSTALLATION.md","hash":"6c5d69e94961c793da156217ecf1179e868d7ba1","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/CODE_OF_CONDUCT.md","hash":"a45a791b49954331390d548ac34169d573ea5922","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/DATA-FILES.md","hash":"f3eec572a7d83542e2710a7404082014aaa1a5e7","modified":1548959308975},{"_id":"themes/next/docs/ru/UPDATE-FROM-5.1.X.md","hash":"b1dd18d9b890b21718883ea1832e7e02a773104a","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/CONTRIBUTING.md","hash":"bd2c955d9b7b1b45bd74a4536717d547e03fcde3","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/ALGOLIA-SEARCH.md","hash":"6855402e2ef59aae307e8bd2a990647d3a605eb8","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/INSTALLATION.md","hash":"b19a6e0ae96eb7c756fb5b1ba03934c7f9cbb3c3","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/LEANCLOUD-COUNTER-SECURITY.md","hash":"115ffbde2b3ce01ef1f8c2b3833e6f6794650132","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/MATH.md","hash":"b76ccbc658024e86639cfa5f8a3817647fc8d651","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/README.md","hash":"15e55eb77616500fa4c64982d6bad9ac17a46e2a","modified":1548959308975},{"_id":"themes/next/docs/zh-CN/UPDATE-FROM-5.1.X.md","hash":"5da70d7fa0c988a66a469b9795d33d471a4a4433","modified":1548959308975},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548959308975},{"_id":"themes/next/layout/_custom/head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1548959308975},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548959308975},{"_id":"themes/next/layout/_macro/post.swig","hash":"fd99aeb8b84625772d85d9ed8e5bd1221c3e201b","modified":1548959308975},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"89b0a0e64637bf5b0cfea0a23642df3d95eedfa4","modified":1548959308975},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"a1ded7ba92354ed55ae20a0b6bcc15bbb4b801c2","modified":1548959308975},{"_id":"themes/next/layout/_partials/comments.swig","hash":"07340f3a4c8d8a9dd491d1eba18d985ecc0855a2","modified":1548959308975},{"_id":"themes/next/layout/_partials/github-banner.swig","hash":"a6ed0b4d6140bdfc5ea4995bb13d969cce50e74a","modified":1548959308975},{"_id":"themes/next/layout/_partials/footer.swig","hash":"07f88421bda86d9d5ff32d130b1cb1196b99a326","modified":1548959308975},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"dbe321bcf3cf45917cc11a3e3f50d8572bac2c70","modified":1548959308975},{"_id":"themes/next/layout/_partials/post-edit.swig","hash":"06dac109504812b63766a80ede9ddacbd42d227d","modified":1548959308975},{"_id":"themes/next/source/css/main.styl","hash":"e010ec8ac73268a0f137204c89e0080ab8d59b3d","modified":1548959308971},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1548959308975},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1548959308975},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1548959308975},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1548959308975},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1548959308975},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1548959308975},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1548959308975},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1548959308975},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1548959308975},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1548959308975},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1548959308975},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1548959308975},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548959308975},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1548959308975},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548959308975},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1548959308975},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1548959308975},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1548959308975},{"_id":"source/_posts/deep-learning/back_propagation.md","hash":"b2366b27e5e2d91d45d59b714444cc529f33b290","modified":1562081745025},{"_id":"source/_posts/deep-learning/nn_cs231n_note.md","hash":"ae9cb9059cf5febe896343e872f57311b42c544c","modified":1562172318221},{"_id":"source/_posts/deep-learning/optimization.md","hash":"80e99788238f832add0024b95784440e639b9135","modified":1562002335314},{"_id":"source/_posts/deep-learning/rnn.md","hash":"41e38191b3d90406c5ccb692abfd67152cdb9faa","modified":1562081260341},{"_id":"themes/next/docs/ru/README.md","hash":"953deb732e0b3b22c423122a189d6847d908c4b8","modified":1548959308975},{"_id":"source/_posts/deep-learning/cnn.md","hash":"da18adcf0949303ef348173e3b795d869a6d606b","modified":1562174514604},{"_id":"source/_posts/coding/exit_after_timeout.ipynb","hash":"ba008800e71371909c1230b007b65fe1edb2336c","modified":1556549039477},{"_id":"source/_posts/machine-learning/decision-tree.md","hash":"c46aef278590e7b1fd348aa6664476dc18c0a573","modified":1561046877003},{"_id":"source/_posts/statitics/estimate.md","hash":"e40c3403e911fc0a8d9c5f3210a1f72985e19702","modified":1556549039501},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"d01881f8056203c4b6920328db8c2ae8fa662a08","modified":1548959308975},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"d66bc7ec3cc03f60fcc7d555368a5b9b010f7f11","modified":1548959308975},{"_id":"themes/next/layout/_scripts/noscript.swig","hash":"edaff4766e0c05fd5c889d9dd32884d376bef9d9","modified":1548959308975},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"c4c58ea2bd4cf10372a5e46dbec1b9a2e0e69f0f","modified":1548959308975},{"_id":"source/_posts/statitics/entropy.md","hash":"7cb2381420bafe6497ef8c4b0c78c8cc5d4e5da1","modified":1563593368664},{"_id":"themes/next/layout/_third-party/bookmark.swig","hash":"10b61a8bac671e375916a4d234c120117098a78f","modified":1548959308975},{"_id":"themes/next/layout/_third-party/copy-code.swig","hash":"4148001b0b3f8a29b13ba5cd3f6f636c9cb260b0","modified":1548959308975},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"d359e638a86bd9664101c48e9344f21ec96e6a15","modified":1548959308975},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"2c4a66be4677d3e4dec3f169ac8a769098dad1fe","modified":1548959308975},{"_id":"themes/next/layout/_third-party/pangu.swig","hash":"c28f9dc96ab735daeb7f599f86470aa5a83c03cf","modified":1548959308975},{"_id":"themes/next/layout/_third-party/pdf.swig","hash":"5453d76e00bfcd1d732fc5f41828a90eb681f645","modified":1548959308975},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"cbe40cb67dad15ade967b0f396c1a95b6871f76a","modified":1548959308975},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"272c46f03766ea0c169163342bb98f09f561cf4c","modified":1548959308975},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1b250c1b7945cb1029b9e855edb09854f7c8250a","modified":1548959308975},{"_id":"source/_posts/deep-learning/dropout.md","hash":"ef09083c3be9a2c56055b1fdac57715f29f26538","modified":1562082681109},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308971},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308971},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308971},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308975},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548959308975},{"_id":"themes/next/scripts/filters/after_post_render/exturl.js","hash":"1c30b09d1855f1720f71f5956e0c9ca4d57b1231","modified":1548959308979},{"_id":"source/_posts/deep-learning/batch_normalization.md","hash":"131a957c43d691a2b47517e10fc8a8c5241cb06a","modified":1562087678478},{"_id":"source/_posts/statitics/Statistics.md","hash":"900f7942c1b15201e3b0dfdf93a3647856d464c7","modified":1556549039497},{"_id":"source/_posts/coding/重构.md","hash":"644a29abc642e7ec6575725debe083379d56af3f","modified":1562081260333},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"fc6bafc8c633afadc538c5afa5620ea2a1cdcb84","modified":1548959308975},{"_id":"themes/next/layout/_partials/head/head-unique.swig","hash":"dc53a41196b675268bfd2a944f6258c57ed44e91","modified":1548959308975},{"_id":"themes/next/layout/_partials/head/head.swig","hash":"6a825ce9412339ec4a128d9714804994cb85522c","modified":1548959308975},{"_id":"themes/next/layout/_partials/header/brand.swig","hash":"58e2e153e8b67e643b24453a1e1cceaae3323647","modified":1548959308975},{"_id":"themes/next/layout/_partials/header/index.swig","hash":"2082f5077551123e695e8afec471c9c44b436acb","modified":1548959308975},{"_id":"themes/next/layout/_partials/header/menu.swig","hash":"fe0614f1c15cf4c6f4bb72afe4a65e10824c9cb0","modified":1548959308975},{"_id":"themes/next/layout/_partials/header/sub-menu.swig","hash":"5adc60100e129c1d0307bdcaa0c7b8e8375a6ea4","modified":1548959308975},{"_id":"themes/next/layout/_partials/page/breadcrumb.swig","hash":"69722be16ce5eae5c027168f9b2fded4776e1b53","modified":1548959308975},{"_id":"themes/next/layout/_partials/page/page-header.swig","hash":"2940df694fff28e8bf71b6546b4162f1e38227db","modified":1548959308975},{"_id":"themes/next/layout/_partials/post/post-copyright.swig","hash":"2f73cc9ffb63534f0b6d8f0e9ee853c1af1b1244","modified":1548959308975},{"_id":"themes/next/layout/_partials/post/post-related.swig","hash":"eea95b785c9c36d28e1839619793f66e89773bee","modified":1548959308975},{"_id":"themes/next/layout/_partials/post/reward.swig","hash":"64d65d9ad0cc94734ac6ded279e2b5dc870a1cab","modified":1548959308975},{"_id":"themes/next/layout/_partials/post/wechat-subscriber.swig","hash":"d63208ee20529450c35de8fe80ef41fffa831dc9","modified":1548959308975},{"_id":"themes/next/layout/_partials/search/index.swig","hash":"a33b29ccbdc2248aedff23b04e0627f435824406","modified":1548959308975},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1548959308975},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a5587bd1f60d35e58618576cec45e662aa44ea1f","modified":1548959308975},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1548959308975},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"6f181cc188ecbe5e607fd989756e470d4cb9765d","modified":1548959308975},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1548959308975},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d5bfb363a1154e6505f0cccbd811fa71db133e3d","modified":1548959308975},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1548959308971},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1548959308971},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"2640a54fa63bdd4c547eab7ce2fc1192cf0ccec8","modified":1548959308971},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"086f5979b3de091c3378512e6c5c2f8fcb4f6298","modified":1548959308971},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"a8aa41625b94cf17a7f473ed10dcbe683b1db705","modified":1548959308975},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1548959308975},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"fc15e277d1504532a09b7b1bd31f900ad95ec4b8","modified":1548959308975},{"_id":"themes/next/source/js/src/affix.js","hash":"a2aab233d99297435a5274bf512c3c753fe08e80","modified":1548959308975},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"1f7f10c579e7703d0f6acb8b73f3d78a07d0c623","modified":1548959308975},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"1c41508b83cb0c4512e64b4d63afa1be954ce8ef","modified":1548959308975},{"_id":"themes/next/source/js/src/exturl.js","hash":"54825acc8de4793feac415be227b965428f4e97d","modified":1548959308975},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1548959308975},{"_id":"themes/next/source/js/src/motion.js","hash":"7933a30382a84b655238f6e78d42ea1b99af4de6","modified":1548959308975},{"_id":"themes/next/source/js/src/post-details.js","hash":"0dde5e6d4547587662a3256317a9d5d1db507692","modified":1548959308975},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"d07b3776708d4ae79ed2037c4c7391d5c9b06b19","modified":1548959308975},{"_id":"themes/next/source/js/src/utils.js","hash":"f1394d64977439ec569d2777b1ac304905e043f1","modified":1548959308975},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fa3c92968bcdbcb8d95a1729f7659d9753cbd077","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1548959308975},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d0e97b205d3320421c380f2eee445457430c8152","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1548959308975},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1548959308975},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1548959308975},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1548959308975},{"_id":"source/_posts/deep-learning/cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg","hash":"670eb624205aa4e9604544112bfae4c554780609","modified":1562003617579},{"_id":"source/_posts/deep-learning/cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg","hash":"0e747e52bf200d5069c7700649463949e3bd63e8","modified":1562004365155},{"_id":"source/_posts/deep-learning/images/42741-dd3d241fa44a71c0.webp","hash":"6403c810115edec0871e9bc313c5c8d27b45bc71","modified":1562081260341},{"_id":"source/_posts/deep-learning/nn_cs231n_note/03b3eccf18ee3760e219f9f95ec14305_hd.png","hash":"4c7877376cffdcf713f0aa74b34f7a42eee192b5","modified":1561197197016},{"_id":"source/_posts/deep-learning/cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg","hash":"85bb9df83f542b7c9ee8424009d6184858a27c9e","modified":1562174271977},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560776449074.png","hash":"7e91eee97de8151660f88d4058a8abefdef48781","modified":1561046876891},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560776135809.png","hash":"04f41de9ecec7e34742f0d6b9a1e370184a24b71","modified":1561046876887},{"_id":"themes/next/layout/_macro/menu/menu-item.swig","hash":"fb33f499022cd02722f834fcef1a0e193362cfde","modified":1548959308975},{"_id":"themes/next/layout/_macro/menu/menu-badge.swig","hash":"65c5e585982dae7ae1542cada71858b4ea1f73d6","modified":1548959308975},{"_id":"source/_posts/deep-learning/nn_cs231n_note/677187e96671a4cac9c95352743b3806_hd.png","hash":"eb528d932f29d13438dba6b842f938931d513ed7","modified":1561046876939},{"_id":"source/_posts/deep-learning/nn_cs231n_note/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","hash":"8c41052570b879d257cd14cfb51a7db1bea1e019","modified":1561050312114},{"_id":"source/_posts/deep-learning/optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png","hash":"4c7877376cffdcf713f0aa74b34f7a42eee192b5","modified":1561197233715},{"_id":"source/_posts/deep-learning/optimization/1561196522519.png","hash":"c1408ffe730f716cf42f103314af8324a98855da","modified":1561196522545},{"_id":"source/_posts/deep-learning/optimization/equation.svg","hash":"bea54f59fb418fc3395f123b5002b2636be8b27a","modified":1561274336001},{"_id":"source/_posts/deep-learning/optimization/nesterov_update_vector.png","hash":"cf8d982d21e86fecc983d8d1773e8c9ad4e86315","modified":1561196576700},{"_id":"source/_posts/deep-learning/optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg","hash":"9f3677bd92ea36de4faec35b74ad57d85899397a","modified":1561196989903},{"_id":"source/_posts/deep-learning/optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","hash":"8c41052570b879d257cd14cfb51a7db1bea1e019","modified":1561197233715},{"_id":"source/_posts/machine-learning/decision-tree/1548940093157.png","hash":"1545a8cdd264da9e41929b5b22c98fabb40b14ba","modified":1561046877003},{"_id":"source/_posts/machine-learning/decision-tree/1548940125578.png","hash":"dc050e44987e396207cdc6b32c689b134207f97c","modified":1561046876999},{"_id":"source/_posts/machine-learning/decision-tree/1548940132559.png","hash":"dc050e44987e396207cdc6b32c689b134207f97c","modified":1561046876999},{"_id":"source/_posts/machine-learning/decision-tree/feature-space.png","hash":"1341d484f40cb56ae4c2295bfe49fb3843db815e","modified":1561046876999},{"_id":"source/_posts/machine-learning/decision-tree/tree_basic.png","hash":"63a086ff52e9fc6b2d59470db972e23737e30369","modified":1561046876999},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"c7f2855f19dfdf18aba8c58d55b7489e631ed035","modified":1548959308975},{"_id":"source/_posts/deep-learning/rnn/2256672-3b20294694c3904b.png","hash":"d2420eebcf356a15cc96b31eddbcff03a4bc599b","modified":1562081260341},{"_id":"source/_posts/deep-learning/rnn/1562068950392.png","hash":"3913c5b01fa10569212c0f4e9458ccc6ae7dd245","modified":1562081260341},{"_id":"source/_posts/deep-learning/rnn/v2-3884f344d71e92d70ec3c44d2795141f_hd.jpg","hash":"ec7dc4b9f3afdc1a164ff7f7703b234cb098a625","modified":1562081260341},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"ffc8e8836714ea79abeb77b75859634615652877","modified":1548959308975},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"108b157fbd1ac3baaf19ae87234fa8728ab79556","modified":1548959308975},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"be24f204a515d5211bf3ba98a030e3bf61d4cc16","modified":1548959308975},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"94e106755c5fb6f40431b621beeba0bd33877e57","modified":1548959308975},{"_id":"source/_posts/deep-learning/rnn/v2-b0175ebd3419f9a11a3d0d8b00e28675_hd.jpg","hash":"c2fdaab09eca14882154825e2e890ddb335717bf","modified":1562081260345},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"a5723950c343d220270bfd27bd30050eda6c3fb3","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"798d67e4a736613ab899eabe6529091bbcda7850","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"8eadb929c9e50e58502ccad2dc2657746f8c592a","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"08cd47ef8572121b7811342d3c9a84a338a18191","modified":1548959308975},{"_id":"source/_posts/deep-learning/rnn/v2-71652d6a1eee9def631c18ea5e3c7605_hd.jpg","hash":"a37e04b13f4077b6bb2ae796043045000d15c451","modified":1562081260345},{"_id":"source/_posts/statitics/entropy/1562775971102.png","hash":"b0b7e3c0dfe7e526eeb586ff4fe05c6d888940cb","modified":1562775971126},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"591b2ccd9713ccb922b9fcf5e278b6de9c5ec30b","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"050ea01f25cfe492be9bb77b409644d623fdf2dc","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"fae69a0e1a1d42f7bb44e594a29857d94594698b","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/growingio.swig","hash":"9e576f12a294b14bd262f59c309a50cbf7003827","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"438c6f5e6665d72f4ea7ee206011d669246f6102","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"866012e74109383c98b31e6062bc735068ac6014","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"5ced33d88f0e7c7546b8da7ff096c59bb0207cdf","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"f240a50cd9b627620d9a374a29cf95f0c5e99d7c","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"cbf620cf2a78e3ac736cdd7e768513cfd6946e83","modified":1548959308975},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"92e04a2b9e0c3df594bc22235d1894e5ad458dfc","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"3533167c4295637b91d90f3bae7c651cd128bb6e","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"3cfeafefc672d9a7704650ebfb2f9d8668b38d9a","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"5856d5f701e51dfae1fd6fb486cefde67effd555","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"a4ab8095bf60def5823bf6b7b91a92a356a4c098","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"210f0c152bc4a9375ed364398ce309f09ebafd10","modified":1548959308975},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"dbe94dd94678ee8e4002b06bb1e9ead2e59e44bf","modified":1548959308975},{"_id":"themes/next/layout/_third-party/math/index.swig","hash":"a7e304b05a44279d3e4f611908d7faef9dc14d7c","modified":1548959308975},{"_id":"themes/next/layout/_third-party/math/katex.swig","hash":"c2cb2f384bc30d31cdccf9794a729c03e687b45c","modified":1548959308975},{"_id":"themes/next/layout/_third-party/math/mathjax.swig","hash":"c76c7ac9b97e74908467701b10e25707ba5c979e","modified":1548959308975},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1548959308975},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"b3eaab6a269aa3fcbafe24fd06f0c9206dc12716","modified":1548959308975},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"323ccd05bf8befb7d33de443cf3ac6a4195c3554","modified":1548959308979},{"_id":"themes/next/layout/_third-party/comments/gitalk.swig","hash":"197207078ff0f4d46417b4413493e02cda0b85f4","modified":1548959308975},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1548959308975},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1548959308975},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561035128653.png","hash":"328a3b273ef07eaedbc9935f58249c83e66e1166","modified":1561046876895},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560779540116.png","hash":"e75abb556987946287bf853feafe5f554aef81c4","modified":1561046876895},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561035151992.png","hash":"1c858d3bfb96425bdff15c7a695ff8a49642315f","modified":1561046876895},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561037588255.png","hash":"ec3756f7612db97741cbdd1162ea22c0a5418008","modified":1561046876899},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561186124221.png","hash":"423870c8ea51cd86797875e27d139a6e33bbb7cd","modified":1561186124256},{"_id":"source/_posts/deep-learning/nn_cs231n_note/42.png","hash":"676fc46d06ed87d6597f2dc71eed1d084824ed9e","modified":1561046876935},{"_id":"source/_posts/deep-learning/nn_cs231n_note/aae11de6e6a29f50d46b9ea106fbb02a_hd.png","hash":"b5dcff7a36e9d96bb915e0bcefa9efe4a1785315","modified":1561046876943},{"_id":"source/_posts/deep-learning/nn_cs231n_note/d0cbce2f2654b8e70fe201fec2982c7d_hd.png","hash":"3d8190e901a235e3ae38f72dce30604e1e740fa8","modified":1561046876955},{"_id":"source/_posts/deep-learning/nn_cs231n_note/e743b6777775b1671c3b5503d7afbbc4_hd.png","hash":"1aae3b4cde09f9710d2e31aebc20a249b7e9180c","modified":1561046876963},{"_id":"source/_posts/deep-learning/batch_normalization/1560779540116.png","hash":"e75abb556987946287bf853feafe5f554aef81c4","modified":1561182231779},{"_id":"source/_posts/deep-learning/optimization/1561035128653.png","hash":"328a3b273ef07eaedbc9935f58249c83e66e1166","modified":1561197233715},{"_id":"source/_posts/deep-learning/optimization/1561186124221.png","hash":"423870c8ea51cd86797875e27d139a6e33bbb7cd","modified":1561191553875},{"_id":"source/_posts/deep-learning/optimization/1561035151992.png","hash":"1c858d3bfb96425bdff15c7a695ff8a49642315f","modified":1561197233715},{"_id":"source/_posts/deep-learning/optimization/412afb713ddcff0ba9165ab026563304_hd.png","hash":"686ea79039c03b2a778b645e7ed2b1d413ef1e42","modified":1561207220604},{"_id":"source/_posts/coding/images/1553235348583.png","hash":"39d5d01e6dca9aa5a6e99a32eef64ed208b0f5c5","modified":1556549039497},{"_id":"source/_posts/deep-learning/rnn/lstm.png","hash":"06665b780177f429290743bccd76ddea206c3ea4","modified":1562081260341},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"9a5e3c6da76f6d5bed70c38fdf5796faa759d473","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"0bef9f0dc134215bc4d0984ba3a16a1a0b6f87ec","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"fe03041c387347e0bcf8efd1b4cf205ece66c339","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fa33213aceed7bf4bf25437ca9c1a00f7734ae65","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"a5bef4fdde80951f3b8c154d79cb1e581638a988","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"fe2dc74726a515549956d233becda188da64f948","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"2dd866817d0bc7d179e81855f8fbcbb5d3c883fc","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"fc160583f742c94316a0fee05c18468033173534","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"936132428a0d35b3947ccedd4c379940abcf223a","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"a5bef4fdde80951f3b8c154d79cb1e581638a988","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"d5e8ea6336bc2e237d501ed0d5bbcbbfe296c832","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"09b5054ae34ba83c0d614821e574da265af55a14","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"9b076c92abdadcf9acee75da64592ff3badd69b8","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"74c7dccf0a3ee9fc2ca25ad8e998243191813a0e","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"fd54eb599d5003bbb1aabc08596bc24a3fa3294f","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/_sub-menu.styl","hash":"b5b936dddb7b4de4720cd1e8428b30a2f06d63fb","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"5779cc8086b1cfde9bc4f1afdd85223bdc45f0a0","modified":1548959308975},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"837ff3718cb5a63eb01a451e35989fd1dfe4218c","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"61ca40856e5cacd48e0fa9728fde4605c7dd4c94","modified":1548959308971},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"7e51ea64611ab5d678c112b4688d4db4fd2737e2","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"8c68d36d1c74628be58cb61e66948868a8c7588d","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"e3ad313825d7ad03e24bb76d036deeb50587022b","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"4fd38490b01af4f977b53aefc433cd2f981cde14","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1548959308971},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"03d57bbe201e7d6865d5b303ee63f3f61c27c9d8","modified":1548959308971},{"_id":"themes/next/source/js/src/schemes/muse.js","hash":"e9bfa6b343b67625f58757efce46ccdaac8f308c","modified":1548959308975},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"9eb63cba0327d3d11b6cbfcbe40b88e97a8378a3","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1548959308975},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560779531173.png","hash":"e83832f9930164a085f6bc9e0b9814785e13d36c","modified":1561046876895},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561034699845.png","hash":"93c4e7d16d02cf540103d77b0f4d03611fefd81b","modified":1561046876895},{"_id":"source/_posts/deep-learning/nn_cs231n_note/ccb56c1fb267bc632d6d88459eb14ace_hd.png","hash":"6b7ed015213b55d3f41426379ef583e4e4966c65","modified":1561046876955},{"_id":"source/_posts/deep-learning/batch_normalization/1560779531173.png","hash":"e83832f9930164a085f6bc9e0b9814785e13d36c","modified":1561182231779},{"_id":"source/_posts/deep-learning/batch_normalization/BNcircuit-1561283729951.png","hash":"23f3f6b99740d8f4a9f31b049caf5382ee43640e","modified":1561283729964},{"_id":"source/_posts/deep-learning/batch_normalization/alg1.png","hash":"7b3adc7132b45efa5c774efc684e292f513c42f0","modified":1562085588427},{"_id":"source/_posts/deep-learning/optimization/1561034699845.png","hash":"93c4e7d16d02cf540103d77b0f4d03611fefd81b","modified":1561197233715},{"_id":"source/_posts/deep-learning/optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png","hash":"fffd7f4621756e12195df0b0c6f535869dc5fb4d","modified":1561196950271},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1548959308975},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1548959308975},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"cd86bed852fec6e6933898067122a03755bc17f0","modified":1548959308975},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1548959308975},{"_id":"source/_posts/deep-learning/optimization/1561191915813.png","hash":"2d221ae72fccc3d750e769b24cab597c6b6b26c9","modified":1561191915816},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1548959308975},{"_id":"source/_posts/deep-learning/nn_cs231n_note/63fcf4cc655cb04f21a37e86aca333cf_hd.png","hash":"4aa257d2eb9b46c6812525dec602cacda713fa6f","modified":1561046876935},{"_id":"source/_posts/deep-learning/optimization/1561186187105.png","hash":"ea5d546b4aeef950ba540a95546ed737c4f6d806","modified":1561191553875},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548959308975},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548959308975},{"_id":"themes/next/source/css/_common/components/header/github-banner.styl","hash":"9e0f215868df17cb27a4a522fd31156c66428c2d","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"7cc3f36222494c9a1325c5347d7eb9ae53755a32","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"05e68adae13f4d99a6ac6493daab39c92e39a6bd","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"c0d9e18a9210fdcaf33e488518b3b288eb58c0a1","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"9c59dbc1a6f2b4f15d8ae499f7aa227d9b0e3058","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1548959308971},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1548959308975},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"3b5a37ba5e70f92c1ee707c8053524e38adbb710","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"2356226157e8068b0e9bbe2f7d0f74e1ab49199b","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"300491cf0e80c34faf5f83a2846c177759ac653f","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"ede576abad438366c8e81f47435242ade5a5a08c","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"417f05ff12a2aaca6ceeac8b7e7eb26e9440c4c3","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"1cf64afd4b49143972f7617869539be3adb91a5e","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"b5e5aa7074a965e396229c5bd263fb406770ce5f","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"8e058c99dd7d41f0bd34c7c28b6ac9fbb17dcb5e","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-reading_progress.styl","hash":"0e8294d042d7d28c680ead48baa9e3c777d407c5","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"a6c24393dffbdd94dd5c01cdbec5e180b0bfbbbd","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"3039df53b94b0847b0c451d2d227270b479cc184","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"35c0350096921dd8e2222ec41b6c17a4ea6b44f2","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"cee0e70d1a6ea963bfd707bf9cedb8a4637f64c2","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"b34bb2ea4d16e47e6fdc06cd4feb32d93ccbd779","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"b964782056658ac785ec6070e747c97a5e234ddb","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"9a3bfc878ca797946815bed23cd6f92b24a16358","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"671a7f8aa138259172e7c6268d82d7a62a1e036a","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"e73db17c210ada503aafca2daaf84a9bfd34be75","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"9ab4e05e7b78af755ebdcbb71731fd723ed2d7f5","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"c11ef42781111d061ed5b6c14dd4359e2cba88be","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"6ec8ea7b11a146777b6b8da0f71f0cc1dbd129df","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"070251836b57027c8240c51e41cb8e8c999c4525","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"0e760758221d4919902bda7c4d3bb96c94a678db","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"75f7876136fe1cae9b42d2c220e7f8b37b8d2f55","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"5e340ee2407a4e39cd708794cfcc718a5f398d7b","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"4cfeec9434a72d5efc6ca225d3445d084d4590f7","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"7d2222f66a1c1a0a3cc90bfd5d817d9b859f4a68","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/gitalk.styl","hash":"ac7753d536341aa824d7bce0332735e838916995","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"c415729e0f0d2439e63b93cec7ae32df54db87b4","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"7059e24235b7c57a07f3f8abaa06b0bd6a7eda2f","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/related-posts.styl","hash":"2d4f318644bf37c50e5b1fab8d62b2673fbab9e8","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"190ad18f45b8a69cef13b2fdd2254893d06ec2c3","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"6904fd7ea6455e008d9884558b68254608af9a3c","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pages/breadcrumb.styl","hash":"2d142c6f39853916256ad8fc79eb6b85f4001ae8","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"fb451dc4cc0355b57849c27d3eb110c73562f794","modified":1548959308971},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1548959308975},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561185046719.png","hash":"01008e8026196b6620879139993b6bf9a1522d5e","modified":1561185046780},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561185066736.png","hash":"a20d551dbc10f0487001b90bc964ca4082a078f7","modified":1561185066788},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561186187105.png","hash":"ea5d546b4aeef950ba540a95546ed737c4f6d806","modified":1561186187143},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1548959308971},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"61af2f656f6e916f9920277bd048c5d58ff32a60","modified":1548959308971},{"_id":"source/_posts/deep-learning/rnn/LSTM3-chain.png","hash":"2a99a02c5bfe4bb5c16e6eb497be628e6ee71062","modified":1562081260341},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1548959308971},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1548959308975},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1548959308975},{"_id":"source/_posts/deep-learning/back_propagation/1561185066736.png","hash":"a20d551dbc10f0487001b90bc964ca4082a078f7","modified":1561191494112},{"_id":"source/_posts/deep-learning/nn_cs231n_note/8608c06086fc196228f4dda78499a2d9_hd.png","hash":"361f334962bfb8f19f0f0fc13bca6d0cbb1a3671","modified":1561046876943},{"_id":"source/_posts/deep-learning/optimization/20160909001936276","hash":"7bc6fa9016fd09af21dc546a394621865c60b35d","modified":1561215023847},{"_id":"source/_posts/deep-learning/nn_cs231n_note/3.1.1.5.png","hash":"942fd53dc0773b63a7245250ca5b5c44edaf7053","modified":1561046876919},{"_id":"source/_posts/deep-learning/optimization/contours_evaluation_optimizers.gif","hash":"0d4d768dcedf08df014f790f86d4f771451b7825","modified":1561215000836},{"_id":"public/leancloud_counter_security_urls.json","hash":"e664a848e063396bf1239a50388a9374b08a8a43","modified":1563803739878},{"_id":"public/categories/index.html","hash":"101969d5b17693fcc2ff6952450fa64418dd4ffb","modified":1563803739894},{"_id":"public/tags/index.html","hash":"000c396cc636f5b505850ccceced4b6f4448773e","modified":1563803739894},{"_id":"public/2019/04/29/statitics/estimate/index.html","hash":"a315e1f8d30835575f35cb937a88976c4a233635","modified":1563803739894},{"_id":"public/categories/dl/index.html","hash":"a36befc91ac9f4f9b58b2552552ddd1b5b0778b6","modified":1563803739894},{"_id":"public/categories/ml/index.html","hash":"0445d7ffa84d3a291f7a93220dc5ac99809ceef4","modified":1563803739894},{"_id":"public/categories/math/index.html","hash":"e2caf7666b95e5d238a9f5d5c17ea052d125bba8","modified":1563803739894},{"_id":"public/archives/page/2/index.html","hash":"13393c0a7ed5e24ea6199f6628964b1d69edfa76","modified":1563803739894},{"_id":"public/archives/2019/page/2/index.html","hash":"3bd5ae4b11cbfe0d8e65b2d347921210f41d09a6","modified":1563803739894},{"_id":"public/archives/2019/01/index.html","hash":"89afed6840b2f1628105f511e004cc6d45a9e0a6","modified":1563803739894},{"_id":"public/archives/2019/03/index.html","hash":"72b60305801c3278cb37fc22d09919e27a64a641","modified":1563803739894},{"_id":"public/archives/2019/04/index.html","hash":"252c47a121dcb073aa83aa465d436acc075aa17c","modified":1563803739894},{"_id":"public/archives/2019/06/index.html","hash":"9589063ae99e1150344b46a36457eadf6cc3a8e3","modified":1563803739894},{"_id":"public/archives/2019/07/index.html","hash":"5989afb3682b5712ffef905af4a0b02c838a4449","modified":1563803739894},{"_id":"public/tags/dl/index.html","hash":"14fdbb7271dd630dd186d7ccd5c918971c820cd7","modified":1563803739894},{"_id":"public/tags/hexo-asset-image/index.html","hash":"533bc71bc884bf42f9d63793589eb8c10be63a15","modified":1563803739894},{"_id":"public/tags/ml/index.html","hash":"1588e23e80555650efa19b88968e02b96a4cb6c6","modified":1563803739895},{"_id":"public/tags/statistics/index.html","hash":"0790c54975a7e9910a1e938b0abcfc034b4c40b0","modified":1563803739895},{"_id":"public/tags/math/index.html","hash":"f5150a785bf0c9695504e5fa8d0411221e7fd6c0","modified":1563803739895},{"_id":"public/2019/07/02/coding/重构/index.html","hash":"c6f144d5fd3d4b9128eca00f68933341071bcae5","modified":1563803739895},{"_id":"public/2019/07/01/deep-learning/cnn/index.html","hash":"c3a3db513fd8c1d711fdc0b386ed57dccea4cad1","modified":1563803739895},{"_id":"public/2019/06/22/deep-learning/back_propagation/index.html","hash":"7bc136d3c87b9ddc88609612a612668d0be8b4ce","modified":1563803739895},{"_id":"public/2019/06/19/deep-learning/batch_normalization/index.html","hash":"cf18e63aa21c2d9e9bbe5ed4b417d1fa771a9c3c","modified":1563803739895},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/index.html","hash":"e1936e1502bcb0bc38cfded5ad2e9e0bca075a57","modified":1563803739895},{"_id":"public/2019/06/17/deep-learning/rnn/index.html","hash":"60612364c73c2a159516fc3e1e235a73cb061380","modified":1563803739895},{"_id":"public/2019/06/17/deep-learning/dropout/index.html","hash":"c6805fc3a1750d556f7da63f00f21e836a07acc7","modified":1563803739895},{"_id":"public/2019/06/17/deep-learning/optimization/index.html","hash":"6fa902233741d932ffe71240016e78e1e9a6123c","modified":1563803739895},{"_id":"public/2019/03/25/statitics/entropy/index.html","hash":"fd0dbd9e926c4438e61953b6ccfa19b58172db79","modified":1563803739895},{"_id":"public/2019/01/31/machine-learning/decision-tree/index.html","hash":"91792b6fa6916bcae23bef688b6f2dbf6c2e28e1","modified":1563803739895},{"_id":"public/2019/01/06/statitics/Statistics/index.html","hash":"1d607c42666a3934404d19b8719ce72f0944c54a","modified":1563803739895},{"_id":"public/index.html","hash":"c1177d839089ed41f747aa82c19baf5c56391fc2","modified":1563803739895},{"_id":"public/page/2/index.html","hash":"88b646fbc378c5c8a8cddcc3459b5795ee3a1e19","modified":1563803739895},{"_id":"public/archives/index.html","hash":"efe53ca115db80851c0ad67aafa0927729ad3f4a","modified":1563803739895},{"_id":"public/archives/2019/index.html","hash":"a4aa5a340a552a9f216cbc957e0158ca20a3a58a","modified":1563803739895},{"_id":"public/CNAME.bak","hash":"129860cef99c0898751d415efbaea935b420fc31","modified":1563803739903},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1563803739903},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1563803739903},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1563803739903},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1563803739903},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1563803739903},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1563803739903},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1563803739903},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1563803739903},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1563803739903},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1563803739903},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1563803739903},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1563803739903},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1563803739903},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1563803739903},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1563803739903},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1563803739903},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1563803739903},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1563803739903},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1563803739903},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1563803739903},{"_id":"public/2019/03/25/statitics/entropy/1562775971102.png","hash":"b0b7e3c0dfe7e526eeb586ff4fe05c6d888940cb","modified":1563803739903},{"_id":"public/2019/07/01/deep-learning/cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg","hash":"670eb624205aa4e9604544112bfae4c554780609","modified":1563803739903},{"_id":"public/2019/07/01/deep-learning/cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg","hash":"85bb9df83f542b7c9ee8424009d6184858a27c9e","modified":1563803739903},{"_id":"public/2019/01/31/machine-learning/decision-tree/1548940093157.png","hash":"1545a8cdd264da9e41929b5b22c98fabb40b14ba","modified":1563803739904},{"_id":"public/2019/01/31/machine-learning/decision-tree/1548940125578.png","hash":"dc050e44987e396207cdc6b32c689b134207f97c","modified":1563803739904},{"_id":"public/2019/01/31/machine-learning/decision-tree/1548940132559.png","hash":"dc050e44987e396207cdc6b32c689b134207f97c","modified":1563803739904},{"_id":"public/2019/01/31/machine-learning/decision-tree/feature-space.png","hash":"1341d484f40cb56ae4c2295bfe49fb3843db815e","modified":1563803739904},{"_id":"public/2019/01/31/machine-learning/decision-tree/tree_basic.png","hash":"63a086ff52e9fc6b2d59470db972e23737e30369","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/rnn/2256672-3b20294694c3904b.png","hash":"d2420eebcf356a15cc96b31eddbcff03a4bc599b","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/rnn/1562068950392.png","hash":"3913c5b01fa10569212c0f4e9458ccc6ae7dd245","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/rnn/v2-3884f344d71e92d70ec3c44d2795141f_hd.jpg","hash":"ec7dc4b9f3afdc1a164ff7f7703b234cb098a625","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/rnn/v2-71652d6a1eee9def631c18ea5e3c7605_hd.jpg","hash":"a37e04b13f4077b6bb2ae796043045000d15c451","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/rnn/v2-b0175ebd3419f9a11a3d0d8b00e28675_hd.jpg","hash":"c2fdaab09eca14882154825e2e890ddb335717bf","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/03b3eccf18ee3760e219f9f95ec14305_hd.png","hash":"4c7877376cffdcf713f0aa74b34f7a42eee192b5","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1560776135809.png","hash":"04f41de9ecec7e34742f0d6b9a1e370184a24b71","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/677187e96671a4cac9c95352743b3806_hd.png","hash":"eb528d932f29d13438dba6b842f938931d513ed7","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","hash":"8c41052570b879d257cd14cfb51a7db1bea1e019","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png","hash":"4c7877376cffdcf713f0aa74b34f7a42eee192b5","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/1561191915813.png","hash":"2d221ae72fccc3d750e769b24cab597c6b6b26c9","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/1561196522519.png","hash":"c1408ffe730f716cf42f103314af8324a98855da","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg","hash":"9f3677bd92ea36de4faec35b74ad57d85899397a","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/equation.svg","hash":"bea54f59fb418fc3395f123b5002b2636be8b27a","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/nesterov_update_vector.png","hash":"cf8d982d21e86fecc983d8d1773e8c9ad4e86315","modified":1563803739904},{"_id":"public/2019/06/17/deep-learning/optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","hash":"8c41052570b879d257cd14cfb51a7db1bea1e019","modified":1563803739904},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1563803740396},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1563803740396},{"_id":"public/2019/07/01/deep-learning/cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg","hash":"0e747e52bf200d5069c7700649463949e3bd63e8","modified":1563803740396},{"_id":"public/2019/06/17/deep-learning/rnn/lstm.png","hash":"06665b780177f429290743bccd76ddea206c3ea4","modified":1563803740396},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1560776449074.png","hash":"7e91eee97de8151660f88d4058a8abefdef48781","modified":1563803740396},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561035128653.png","hash":"328a3b273ef07eaedbc9935f58249c83e66e1166","modified":1563803740396},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561035151992.png","hash":"1c858d3bfb96425bdff15c7a695ff8a49642315f","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561186124221.png","hash":"423870c8ea51cd86797875e27d139a6e33bbb7cd","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/42.png","hash":"676fc46d06ed87d6597f2dc71eed1d084824ed9e","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/aae11de6e6a29f50d46b9ea106fbb02a_hd.png","hash":"b5dcff7a36e9d96bb915e0bcefa9efe4a1785315","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/d0cbce2f2654b8e70fe201fec2982c7d_hd.png","hash":"3d8190e901a235e3ae38f72dce30604e1e740fa8","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/e743b6777775b1671c3b5503d7afbbc4_hd.png","hash":"1aae3b4cde09f9710d2e31aebc20a249b7e9180c","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/optimization/1561034699845.png","hash":"93c4e7d16d02cf540103d77b0f4d03611fefd81b","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/optimization/1561035128653.png","hash":"328a3b273ef07eaedbc9935f58249c83e66e1166","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/optimization/1561035151992.png","hash":"1c858d3bfb96425bdff15c7a695ff8a49642315f","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/optimization/1561186124221.png","hash":"423870c8ea51cd86797875e27d139a6e33bbb7cd","modified":1563803740397},{"_id":"public/2019/06/17/deep-learning/optimization/412afb713ddcff0ba9165ab026563304_hd.png","hash":"686ea79039c03b2a778b645e7ed2b1d413ef1e42","modified":1563803740397},{"_id":"public/2019/06/19/deep-learning/batch_normalization/1560779540116.png","hash":"e75abb556987946287bf853feafe5f554aef81c4","modified":1563803740397},{"_id":"public/js/src/affix.js","hash":"a2aab233d99297435a5274bf512c3c753fe08e80","modified":1563803740402},{"_id":"public/js/src/algolia-search.js","hash":"1f7f10c579e7703d0f6acb8b73f3d78a07d0c623","modified":1563803740402},{"_id":"public/js/src/bootstrap.js","hash":"1c41508b83cb0c4512e64b4d63afa1be954ce8ef","modified":1563803740403},{"_id":"public/js/src/exturl.js","hash":"54825acc8de4793feac415be227b965428f4e97d","modified":1563803740403},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1563803740403},{"_id":"public/js/src/post-details.js","hash":"0dde5e6d4547587662a3256317a9d5d1db507692","modified":1563803740403},{"_id":"public/js/src/scroll-cookie.js","hash":"d07b3776708d4ae79ed2037c4c7391d5c9b06b19","modified":1563803740403},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1563803740403},{"_id":"public/js/src/scrollspy.js","hash":"fa3c92968bcdbcb8d95a1729f7659d9753cbd077","modified":1563803740403},{"_id":"public/js/src/schemes/muse.js","hash":"e9bfa6b343b67625f58757efce46ccdaac8f308c","modified":1563803740403},{"_id":"public/js/src/schemes/pisces.js","hash":"9eb63cba0327d3d11b6cbfcbe40b88e97a8378a3","modified":1563803740403},{"_id":"public/css/main.css","hash":"84f1a2f12d54bbf024d068c773b82081ec518aa6","modified":1563803740403},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1560779531173.png","hash":"e83832f9930164a085f6bc9e0b9814785e13d36c","modified":1563803740403},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561034699845.png","hash":"93c4e7d16d02cf540103d77b0f4d03611fefd81b","modified":1563803740403},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/ccb56c1fb267bc632d6d88459eb14ace_hd.png","hash":"6b7ed015213b55d3f41426379ef583e4e4966c65","modified":1563803740403},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/63fcf4cc655cb04f21a37e86aca333cf_hd.png","hash":"4aa257d2eb9b46c6812525dec602cacda713fa6f","modified":1563803740403},{"_id":"public/2019/06/17/deep-learning/optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png","hash":"fffd7f4621756e12195df0b0c6f535869dc5fb4d","modified":1563803740403},{"_id":"public/2019/06/19/deep-learning/batch_normalization/1560779531173.png","hash":"e83832f9930164a085f6bc9e0b9814785e13d36c","modified":1563803740404},{"_id":"public/2019/06/19/deep-learning/batch_normalization/alg1.png","hash":"7b3adc7132b45efa5c774efc684e292f513c42f0","modified":1563803740404},{"_id":"public/js/src/motion.js","hash":"7933a30382a84b655238f6e78d42ea1b99af4de6","modified":1563803740408},{"_id":"public/js/src/utils.js","hash":"f1394d64977439ec569d2777b1ac304905e043f1","modified":1563803740408},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1563803740408},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1563803740408},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1563803740409},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1563803740409},{"_id":"public/2019/06/17/deep-learning/optimization/1561186187105.png","hash":"ea5d546b4aeef950ba540a95546ed737c4f6d806","modified":1563803740409},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1560779540116.png","hash":"e75abb556987946287bf853feafe5f554aef81c4","modified":1563803740409},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561037588255.png","hash":"ec3756f7612db97741cbdd1162ea22c0a5418008","modified":1563803740409},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561186187105.png","hash":"ea5d546b4aeef950ba540a95546ed737c4f6d806","modified":1563803740414},{"_id":"public/2019/06/19/deep-learning/batch_normalization/BNcircuit-1561283729951.png","hash":"23f3f6b99740d8f4a9f31b049caf5382ee43640e","modified":1563803740414},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1563803740419},{"_id":"public/2019/06/17/deep-learning/rnn/LSTM3-chain.png","hash":"2a99a02c5bfe4bb5c16e6eb497be628e6ee71062","modified":1563803740419},{"_id":"public/2019/06/22/deep-learning/back_propagation/1561185066736.png","hash":"a20d551dbc10f0487001b90bc964ca4082a078f7","modified":1563803740419},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1563803740424},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1563803740424},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1563803740424},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561185046719.png","hash":"01008e8026196b6620879139993b6bf9a1522d5e","modified":1563803740425},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/1561185066736.png","hash":"a20d551dbc10f0487001b90bc964ca4082a078f7","modified":1563803740425},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/8608c06086fc196228f4dda78499a2d9_hd.png","hash":"361f334962bfb8f19f0f0fc13bca6d0cbb1a3671","modified":1563803740436},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1563803740443},{"_id":"public/2019/06/17/deep-learning/nn_cs231n_note/3.1.1.5.png","hash":"942fd53dc0773b63a7245250ca5b5c44edaf7053","modified":1563803740449},{"_id":"public/2019/06/17/deep-learning/optimization/20160909001936276","hash":"7bc6fa9016fd09af21dc546a394621865c60b35d","modified":1563803740450},{"_id":"public/2019/06/17/deep-learning/optimization/contours_evaluation_optimizers.gif","hash":"0d4d768dcedf08df014f790f86d4f771451b7825","modified":1563803740451},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1563803740452}],"Category":[{"name":"dl","_id":"cjyegdapv0004u09oa0pgy0m2"},{"name":"ml","_id":"cjyegdaq3000iu09ozc5ndmxv"},{"name":"math","_id":"cjyegdaq4000nu09owxwrdz0z"}],"Data":[],"Page":[{"title":"categories","date":"2019-01-31T16:58:44.000Z","_content":"\n[西瓜书](../xiguashu/)","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-02-01 00:58:44\n---\n\n[西瓜书](../xiguashu/)","updated":"2019-01-31T18:13:08.996Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjyegdanw0000u09oqver3cya","content":"<p><a href=\"../xiguashu/\">西瓜书</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"../xiguashu/\">西瓜书</a></p>\n"},{"title":"tags","date":"2019-01-31T16:57:47.000Z","tags":["xiguashu","ml","testing"],"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-02-01 00:57:47\ntags:\n  - xiguashu\n  - ml\n  - testing\n---\n","updated":"2019-01-31T18:13:08.996Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjyegdanx0001u09o21pnccsg","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Back Propagation","date":"2019-06-21T16:00:00.000Z","mathjax":true,"_content":"\n## Backpropagation\n\nReference: [Understanding the backward pass through Batch Normalization Layer](<https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html>)\n\n\n\n#### 全连接网络数据指示图\n\n![1561185066736](back_propagation/1561185066736.png)\n\n$$w = w - \\eta dw$$\n\n\n\n","source":"_posts/deep-learning/back_propagation.md","raw":"---\ntitle: Back Propagation\ndate: 2019-06-22\nmathjax: true\ncategories:\n  - dl\ntag:\n  - dl\n  - hexo-asset-image\n---\n\n## Backpropagation\n\nReference: [Understanding the backward pass through Batch Normalization Layer](<https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html>)\n\n\n\n#### 全连接网络数据指示图\n\n![1561185066736](back_propagation/1561185066736.png)\n\n$$w = w - \\eta dw$$\n\n\n\n","slug":"deep-learning/back_propagation","published":1,"updated":"2019-07-02T15:35:45.025Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdapq0002u09o8q0bp9cn","content":"<h2 id=\"Backpropagation\"><a href=\"#Backpropagation\" class=\"headerlink\" title=\"Backpropagation\"></a>Backpropagation</h2><p>Reference: <a href=\"https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\" target=\"_blank\" rel=\"noopener\">Understanding the backward pass through Batch Normalization Layer</a></p>\n<h4 id=\"全连接网络数据指示图\"><a href=\"#全连接网络数据指示图\" class=\"headerlink\" title=\"全连接网络数据指示图\"></a>全连接网络数据指示图</h4><p><img src=\"/2019/06/22/deep-learning/back_propagation/1561185066736.png\" alt=\"1561185066736\"></p>\n<p>$$w = w - \\eta dw$$</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Backpropagation\"><a href=\"#Backpropagation\" class=\"headerlink\" title=\"Backpropagation\"></a>Backpropagation</h2><p>Reference: <a href=\"https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\" target=\"_blank\" rel=\"noopener\">Understanding the backward pass through Batch Normalization Layer</a></p>\n<h4 id=\"全连接网络数据指示图\"><a href=\"#全连接网络数据指示图\" class=\"headerlink\" title=\"全连接网络数据指示图\"></a>全连接网络数据指示图</h4><p><img src=\"/2019/06/22/deep-learning/back_propagation/1561185066736.png\" alt=\"1561185066736\"></p>\n<p>$$w = w - \\eta dw$$</p>\n"},{"_content":"","source":"_posts/deep-learning/nn_cs231n_note.md","raw":"","slug":"deep-learning/nn_cs231n_note","published":1,"date":"2019-07-22T14:03:25.487Z","updated":"2019-07-22T14:03:25.487Z","_id":"cjyegdapt0003u09ot2248n1q","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"_content":"","source":"_posts/deep-learning/rnn.md","raw":"","slug":"deep-learning/rnn","published":1,"date":"2019-07-22T14:03:35.891Z","updated":"2019-07-22T14:03:35.891Z","_id":"cjyegdapw0006u09oe0gc4rdy","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"CNN","date":"2019-06-30T16:00:00.000Z","mathjax":true,"_content":"\nCovolution Neuro Network\n------------------------------------------\n\n\n## 卷积\n卷积运算，源于信号处理\n\n#### 感受野，接受域\n\n![img](cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg)\n\n只受３个输入单元影响，接受域为３，忽略接受域外权重（无限强先验）\n\n#### 优点\n\n- 稀疏交互\n\n- 参数共享，在不同输入位置上使用相同的参数。普通神经网络权重与神经元绑定，需要 $N_l * N_{l+1}$ 个参数；卷积神经网络每个权重参数不变，只需要 $k*k$ 个参数。\n- 平移不变性，只包含局部连接关系（接受域）\n\n![img](cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg)\n\n96个[11x11x3]滤波器，如果在图像某些地方探测到一个水平的边界是很重要，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。\n\n有的滤波器学习到了条纹，有些学到了色彩差别\n\n#### CNN\n\n输出尺寸：$\\frac{W-F+2P}{S} + 1$\n\n- F: fiter, 卷积核/滤波器/感受野的尺寸，常用3x3, 5x5\n- P: padding, 零填充的数量. SAME(输出与输入保持一直，p=F-1/S)，VALID(不填充，输出尺寸减少, p=F/S)\n- S: stride, 步长\n\n#### code\n\n```python\n# forward\ndef conv_forward_naive(x, w, b, conv_param):\n    # input x: N data points, C channels, height H, width W\n    N, C, H, W = x.shape\n    # filter w: (F, C, HH, WW)\n    F, _, HH, WW = w.shape\n    \n    stride, pad = conv_param['stride'], conv_param['pad']\n    H_out = 1 + (H + 2 * pad - HH) // stride  \n    W_out = 1 + (W + 2 * pad - WW) // stride\n    out = np.zeros((N, F, H_out, W_out))\n    \n    # ０填充\n    x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n    \n    # out: (N, F, H', W')  F filters\n    # N个输入格式一致，直接在矩阵中操作\n    # 遍历输出点高度和宽度(h_out, w_out)\n    # 输出点从上到下，从左到右移动\n    for h_out in range(H_out):\n        for w_out in range(W_out):\n            # 获得当前卷积核对应的输入块（HH,WW）\n            x_pad_block = x_pad[:, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]\n            # 计算每个卷积核（滤波器 f）得到的输出，对应点（h_out, w_out)\n            for f in range(F):\n                out[:, f, h_out, w_out] = np.sum(x_pad_block * w[f, :, :, :], axis=(1,2,3)) + b[f]\n\n    cache = (x, w, b, conv_param)\n    return out, cache\n\n# backward\ndef conv_backward_naive(dout, cache):\n    x, w, b, conv_param = cache\n    N, C, H, W = x.shape\n    F, _, HH, WW = w.shape\n    _, _, H_out, W_out = dout.shape\n    stride, pad = conv_param['stride'], conv_param['pad']\n\t\n    # 0填充　padding\n    x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n\n    dx_pad = np.zeros_like(x_pad)\n    dw = np.zeros_like(w)\n    db = np.zeros_like(b)\n\n    # 遍历数据输入n\n    for n in range(N):\n        # 遍历 filter f\n        for f in range(F):\n            # db (N,F)\n            db[f] += np.sum(dout[n, f])\n            # 遍历输出点高度和宽度　[h,w]\n            for h_out in range(H_out):\n                for w_out in range(W_out):\n                    # 获得当前卷积核f对应的输入块（HH,WW）\n                    x_pad_block = x_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]\n                    # dw (F,)\n                    dw[f, :, :, :] += x_pad_block * dout[n, f, h_out, w_out]\n                    dx_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW] += \\\n                        w[f, :, :, :] * dout[n, f, h_out, w_out]\n\n    dx = dx_pad[:, :, pad:pad+H, pad:pad+W]\n\t\n    # return Gradients: dx, dw, db\n    return dx, dw, db\n\n\n```\n\n*卷积层是如何解决不同大小输入的问题 ???*\n\n\n\n## 池化\n\n#### 特点\n\n- 局部平移不变性：关心某个特征是否出现，不关心出现的具体位置　（无限强先验）\n- 降采样：下一层少了 k 倍输入\n- 综合池化区域(pool)的 k*k 个像素的统计特征\n- 处理不同大小的输入，输出相同数量的统计特征\n\n\n\n最大池化 pool (2, 2)，步长 stride 2，输出大小减半\n\n![img](cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg)\n\n```python\n\ndef max_pool_forward_naive(x, pool_param): \n    # input x: (N, C, H, W)\n    N, C, H, W = x.shape\n    # pool region: (heigth, width), stride\n    pool_height = pool_param['pool_height']\n    pool_width = pool_param['pool_width']\n    stride = pool_param['stride']\n    # output: (N, C, H', W')\n    H_out = 1 + (H - pool_height) // stride \n    W_out = 1 + (W - pool_width) // stride\n    out = np.zeros((N, C, H_out, W_out))\n\n    # 遍历输出点高度和宽度 [h,w]\n    for h in range(H_out):\n        for w in range(W_out):\n            # pool对应的输入块\n            x_pad_block = x[:, :, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]\n            # 最大池化，输出到　[:, :, h, w]\n            out[:, :, h, w] = np.max(x_pad_block, axis=(-1, -2))\n\n    cache = (x, pool_param)\n    return out, cache\n\n\ndef max_pool_backward_naive(dout, cache):\n    x, pool_param = cache\n    N, C, H, W = x.shape\n    # pool region: (heigth, width), stride\n    pool_height = pool_param['pool_height']\n    pool_width = pool_param['pool_width']\n    stride = pool_param['stride']\n    # output: (N, C, H', W')\n    H_out = 1 + (H - pool_height) // stride \n    W_out = 1 + (W - pool_width) // stride\n    # 初始化梯度　dx\n    dx = np.zeros_like(x)\n     \n    # 遍历输入 n\n    for n in range(N):\n        # 遍历filter c\n        for c in range(C):\n            # 遍历输出点高度和宽度 [h, w]\n            for h in range(H_out):\n                for w in range(W_out):\n                    # 当前输出点对应的 pool 输入块\n                    x_pad_block = x[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]\n                    # Find the index (row, col) of the max value\n                    # grads on the max value is exists, else is 0\n                    index = np.unravel_index(np.argmax(x_pad_block, axis=None), (pool_height, pool_width))\n                    # pool对应的输入块各点的梯度\n                    # 只有pool输入块中最大值对应的点(索引index)存在梯度，等于dout[n, c, h, w]，其余点梯度为0\n                    dx[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width][index] = dout[n, c, h, w]\n\n    return dx\n```\n\n","source":"_posts/deep-learning/cnn.md","raw":"---\ntitle: CNN\ndate: 2019-07-01\nmathjax: true\ncategories:\n  - dl\ntag:\n  - dl\n  - hexo-asset-image\n---\n\nCovolution Neuro Network\n------------------------------------------\n\n\n## 卷积\n卷积运算，源于信号处理\n\n#### 感受野，接受域\n\n![img](cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg)\n\n只受３个输入单元影响，接受域为３，忽略接受域外权重（无限强先验）\n\n#### 优点\n\n- 稀疏交互\n\n- 参数共享，在不同输入位置上使用相同的参数。普通神经网络权重与神经元绑定，需要 $N_l * N_{l+1}$ 个参数；卷积神经网络每个权重参数不变，只需要 $k*k$ 个参数。\n- 平移不变性，只包含局部连接关系（接受域）\n\n![img](cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg)\n\n96个[11x11x3]滤波器，如果在图像某些地方探测到一个水平的边界是很重要，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。\n\n有的滤波器学习到了条纹，有些学到了色彩差别\n\n#### CNN\n\n输出尺寸：$\\frac{W-F+2P}{S} + 1$\n\n- F: fiter, 卷积核/滤波器/感受野的尺寸，常用3x3, 5x5\n- P: padding, 零填充的数量. SAME(输出与输入保持一直，p=F-1/S)，VALID(不填充，输出尺寸减少, p=F/S)\n- S: stride, 步长\n\n#### code\n\n```python\n# forward\ndef conv_forward_naive(x, w, b, conv_param):\n    # input x: N data points, C channels, height H, width W\n    N, C, H, W = x.shape\n    # filter w: (F, C, HH, WW)\n    F, _, HH, WW = w.shape\n    \n    stride, pad = conv_param['stride'], conv_param['pad']\n    H_out = 1 + (H + 2 * pad - HH) // stride  \n    W_out = 1 + (W + 2 * pad - WW) // stride\n    out = np.zeros((N, F, H_out, W_out))\n    \n    # ０填充\n    x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n    \n    # out: (N, F, H', W')  F filters\n    # N个输入格式一致，直接在矩阵中操作\n    # 遍历输出点高度和宽度(h_out, w_out)\n    # 输出点从上到下，从左到右移动\n    for h_out in range(H_out):\n        for w_out in range(W_out):\n            # 获得当前卷积核对应的输入块（HH,WW）\n            x_pad_block = x_pad[:, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]\n            # 计算每个卷积核（滤波器 f）得到的输出，对应点（h_out, w_out)\n            for f in range(F):\n                out[:, f, h_out, w_out] = np.sum(x_pad_block * w[f, :, :, :], axis=(1,2,3)) + b[f]\n\n    cache = (x, w, b, conv_param)\n    return out, cache\n\n# backward\ndef conv_backward_naive(dout, cache):\n    x, w, b, conv_param = cache\n    N, C, H, W = x.shape\n    F, _, HH, WW = w.shape\n    _, _, H_out, W_out = dout.shape\n    stride, pad = conv_param['stride'], conv_param['pad']\n\t\n    # 0填充　padding\n    x_pad = np.pad(x, ((0,), (0,), (pad,), (pad,)), mode='constant', constant_values=0)\n\n    dx_pad = np.zeros_like(x_pad)\n    dw = np.zeros_like(w)\n    db = np.zeros_like(b)\n\n    # 遍历数据输入n\n    for n in range(N):\n        # 遍历 filter f\n        for f in range(F):\n            # db (N,F)\n            db[f] += np.sum(dout[n, f])\n            # 遍历输出点高度和宽度　[h,w]\n            for h_out in range(H_out):\n                for w_out in range(W_out):\n                    # 获得当前卷积核f对应的输入块（HH,WW）\n                    x_pad_block = x_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]\n                    # dw (F,)\n                    dw[f, :, :, :] += x_pad_block * dout[n, f, h_out, w_out]\n                    dx_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW] += \\\n                        w[f, :, :, :] * dout[n, f, h_out, w_out]\n\n    dx = dx_pad[:, :, pad:pad+H, pad:pad+W]\n\t\n    # return Gradients: dx, dw, db\n    return dx, dw, db\n\n\n```\n\n*卷积层是如何解决不同大小输入的问题 ???*\n\n\n\n## 池化\n\n#### 特点\n\n- 局部平移不变性：关心某个特征是否出现，不关心出现的具体位置　（无限强先验）\n- 降采样：下一层少了 k 倍输入\n- 综合池化区域(pool)的 k*k 个像素的统计特征\n- 处理不同大小的输入，输出相同数量的统计特征\n\n\n\n最大池化 pool (2, 2)，步长 stride 2，输出大小减半\n\n![img](cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg)\n\n```python\n\ndef max_pool_forward_naive(x, pool_param): \n    # input x: (N, C, H, W)\n    N, C, H, W = x.shape\n    # pool region: (heigth, width), stride\n    pool_height = pool_param['pool_height']\n    pool_width = pool_param['pool_width']\n    stride = pool_param['stride']\n    # output: (N, C, H', W')\n    H_out = 1 + (H - pool_height) // stride \n    W_out = 1 + (W - pool_width) // stride\n    out = np.zeros((N, C, H_out, W_out))\n\n    # 遍历输出点高度和宽度 [h,w]\n    for h in range(H_out):\n        for w in range(W_out):\n            # pool对应的输入块\n            x_pad_block = x[:, :, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]\n            # 最大池化，输出到　[:, :, h, w]\n            out[:, :, h, w] = np.max(x_pad_block, axis=(-1, -2))\n\n    cache = (x, pool_param)\n    return out, cache\n\n\ndef max_pool_backward_naive(dout, cache):\n    x, pool_param = cache\n    N, C, H, W = x.shape\n    # pool region: (heigth, width), stride\n    pool_height = pool_param['pool_height']\n    pool_width = pool_param['pool_width']\n    stride = pool_param['stride']\n    # output: (N, C, H', W')\n    H_out = 1 + (H - pool_height) // stride \n    W_out = 1 + (W - pool_width) // stride\n    # 初始化梯度　dx\n    dx = np.zeros_like(x)\n     \n    # 遍历输入 n\n    for n in range(N):\n        # 遍历filter c\n        for c in range(C):\n            # 遍历输出点高度和宽度 [h, w]\n            for h in range(H_out):\n                for w in range(W_out):\n                    # 当前输出点对应的 pool 输入块\n                    x_pad_block = x[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]\n                    # Find the index (row, col) of the max value\n                    # grads on the max value is exists, else is 0\n                    index = np.unravel_index(np.argmax(x_pad_block, axis=None), (pool_height, pool_width))\n                    # pool对应的输入块各点的梯度\n                    # 只有pool输入块中最大值对应的点(索引index)存在梯度，等于dout[n, c, h, w]，其余点梯度为0\n                    dx[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width][index] = dout[n, c, h, w]\n\n    return dx\n```\n\n","slug":"deep-learning/cnn","published":1,"updated":"2019-07-03T17:21:54.604Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdapx0007u09oliz9chab","content":"<h2 id=\"Covolution-Neuro-Network\"><a href=\"#Covolution-Neuro-Network\" class=\"headerlink\" title=\"Covolution Neuro Network\"></a>Covolution Neuro Network</h2><h2 id=\"卷积\"><a href=\"#卷积\" class=\"headerlink\" title=\"卷积\"></a>卷积</h2><p>卷积运算，源于信号处理</p>\n<h4 id=\"感受野，接受域\"><a href=\"#感受野，接受域\" class=\"headerlink\" title=\"感受野，接受域\"></a>感受野，接受域</h4><p><img src=\"/2019/07/01/deep-learning/cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg\" alt=\"img\"></p>\n<p>只受３个输入单元影响，接受域为３，忽略接受域外权重（无限强先验）</p>\n<h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h4><ul>\n<li><p>稀疏交互</p>\n</li>\n<li><p>参数共享，在不同输入位置上使用相同的参数。普通神经网络权重与神经元绑定，需要 $N_l <em> N_{l+1}$ 个参数；卷积神经网络每个权重参数不变，只需要 $k</em>k$ 个参数。</p>\n</li>\n<li>平移不变性，只包含局部连接关系（接受域）</li>\n</ul>\n<p><img src=\"/2019/07/01/deep-learning/cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg\" alt=\"img\"></p>\n<p>96个[11x11x3]滤波器，如果在图像某些地方探测到一个水平的边界是很重要，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。</p>\n<p>有的滤波器学习到了条纹，有些学到了色彩差别</p>\n<h4 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h4><p>输出尺寸：$\\frac{W-F+2P}{S} + 1$</p>\n<ul>\n<li>F: fiter, 卷积核/滤波器/感受野的尺寸，常用3x3, 5x5</li>\n<li>P: padding, 零填充的数量. SAME(输出与输入保持一直，p=F-1/S)，VALID(不填充，输出尺寸减少, p=F/S)</li>\n<li>S: stride, 步长</li>\n</ul>\n<h4 id=\"code\"><a href=\"#code\" class=\"headerlink\" title=\"code\"></a>code</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># forward</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_forward_naive</span><span class=\"params\">(x, w, b, conv_param)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># input x: N data points, C channels, height H, width W</span></span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># filter w: (F, C, HH, WW)</span></span><br><span class=\"line\">    F, _, HH, WW = w.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    stride, pad = conv_param[<span class=\"string\">'stride'</span>], conv_param[<span class=\"string\">'pad'</span>]</span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H + <span class=\"number\">2</span> * pad - HH) // stride  </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W + <span class=\"number\">2</span> * pad - WW) // stride</span><br><span class=\"line\">    out = np.zeros((N, F, H_out, W_out))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># ０填充</span></span><br><span class=\"line\">    x_pad = np.pad(x, ((<span class=\"number\">0</span>,), (<span class=\"number\">0</span>,), (pad,), (pad,)), mode=<span class=\"string\">'constant'</span>, constant_values=<span class=\"number\">0</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># out: (N, F, H', W')  F filters</span></span><br><span class=\"line\">    <span class=\"comment\"># N个输入格式一致，直接在矩阵中操作</span></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出点高度和宽度(h_out, w_out)</span></span><br><span class=\"line\">    <span class=\"comment\"># 输出点从上到下，从左到右移动</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> h_out <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w_out <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">            <span class=\"comment\"># 获得当前卷积核对应的输入块（HH,WW）</span></span><br><span class=\"line\">            x_pad_block = x_pad[:, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]</span><br><span class=\"line\">            <span class=\"comment\"># 计算每个卷积核（滤波器 f）得到的输出，对应点（h_out, w_out)</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> range(F):</span><br><span class=\"line\">                out[:, f, h_out, w_out] = np.sum(x_pad_block * w[f, :, :, :], axis=(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)) + b[f]</span><br><span class=\"line\"></span><br><span class=\"line\">    cache = (x, w, b, conv_param)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># backward</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_backward_naive</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    x, w, b, conv_param = cache</span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    F, _, HH, WW = w.shape</span><br><span class=\"line\">    _, _, H_out, W_out = dout.shape</span><br><span class=\"line\">    stride, pad = conv_param[<span class=\"string\">'stride'</span>], conv_param[<span class=\"string\">'pad'</span>]</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 0填充　padding</span></span><br><span class=\"line\">    x_pad = np.pad(x, ((<span class=\"number\">0</span>,), (<span class=\"number\">0</span>,), (pad,), (pad,)), mode=<span class=\"string\">'constant'</span>, constant_values=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    dx_pad = np.zeros_like(x_pad)</span><br><span class=\"line\">    dw = np.zeros_like(w)</span><br><span class=\"line\">    db = np.zeros_like(b)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历数据输入n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> range(N):</span><br><span class=\"line\">        <span class=\"comment\"># 遍历 filter f</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> range(F):</span><br><span class=\"line\">            <span class=\"comment\"># db (N,F)</span></span><br><span class=\"line\">            db[f] += np.sum(dout[n, f])</span><br><span class=\"line\">            <span class=\"comment\"># 遍历输出点高度和宽度　[h,w]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> h_out <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> w_out <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">                    <span class=\"comment\"># 获得当前卷积核f对应的输入块（HH,WW）</span></span><br><span class=\"line\">                    x_pad_block = x_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]</span><br><span class=\"line\">                    <span class=\"comment\"># dw (F,)</span></span><br><span class=\"line\">                    dw[f, :, :, :] += x_pad_block * dout[n, f, h_out, w_out]</span><br><span class=\"line\">                    dx_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW] += \\</span><br><span class=\"line\">                        w[f, :, :, :] * dout[n, f, h_out, w_out]</span><br><span class=\"line\"></span><br><span class=\"line\">    dx = dx_pad[:, :, pad:pad+H, pad:pad+W]</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># return Gradients: dx, dw, db</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx, dw, db</span><br></pre></td></tr></table></figure>\n<p><em>卷积层是如何解决不同大小输入的问题 ???</em></p>\n<h2 id=\"池化\"><a href=\"#池化\" class=\"headerlink\" title=\"池化\"></a>池化</h2><h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>局部平移不变性：关心某个特征是否出现，不关心出现的具体位置　（无限强先验）</li>\n<li>降采样：下一层少了 k 倍输入</li>\n<li>综合池化区域(pool)的 k*k 个像素的统计特征</li>\n<li>处理不同大小的输入，输出相同数量的统计特征</li>\n</ul>\n<p>最大池化 pool (2, 2)，步长 stride 2，输出大小减半</p>\n<p><img src=\"/2019/07/01/deep-learning/cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">max_pool_forward_naive</span><span class=\"params\">(x, pool_param)</span>:</span> </span><br><span class=\"line\">    <span class=\"comment\"># input x: (N, C, H, W)</span></span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># pool region: (heigth, width), stride</span></span><br><span class=\"line\">    pool_height = pool_param[<span class=\"string\">'pool_height'</span>]</span><br><span class=\"line\">    pool_width = pool_param[<span class=\"string\">'pool_width'</span>]</span><br><span class=\"line\">    stride = pool_param[<span class=\"string\">'stride'</span>]</span><br><span class=\"line\">    <span class=\"comment\"># output: (N, C, H', W')</span></span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H - pool_height) // stride </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W - pool_width) // stride</span><br><span class=\"line\">    out = np.zeros((N, C, H_out, W_out))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出点高度和宽度 [h,w]</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">            <span class=\"comment\"># pool对应的输入块</span></span><br><span class=\"line\">            x_pad_block = x[:, :, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]</span><br><span class=\"line\">            <span class=\"comment\"># 最大池化，输出到　[:, :, h, w]</span></span><br><span class=\"line\">            out[:, :, h, w] = np.max(x_pad_block, axis=(<span class=\"number\">-1</span>, <span class=\"number\">-2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    cache = (x, pool_param)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">max_pool_backward_naive</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    x, pool_param = cache</span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># pool region: (heigth, width), stride</span></span><br><span class=\"line\">    pool_height = pool_param[<span class=\"string\">'pool_height'</span>]</span><br><span class=\"line\">    pool_width = pool_param[<span class=\"string\">'pool_width'</span>]</span><br><span class=\"line\">    stride = pool_param[<span class=\"string\">'stride'</span>]</span><br><span class=\"line\">    <span class=\"comment\"># output: (N, C, H', W')</span></span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H - pool_height) // stride </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W - pool_width) // stride</span><br><span class=\"line\">    <span class=\"comment\"># 初始化梯度　dx</span></span><br><span class=\"line\">    dx = np.zeros_like(x)</span><br><span class=\"line\">     </span><br><span class=\"line\">    <span class=\"comment\"># 遍历输入 n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> range(N):</span><br><span class=\"line\">        <span class=\"comment\"># 遍历filter c</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> range(C):</span><br><span class=\"line\">            <span class=\"comment\"># 遍历输出点高度和宽度 [h, w]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">                    <span class=\"comment\"># 当前输出点对应的 pool 输入块</span></span><br><span class=\"line\">                    x_pad_block = x[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]</span><br><span class=\"line\">                    <span class=\"comment\"># Find the index (row, col) of the max value</span></span><br><span class=\"line\">                    <span class=\"comment\"># grads on the max value is exists, else is 0</span></span><br><span class=\"line\">                    index = np.unravel_index(np.argmax(x_pad_block, axis=<span class=\"keyword\">None</span>), (pool_height, pool_width))</span><br><span class=\"line\">                    <span class=\"comment\"># pool对应的输入块各点的梯度</span></span><br><span class=\"line\">                    <span class=\"comment\"># 只有pool输入块中最大值对应的点(索引index)存在梯度，等于dout[n, c, h, w]，其余点梯度为0</span></span><br><span class=\"line\">                    dx[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width][index] = dout[n, c, h, w]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Covolution-Neuro-Network\"><a href=\"#Covolution-Neuro-Network\" class=\"headerlink\" title=\"Covolution Neuro Network\"></a>Covolution Neuro Network</h2><h2 id=\"卷积\"><a href=\"#卷积\" class=\"headerlink\" title=\"卷积\"></a>卷积</h2><p>卷积运算，源于信号处理</p>\n<h4 id=\"感受野，接受域\"><a href=\"#感受野，接受域\" class=\"headerlink\" title=\"感受野，接受域\"></a>感受野，接受域</h4><p><img src=\"/2019/07/01/deep-learning/cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg\" alt=\"img\"></p>\n<p>只受３个输入单元影响，接受域为３，忽略接受域外权重（无限强先验）</p>\n<h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点\"></a>优点</h4><ul>\n<li><p>稀疏交互</p>\n</li>\n<li><p>参数共享，在不同输入位置上使用相同的参数。普通神经网络权重与神经元绑定，需要 $N_l <em> N_{l+1}$ 个参数；卷积神经网络每个权重参数不变，只需要 $k</em>k$ 个参数。</p>\n</li>\n<li>平移不变性，只包含局部连接关系（接受域）</li>\n</ul>\n<p><img src=\"/2019/07/01/deep-learning/cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg\" alt=\"img\"></p>\n<p>96个[11x11x3]滤波器，如果在图像某些地方探测到一个水平的边界是很重要，那么在其他一些地方也会同样是有用的，这是因为图像结构具有平移不变性。</p>\n<p>有的滤波器学习到了条纹，有些学到了色彩差别</p>\n<h4 id=\"CNN\"><a href=\"#CNN\" class=\"headerlink\" title=\"CNN\"></a>CNN</h4><p>输出尺寸：$\\frac{W-F+2P}{S} + 1$</p>\n<ul>\n<li>F: fiter, 卷积核/滤波器/感受野的尺寸，常用3x3, 5x5</li>\n<li>P: padding, 零填充的数量. SAME(输出与输入保持一直，p=F-1/S)，VALID(不填充，输出尺寸减少, p=F/S)</li>\n<li>S: stride, 步长</li>\n</ul>\n<h4 id=\"code\"><a href=\"#code\" class=\"headerlink\" title=\"code\"></a>code</h4><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># forward</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_forward_naive</span><span class=\"params\">(x, w, b, conv_param)</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># input x: N data points, C channels, height H, width W</span></span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># filter w: (F, C, HH, WW)</span></span><br><span class=\"line\">    F, _, HH, WW = w.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    stride, pad = conv_param[<span class=\"string\">'stride'</span>], conv_param[<span class=\"string\">'pad'</span>]</span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H + <span class=\"number\">2</span> * pad - HH) // stride  </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W + <span class=\"number\">2</span> * pad - WW) // stride</span><br><span class=\"line\">    out = np.zeros((N, F, H_out, W_out))</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># ０填充</span></span><br><span class=\"line\">    x_pad = np.pad(x, ((<span class=\"number\">0</span>,), (<span class=\"number\">0</span>,), (pad,), (pad,)), mode=<span class=\"string\">'constant'</span>, constant_values=<span class=\"number\">0</span>)</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># out: (N, F, H', W')  F filters</span></span><br><span class=\"line\">    <span class=\"comment\"># N个输入格式一致，直接在矩阵中操作</span></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出点高度和宽度(h_out, w_out)</span></span><br><span class=\"line\">    <span class=\"comment\"># 输出点从上到下，从左到右移动</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> h_out <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w_out <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">            <span class=\"comment\"># 获得当前卷积核对应的输入块（HH,WW）</span></span><br><span class=\"line\">            x_pad_block = x_pad[:, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]</span><br><span class=\"line\">            <span class=\"comment\"># 计算每个卷积核（滤波器 f）得到的输出，对应点（h_out, w_out)</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> range(F):</span><br><span class=\"line\">                out[:, f, h_out, w_out] = np.sum(x_pad_block * w[f, :, :, :], axis=(<span class=\"number\">1</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>)) + b[f]</span><br><span class=\"line\"></span><br><span class=\"line\">    cache = (x, w, b, conv_param)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># backward</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">conv_backward_naive</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    x, w, b, conv_param = cache</span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    F, _, HH, WW = w.shape</span><br><span class=\"line\">    _, _, H_out, W_out = dout.shape</span><br><span class=\"line\">    stride, pad = conv_param[<span class=\"string\">'stride'</span>], conv_param[<span class=\"string\">'pad'</span>]</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># 0填充　padding</span></span><br><span class=\"line\">    x_pad = np.pad(x, ((<span class=\"number\">0</span>,), (<span class=\"number\">0</span>,), (pad,), (pad,)), mode=<span class=\"string\">'constant'</span>, constant_values=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    dx_pad = np.zeros_like(x_pad)</span><br><span class=\"line\">    dw = np.zeros_like(w)</span><br><span class=\"line\">    db = np.zeros_like(b)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历数据输入n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> range(N):</span><br><span class=\"line\">        <span class=\"comment\"># 遍历 filter f</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> f <span class=\"keyword\">in</span> range(F):</span><br><span class=\"line\">            <span class=\"comment\"># db (N,F)</span></span><br><span class=\"line\">            db[f] += np.sum(dout[n, f])</span><br><span class=\"line\">            <span class=\"comment\"># 遍历输出点高度和宽度　[h,w]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> h_out <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> w_out <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">                    <span class=\"comment\"># 获得当前卷积核f对应的输入块（HH,WW）</span></span><br><span class=\"line\">                    x_pad_block = x_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW]</span><br><span class=\"line\">                    <span class=\"comment\"># dw (F,)</span></span><br><span class=\"line\">                    dw[f, :, :, :] += x_pad_block * dout[n, f, h_out, w_out]</span><br><span class=\"line\">                    dx_pad[n, :, h_out*stride:h_out*stride+HH, w_out*stride:w_out*stride+WW] += \\</span><br><span class=\"line\">                        w[f, :, :, :] * dout[n, f, h_out, w_out]</span><br><span class=\"line\"></span><br><span class=\"line\">    dx = dx_pad[:, :, pad:pad+H, pad:pad+W]</span><br><span class=\"line\">\t</span><br><span class=\"line\">    <span class=\"comment\"># return Gradients: dx, dw, db</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx, dw, db</span><br></pre></td></tr></table></figure>\n<p><em>卷积层是如何解决不同大小输入的问题 ???</em></p>\n<h2 id=\"池化\"><a href=\"#池化\" class=\"headerlink\" title=\"池化\"></a>池化</h2><h4 id=\"特点\"><a href=\"#特点\" class=\"headerlink\" title=\"特点\"></a>特点</h4><ul>\n<li>局部平移不变性：关心某个特征是否出现，不关心出现的具体位置　（无限强先验）</li>\n<li>降采样：下一层少了 k 倍输入</li>\n<li>综合池化区域(pool)的 k*k 个像素的统计特征</li>\n<li>处理不同大小的输入，输出相同数量的统计特征</li>\n</ul>\n<p>最大池化 pool (2, 2)，步长 stride 2，输出大小减半</p>\n<p><img src=\"/2019/07/01/deep-learning/cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">max_pool_forward_naive</span><span class=\"params\">(x, pool_param)</span>:</span> </span><br><span class=\"line\">    <span class=\"comment\"># input x: (N, C, H, W)</span></span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># pool region: (heigth, width), stride</span></span><br><span class=\"line\">    pool_height = pool_param[<span class=\"string\">'pool_height'</span>]</span><br><span class=\"line\">    pool_width = pool_param[<span class=\"string\">'pool_width'</span>]</span><br><span class=\"line\">    stride = pool_param[<span class=\"string\">'stride'</span>]</span><br><span class=\"line\">    <span class=\"comment\"># output: (N, C, H', W')</span></span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H - pool_height) // stride </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W - pool_width) // stride</span><br><span class=\"line\">    out = np.zeros((N, C, H_out, W_out))</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># 遍历输出点高度和宽度 [h,w]</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">        <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">            <span class=\"comment\"># pool对应的输入块</span></span><br><span class=\"line\">            x_pad_block = x[:, :, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]</span><br><span class=\"line\">            <span class=\"comment\"># 最大池化，输出到　[:, :, h, w]</span></span><br><span class=\"line\">            out[:, :, h, w] = np.max(x_pad_block, axis=(<span class=\"number\">-1</span>, <span class=\"number\">-2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\">    cache = (x, pool_param)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">max_pool_backward_naive</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    x, pool_param = cache</span><br><span class=\"line\">    N, C, H, W = x.shape</span><br><span class=\"line\">    <span class=\"comment\"># pool region: (heigth, width), stride</span></span><br><span class=\"line\">    pool_height = pool_param[<span class=\"string\">'pool_height'</span>]</span><br><span class=\"line\">    pool_width = pool_param[<span class=\"string\">'pool_width'</span>]</span><br><span class=\"line\">    stride = pool_param[<span class=\"string\">'stride'</span>]</span><br><span class=\"line\">    <span class=\"comment\"># output: (N, C, H', W')</span></span><br><span class=\"line\">    H_out = <span class=\"number\">1</span> + (H - pool_height) // stride </span><br><span class=\"line\">    W_out = <span class=\"number\">1</span> + (W - pool_width) // stride</span><br><span class=\"line\">    <span class=\"comment\"># 初始化梯度　dx</span></span><br><span class=\"line\">    dx = np.zeros_like(x)</span><br><span class=\"line\">     </span><br><span class=\"line\">    <span class=\"comment\"># 遍历输入 n</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> n <span class=\"keyword\">in</span> range(N):</span><br><span class=\"line\">        <span class=\"comment\"># 遍历filter c</span></span><br><span class=\"line\">        <span class=\"keyword\">for</span> c <span class=\"keyword\">in</span> range(C):</span><br><span class=\"line\">            <span class=\"comment\"># 遍历输出点高度和宽度 [h, w]</span></span><br><span class=\"line\">            <span class=\"keyword\">for</span> h <span class=\"keyword\">in</span> range(H_out):</span><br><span class=\"line\">                <span class=\"keyword\">for</span> w <span class=\"keyword\">in</span> range(W_out):</span><br><span class=\"line\">                    <span class=\"comment\"># 当前输出点对应的 pool 输入块</span></span><br><span class=\"line\">                    x_pad_block = x[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width]</span><br><span class=\"line\">                    <span class=\"comment\"># Find the index (row, col) of the max value</span></span><br><span class=\"line\">                    <span class=\"comment\"># grads on the max value is exists, else is 0</span></span><br><span class=\"line\">                    index = np.unravel_index(np.argmax(x_pad_block, axis=<span class=\"keyword\">None</span>), (pool_height, pool_width))</span><br><span class=\"line\">                    <span class=\"comment\"># pool对应的输入块各点的梯度</span></span><br><span class=\"line\">                    <span class=\"comment\"># 只有pool输入块中最大值对应的点(索引index)存在梯度，等于dout[n, c, h, w]，其余点梯度为0</span></span><br><span class=\"line\">                    dx[n, c, h*stride:h*stride+pool_height, w*stride:w*stride+pool_width][index] = dout[n, c, h, w]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx</span><br></pre></td></tr></table></figure>\n"},{"title":"Decistion Tree","date":"2019-01-31T12:33:05.000Z","mathjax":true,"_content":"\n## Part 4. 决策树\n\n--------\n\n\n\nDecision Tree　树形结构，根据损失函数最小化原则建立决策树模型\n\n![1548939696690](decision-tree/tree_basic.png)\n\nif-then规则集合，每一条路径构建一条规则\n\n- 内部节点：特征/属性，规则的条件\n\n- 叶节点：　类，规则的结论\n\n条件概率分布\n\n将特征空间划分为互不相交的单元（cell）或区域（region）\n\n$P(Y=+1|X=c)>0.5$, 单元cell　属于正类\n\n\n\n![1548940003249](decision-tree/feature-space.png)\n\n![1548940132559](decision-tree/1548940132559.png)\n\n![1548940093157](decision-tree/1548940093157.png)\n\n\n\n","source":"_posts/machine-learning/decision-tree.md","raw":"---\ntitle: Decistion Tree\ndate: 2019-01-31 20:33:05\nmathjax: true\ncategories:\n  - ml\ntag: \n  - ml\n  - hexo-asset-image\n---\n\n## Part 4. 决策树\n\n--------\n\n\n\nDecision Tree　树形结构，根据损失函数最小化原则建立决策树模型\n\n![1548939696690](decision-tree/tree_basic.png)\n\nif-then规则集合，每一条路径构建一条规则\n\n- 内部节点：特征/属性，规则的条件\n\n- 叶节点：　类，规则的结论\n\n条件概率分布\n\n将特征空间划分为互不相交的单元（cell）或区域（region）\n\n$P(Y=+1|X=c)>0.5$, 单元cell　属于正类\n\n\n\n![1548940003249](decision-tree/feature-space.png)\n\n![1548940132559](decision-tree/1548940132559.png)\n\n![1548940093157](decision-tree/1548940093157.png)\n\n\n\n","slug":"machine-learning/decision-tree","published":1,"updated":"2019-06-20T16:07:57.003Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdapx0008u09o63k4cdc4","content":"<h2 id=\"Part-4-决策树\"><a href=\"#Part-4-决策树\" class=\"headerlink\" title=\"Part 4. 决策树\"></a>Part 4. 决策树</h2><hr>\n<p>Decision Tree　树形结构，根据损失函数最小化原则建立决策树模型</p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/tree_basic.png\" alt=\"1548939696690\"></p>\n<p>if-then规则集合，每一条路径构建一条规则</p>\n<ul>\n<li><p>内部节点：特征/属性，规则的条件</p>\n</li>\n<li><p>叶节点：　类，规则的结论</p>\n</li>\n</ul>\n<p>条件概率分布</p>\n<p>将特征空间划分为互不相交的单元（cell）或区域（region）</p>\n<p>$P(Y=+1|X=c)&gt;0.5$, 单元cell　属于正类</p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/feature-space.png\" alt=\"1548940003249\"></p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/1548940132559.png\" alt=\"1548940132559\"></p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/1548940093157.png\" alt=\"1548940093157\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Part-4-决策树\"><a href=\"#Part-4-决策树\" class=\"headerlink\" title=\"Part 4. 决策树\"></a>Part 4. 决策树</h2><hr>\n<p>Decision Tree　树形结构，根据损失函数最小化原则建立决策树模型</p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/tree_basic.png\" alt=\"1548939696690\"></p>\n<p>if-then规则集合，每一条路径构建一条规则</p>\n<ul>\n<li><p>内部节点：特征/属性，规则的条件</p>\n</li>\n<li><p>叶节点：　类，规则的结论</p>\n</li>\n</ul>\n<p>条件概率分布</p>\n<p>将特征空间划分为互不相交的单元（cell）或区域（region）</p>\n<p>$P(Y=+1|X=c)&gt;0.5$, 单元cell　属于正类</p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/feature-space.png\" alt=\"1548940003249\"></p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/1548940132559.png\" alt=\"1548940132559\"></p>\n<p><img src=\"/2019/01/31/machine-learning/decision-tree/1548940093157.png\" alt=\"1548940093157\"></p>\n"},{"title":"无偏估计和有偏估计","date":"2019-04-29T14:43:59.501Z","_content":"\n","source":"_posts/statitics/estimate.md","raw":"---\ntitle: 无偏估计和有偏估计\ndate: \ncategories:\n  - \ntag: \n  - statistics\n---\n\n","slug":"statitics/estimate","published":1,"updated":"2019-04-29T14:43:59.501Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdapz000bu09o5pbeavbz","content":"","site":{"data":{}},"excerpt":"","more":""},{"_content":"","source":"_posts/statitics/entropy.md","raw":"","slug":"statitics/entropy","published":1,"date":"2019-07-22T14:04:54.451Z","updated":"2019-07-22T14:04:54.451Z","_id":"cjyegdaq1000cu09o0b5fsndl","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"_content":"","source":"_posts/deep-learning/dropout.md","raw":"","slug":"deep-learning/dropout","published":1,"date":"2019-07-22T14:03:46.851Z","updated":"2019-07-22T14:03:46.851Z","_id":"cjyegdarl0017u09oa91owa4f","title":"","comments":1,"layout":"post","photos":[],"link":"","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Dropout","date":"2019-06-16T16:00:00.000Z","mathjax":true,"_content":"Optimization\n-------------\n\n- [Optimization](#Optimization)\n- [损失函数](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0)\n    - [损失函数 Loss function / 代价函数 Cost function](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-Loss-function--%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0-Cost-function)\n    - [均方损失](#%E5%9D%87%E6%96%B9%E6%8D%9F%E5%A4%B1)\n    - [交叉熵损失（cross-entropy loss)](#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1cross-entropy-loss)\n    - [Softmax 函数](#Softmax-%E5%87%BD%E6%95%B0)\n    - [损失函数可视化](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96)\n- [梯度下降](#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)\n    - [全局梯度下降　Batch Gradient Descent](#%E5%85%A8%E5%B1%80%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Batch-Gradient-Descent)\n    - [随机梯度下降SGD　Stochastic Gradient Descent](#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DSGD-Stochastic-Gradient-Descent)\n    - [小批量梯度下降　Ｍini-batch Gradient Descent](#%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%EF%BC%ADini-batch-Gradient-Descent)\n    - [Challange](#Challange)\n- [优化算法](#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)\n    - [牛顿法](#%E7%89%9B%E9%A1%BF%E6%B3%95)\n    - [BFGS, L-BFGS](#BFGS-L-BFGS)\n    - [梯度衰减(模拟退火)](#%E6%A2%AF%E5%BA%A6%E8%A1%B0%E5%87%8F%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB)\n    - [Ｍomentum](#%EF%BC%ADomentum)\n    - [NAG Neterov Accelerated Gradient](#NAG-Neterov-Accelerated-Gradient)\n    - [Adagrad](#Adagrad)\n    - [Adadelta](#Adadelta)\n    - [RMSProp](#RMSProp)\n    - [Adam](#Adam)\n    - [Nadam](#Nadam)\n  - [各种优化方法动态图](#%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%8A%A8%E6%80%81%E5%9B%BE)\n\n\n## 损失函数\n\n#### 损失函数 Loss function / 代价函数 Cost function\n\n![img](optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png)\n\n#### 均方损失\n\n$$L(x)=\\sum_{i}(y_i - y_j)^2$$\n\n#### 交叉熵损失（cross-entropy loss)\n\n$$L(x)=\\sum_{i}p_i\\log \\frac{1}{q_i}$$\n\n交叉熵作为代价函数可以避免均方代价函数带来的学习减速(nelson)\n\n#### Softmax 函数\n\n![1561034699845](optimization/1561034699845.png)\n\n$$y_i=\\frac{e^{z_i}}{\\sum_{i}{e^{z_i}}}$$\n\nSoftmax 分类器为每一个分类都提供了“可能性（概率）”\n\n输出值$z_i$ => 概率$y_i$\n\n**决策函数**：$$\\hat{y}=argmax_{i}(y=y_i|Z)$$  (y所属类别$\\hat{y}$)\n\n#### 损失函数可视化\n\n颜色越深，损失函数越小\n\n\n![img](optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png)\n\n\n## 梯度下降\n\n损失函数 L 的 3D 图：\n\n![1561035128653](optimization/1561035128653.png)\n\nGradient: 损失函数 L 在某一点的梯度（斜率，一阶导数）\n\n![1561035151992](optimization/1561035151992.png)\n\n![preview](optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg)\n\n梯度下降法：某一点沿着斜坡在当前点梯度最大的方向($f'(x)​$)移动一个步长(learning rate)，在下一次更新中就会更接近最小点。\n\n$$w = w - \\eta dw$$\n\n\n\n![img](optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg)\n\n白箭头为（负梯度方向），是损失函数下降最陡峭的方向。沿着梯度方向逐步下降更新参数，就是深度学习中的梯度下降学习方法。\n\n![1561186124221](optimization/1561186124221.png)\n\n\n#### 全局梯度下降　Batch Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta)$$\n\n优点：保证每次更新梯度都朝着正确的方向进行，保证收敛到局部最小点\n\n缺点：每次需计算整个训练集数据，成本比较高\n\n#### 随机梯度下降SGD　Stochastic Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_i,y_i)$$\n\n优点：每次只选择一个样本来学习，成本低，可以进行在线更新; 不容易陷入某个局部\n\n缺点：优化过程中波动较大，收敛速度慢；可能在沟壑两边持续震荡，停留在一个局部最优点\n\n#### 小批量梯度下降　Ｍini-batch Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_{i:i+n},y_{i,i+n})$$\n\nn的大小通常为50-256\n\n优点：相对于随机梯度下降(SGD)，降低收敛波动性（降低参数更新的方差），使得收敛过程更加稳定。相对于全量梯度下降，提高了每次学习的速度。\n\n#### Challange\n\n- **学习速率**的选择，过小则收敛很慢，过大则在极值点附近震荡\n- 学习速率调整（模拟退火）一般使用事先设定的策略或者每次迭代中衰减一个阈值。都需要事先固定设置，无法**自适应**数据集的特点\n- 所有的**参数每次更新都使用相同的学习速率**。如果数据特征稀疏或者取值空间分布不同，就不应该使用同样的学习速率，对于很少出现的特征应该使用一个较大的学习速率\n- 对于非凸损失函数，容易陷入局部最小点，更严重的问题在于**鞍点**，附近点的梯度在所有维度上都接近于０\n\n## 优化算法\n\n#### 牛顿法\n\n$x = x -[Hf(x)]^{-1}\\nabla f(x)$\n\n$Hf(x)$: Hessian 矩阵，描述损失函数的局部曲率\n\n$[Hf(x)]^{-1}$让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进\n\n而且，没有学习率这个超参数\n\n但是，Hessian矩阵计算成本很高\n\n#### BFGS, L-BFGS\n\n\n\n#### 梯度衰减(模拟退火)\n\n- 随步数减半：没５个周期减半，每20个周期减少到之前0.1\n\n- 指数衰减：$\\alpha=\\alpha_{0}e^{-kt}$\n- 1/t衰减：$\\alpha=\\frac{\\alpha_0}{1+kt}$\n\n#### Ｍomentum\n\n累积之前的下降方向，并略微偏向当前时刻的下降方向\n\n![1561186187105](optimization/1561186187105.png)\n\n引入动量，**累积之前的动量(梯度的指数衰减)**，速度越来越快。\n\n$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$$\n\n$$\\theta = \\theta - v_t$$\n\n$$\\gamma$$通常使用0.9\n\n\n\n加上动量后，就像从山顶往下滚的球。更新过程中，与上一次梯度方向相同的参数更新加强，在这个方向下降更快；与上一次梯度方向不同的参数更新减弱，在这个方向下降减慢。因此获得更快的收敛速度并减少震荡。\n\n![1561196522519](optimization/1561196522519.png)\n\n#### NAG Neterov Accelerated Gradient\n\n往标准动量方法添加一个修正因子(当前梯度衰减$\\eta v_{t-1}$)，阻止过快更新\n\n$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta-\\gamma v_{t-1})$$\n\n$$\\theta = \\theta - v_t$$\n\n\n\n![SGD fluctuation](optimization/nesterov_update_vector.png)\n\n核心思路：\n\n当参数向量位于某个位置ｘ时，动量部分衰减$\\gamma v_{t-1}$，向前一步$\\theta-\\gamma v_{t-1}$得到下一步要到达的位置，**向前看**在**下一步**的位置计算梯度。![img](optimization/412afb713ddcff0ba9165ab026563304_hd.png)\n\n```python\nx_ahead = x + mu * v\n# 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)\nv = mu * v - learning_rate * dx_ahead\nx += v\n```\n\n**通过上面的两种方法，可以做到每次学习过程中能够根据损失函数的斜率做到自适应更新来加速SGD的收敛**。\n\n接下来引入二阶动量，希望同时解决**不同参数应该使用不同学习速率的问题**。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。\n\n怎么样去度量历史更新频率呢？\n\n那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：\n\n$$V_t=\\sum_{\\tau=1}^{t} g_{\\tau}^2$$\n\n#### Adagrad\n\n**累积平方梯度**\n\n$$g_{t} = \\nabla_{\\theta} J(\\theta)$$\n\n$$r=r + g \\odot g$$\n\n$$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{r+\\epsilon}}\\odot g$$\n\n优点：\n\n- 适合处理稀疏梯度。自适应不同的学习速率，对稀疏特征，得到更大的学习更新；对非稀疏特征，得到更小的学习更新　　特征出现越多，累积平方梯度ｒ越大，分母$\\sqrt{r+\\epsilon}$越大，更新越慢\n\n- 前期$g_t$较小，校正因子较大，能够放大梯度，累积势越小，更新越快\n\n- 后期$g_t$较大，校正因子较大，能够约束梯度，累积势越大，更新越慢\n\n缺点：\n\n- 依赖学习速率\n- 学习速率$\\eta$不能过大，否则导致对梯度调节过大\n- 单调的学习率被证明通常**过于激进且过早停止学习**。后期如果梯度的平方累积($r$)过大，导致更新很小，接近于０，使得训练提前结束\n\n由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。\n\n引入指数移动平均值：\n\n$$r_t=\\gamma r_{t-1}+(1-\\gamma)g_{t}^2$$\n\n#### Adadelta\n\n对Adagrad的扩展\n\n$$g_{t} = \\nabla_{\\theta} J(\\theta)$$\n\n$$r=\\gamma r + (1-\\gamma) g \\odot g$$\n\n$$g'_t=\\sqrt{\\frac{\\Delta x_{t-1} +\\epsilon}{r+\\epsilon}}\\odot g$$                   # 使用**状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$**\n\n$$\\theta_{t+1}=\\theta_{t}-g'_t$$\n\n$$\\Delta x_t=\\gamma \\Delta x_{t-1}+(1-\\gamma)g'_t\\odot g'_t $$   # 使用$\\Delta x_{t-1}$记录自变量变化量$g′_t$按元素平方的指数加权移动平均\n\n优点：\n\n- 不再依赖学习率，使用梯度平方的指数加权累积得到状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$\n- 训练初中期，加速效果好\n- 训练后期，反复在局部最小值附近抖动\n\n#### RMSProp\n\n**累积指数加权的平方梯度**\n\n$$E[g^2]_t=\\gamma E[g^2]_{t-1}+(1-\\gamma)g_t^2$$          # 梯度平方的滑动平均\n\n$$\\theta_{t-1}=\\theta_{t} - \\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\\odot g_t$$\n\n$\\gamma=0.9, \\eta=0.001$\n\n\n\n- RMSProp 是 Adagrad 的一种发展，和 Adadelta 的变体，效果趋于二者之间，**降低了 Adagrad 中学习速率衰减过快**的问题\n- 适合处理非平稳目标（RNN）\n\n接下来，整合前面所有方法，就得到 Adam。SGD-Momentum 在 SGD 的基础上增加了一阶动量，AdaGrad 和 AdaDelta 在 SGD 的基础上增加了二阶动量。结合一阶动量和二阶动量，就是 Adam (Adaptive+Momentum). 再加上 Neterov，就是 Nadam。\n\n#### Adam\n\nAdaptive Moment Estimation(Adam)\n\n**累积指数加权的梯度和平方梯度**\n\n$$m_t=\\beta_1 m_{t-1} + (1-\\beta_1)g_t$$   # 一阶累积\n\n$$r_t = \\beta_2 r_{t-1} + (1-\\beta_2)g_{t}^2$$　　# 二阶累积\n\n$$\\hat{m_t}=\\frac{m_t}{1-\\beta_1^t}$$　　　　　　　　　# 校正因子，$m_t$接近与０(初始0, $\\beta$ 接近１)\n\n$$\\hat{v_t}=\\frac{v_t}{1-\\beta_2^t}$$\n\n$$\\theta_{t+1}=\\theta_t - \\eta\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t} + \\epsilon}}$$\n\n$\\beta_1=0.9,\\beta_2=0.999,\\epsilon=10^{-8}$\n\n#### Nadam\n\n$$g_t=\\nabla_{\\theta_t} J(\\theta_t - m_t)$$\n\n\n\n优点：\n\n- 结合 Adagrad 善于处理稀疏梯度和 RMSProp 善于处理非平稳目标的问题\n- 适用于大数据集和高维空间\n\n缺点：\n\n- 二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得 ![[公式]](optimization/equation.svg) 可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。\n- 可能错过全局最优解\n\n\n\n*cs231n: The two recommended updates to use are either SGD+Nesterov Momentum or Adam*\n\n### 各种优化方法动态图\n\n![SGD without momentum](http://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif)\n\n Adagrad、Adadelta与RMSprop在损失曲面上能够立即转移到正确的移动方向上达到快速的收敛。而Momentum 与NAG会导致偏离(off-track)。同时NAG能够在偏离之后快速修正其路线，因为其根据梯度修正来提高响应性\n\n![saddle_point_evaluation_optimizers](optimization/20160909001936276)\n\n从上图可以看出，在鞍点（saddle points）处(即某些维度上梯度为零，某些维度上梯度不为零)，SGD、Momentum与NAG一直在鞍点梯度为零的方向上振荡，很难打破鞍点位置的对称性；Adagrad、RMSprop与Adadelta能够很快地向梯度不为零的方向上转移。\n   从上面两幅图可以看出，自适应学习速率方法(Adagrad、Adadelta、RMSprop与Adam)在这些场景下具有更好的收敛速度与收敛性。\n\n\n\nReferences:\n\n1. [An overview of gradient descent optimization algorithms](<http://ruder.io/optimizing-gradient-descent/index.html>)\n2. [梯度下降优化算法综述(1的翻译)](<https://blog.csdn.net/heyongluoyao8/article/details/52478715>)\n3. [一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - Juliuszh的文章 - 知乎](\n   https://zhuanlan.zhihu.com/p/32230623)\n\n","source":"_posts/deep-learning/optimization.md","raw":"---\ntitle: Dropout\ndate: 2019-06-17\nmathjax: true\ncategories:\n  - dl\ntag:\n  - dl\n  - hexo-asset-image\n---\nOptimization\n-------------\n\n- [Optimization](#Optimization)\n- [损失函数](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0)\n    - [损失函数 Loss function / 代价函数 Cost function](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-Loss-function--%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0-Cost-function)\n    - [均方损失](#%E5%9D%87%E6%96%B9%E6%8D%9F%E5%A4%B1)\n    - [交叉熵损失（cross-entropy loss)](#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1cross-entropy-loss)\n    - [Softmax 函数](#Softmax-%E5%87%BD%E6%95%B0)\n    - [损失函数可视化](#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96)\n- [梯度下降](#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D)\n    - [全局梯度下降　Batch Gradient Descent](#%E5%85%A8%E5%B1%80%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Batch-Gradient-Descent)\n    - [随机梯度下降SGD　Stochastic Gradient Descent](#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DSGD-Stochastic-Gradient-Descent)\n    - [小批量梯度下降　Ｍini-batch Gradient Descent](#%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%EF%BC%ADini-batch-Gradient-Descent)\n    - [Challange](#Challange)\n- [优化算法](#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95)\n    - [牛顿法](#%E7%89%9B%E9%A1%BF%E6%B3%95)\n    - [BFGS, L-BFGS](#BFGS-L-BFGS)\n    - [梯度衰减(模拟退火)](#%E6%A2%AF%E5%BA%A6%E8%A1%B0%E5%87%8F%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB)\n    - [Ｍomentum](#%EF%BC%ADomentum)\n    - [NAG Neterov Accelerated Gradient](#NAG-Neterov-Accelerated-Gradient)\n    - [Adagrad](#Adagrad)\n    - [Adadelta](#Adadelta)\n    - [RMSProp](#RMSProp)\n    - [Adam](#Adam)\n    - [Nadam](#Nadam)\n  - [各种优化方法动态图](#%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%8A%A8%E6%80%81%E5%9B%BE)\n\n\n## 损失函数\n\n#### 损失函数 Loss function / 代价函数 Cost function\n\n![img](optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png)\n\n#### 均方损失\n\n$$L(x)=\\sum_{i}(y_i - y_j)^2$$\n\n#### 交叉熵损失（cross-entropy loss)\n\n$$L(x)=\\sum_{i}p_i\\log \\frac{1}{q_i}$$\n\n交叉熵作为代价函数可以避免均方代价函数带来的学习减速(nelson)\n\n#### Softmax 函数\n\n![1561034699845](optimization/1561034699845.png)\n\n$$y_i=\\frac{e^{z_i}}{\\sum_{i}{e^{z_i}}}$$\n\nSoftmax 分类器为每一个分类都提供了“可能性（概率）”\n\n输出值$z_i$ => 概率$y_i$\n\n**决策函数**：$$\\hat{y}=argmax_{i}(y=y_i|Z)$$  (y所属类别$\\hat{y}$)\n\n#### 损失函数可视化\n\n颜色越深，损失函数越小\n\n\n![img](optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png)\n\n\n## 梯度下降\n\n损失函数 L 的 3D 图：\n\n![1561035128653](optimization/1561035128653.png)\n\nGradient: 损失函数 L 在某一点的梯度（斜率，一阶导数）\n\n![1561035151992](optimization/1561035151992.png)\n\n![preview](optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg)\n\n梯度下降法：某一点沿着斜坡在当前点梯度最大的方向($f'(x)​$)移动一个步长(learning rate)，在下一次更新中就会更接近最小点。\n\n$$w = w - \\eta dw$$\n\n\n\n![img](optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg)\n\n白箭头为（负梯度方向），是损失函数下降最陡峭的方向。沿着梯度方向逐步下降更新参数，就是深度学习中的梯度下降学习方法。\n\n![1561186124221](optimization/1561186124221.png)\n\n\n#### 全局梯度下降　Batch Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta)$$\n\n优点：保证每次更新梯度都朝着正确的方向进行，保证收敛到局部最小点\n\n缺点：每次需计算整个训练集数据，成本比较高\n\n#### 随机梯度下降SGD　Stochastic Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_i,y_i)$$\n\n优点：每次只选择一个样本来学习，成本低，可以进行在线更新; 不容易陷入某个局部\n\n缺点：优化过程中波动较大，收敛速度慢；可能在沟壑两边持续震荡，停留在一个局部最优点\n\n#### 小批量梯度下降　Ｍini-batch Gradient Descent\n\n$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_{i:i+n},y_{i,i+n})$$\n\nn的大小通常为50-256\n\n优点：相对于随机梯度下降(SGD)，降低收敛波动性（降低参数更新的方差），使得收敛过程更加稳定。相对于全量梯度下降，提高了每次学习的速度。\n\n#### Challange\n\n- **学习速率**的选择，过小则收敛很慢，过大则在极值点附近震荡\n- 学习速率调整（模拟退火）一般使用事先设定的策略或者每次迭代中衰减一个阈值。都需要事先固定设置，无法**自适应**数据集的特点\n- 所有的**参数每次更新都使用相同的学习速率**。如果数据特征稀疏或者取值空间分布不同，就不应该使用同样的学习速率，对于很少出现的特征应该使用一个较大的学习速率\n- 对于非凸损失函数，容易陷入局部最小点，更严重的问题在于**鞍点**，附近点的梯度在所有维度上都接近于０\n\n## 优化算法\n\n#### 牛顿法\n\n$x = x -[Hf(x)]^{-1}\\nabla f(x)$\n\n$Hf(x)$: Hessian 矩阵，描述损失函数的局部曲率\n\n$[Hf(x)]^{-1}$让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进\n\n而且，没有学习率这个超参数\n\n但是，Hessian矩阵计算成本很高\n\n#### BFGS, L-BFGS\n\n\n\n#### 梯度衰减(模拟退火)\n\n- 随步数减半：没５个周期减半，每20个周期减少到之前0.1\n\n- 指数衰减：$\\alpha=\\alpha_{0}e^{-kt}$\n- 1/t衰减：$\\alpha=\\frac{\\alpha_0}{1+kt}$\n\n#### Ｍomentum\n\n累积之前的下降方向，并略微偏向当前时刻的下降方向\n\n![1561186187105](optimization/1561186187105.png)\n\n引入动量，**累积之前的动量(梯度的指数衰减)**，速度越来越快。\n\n$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$$\n\n$$\\theta = \\theta - v_t$$\n\n$$\\gamma$$通常使用0.9\n\n\n\n加上动量后，就像从山顶往下滚的球。更新过程中，与上一次梯度方向相同的参数更新加强，在这个方向下降更快；与上一次梯度方向不同的参数更新减弱，在这个方向下降减慢。因此获得更快的收敛速度并减少震荡。\n\n![1561196522519](optimization/1561196522519.png)\n\n#### NAG Neterov Accelerated Gradient\n\n往标准动量方法添加一个修正因子(当前梯度衰减$\\eta v_{t-1}$)，阻止过快更新\n\n$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta-\\gamma v_{t-1})$$\n\n$$\\theta = \\theta - v_t$$\n\n\n\n![SGD fluctuation](optimization/nesterov_update_vector.png)\n\n核心思路：\n\n当参数向量位于某个位置ｘ时，动量部分衰减$\\gamma v_{t-1}$，向前一步$\\theta-\\gamma v_{t-1}$得到下一步要到达的位置，**向前看**在**下一步**的位置计算梯度。![img](optimization/412afb713ddcff0ba9165ab026563304_hd.png)\n\n```python\nx_ahead = x + mu * v\n# 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)\nv = mu * v - learning_rate * dx_ahead\nx += v\n```\n\n**通过上面的两种方法，可以做到每次学习过程中能够根据损失函数的斜率做到自适应更新来加速SGD的收敛**。\n\n接下来引入二阶动量，希望同时解决**不同参数应该使用不同学习速率的问题**。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。\n\n怎么样去度量历史更新频率呢？\n\n那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：\n\n$$V_t=\\sum_{\\tau=1}^{t} g_{\\tau}^2$$\n\n#### Adagrad\n\n**累积平方梯度**\n\n$$g_{t} = \\nabla_{\\theta} J(\\theta)$$\n\n$$r=r + g \\odot g$$\n\n$$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{r+\\epsilon}}\\odot g$$\n\n优点：\n\n- 适合处理稀疏梯度。自适应不同的学习速率，对稀疏特征，得到更大的学习更新；对非稀疏特征，得到更小的学习更新　　特征出现越多，累积平方梯度ｒ越大，分母$\\sqrt{r+\\epsilon}$越大，更新越慢\n\n- 前期$g_t$较小，校正因子较大，能够放大梯度，累积势越小，更新越快\n\n- 后期$g_t$较大，校正因子较大，能够约束梯度，累积势越大，更新越慢\n\n缺点：\n\n- 依赖学习速率\n- 学习速率$\\eta$不能过大，否则导致对梯度调节过大\n- 单调的学习率被证明通常**过于激进且过早停止学习**。后期如果梯度的平方累积($r$)过大，导致更新很小，接近于０，使得训练提前结束\n\n由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。\n\n引入指数移动平均值：\n\n$$r_t=\\gamma r_{t-1}+(1-\\gamma)g_{t}^2$$\n\n#### Adadelta\n\n对Adagrad的扩展\n\n$$g_{t} = \\nabla_{\\theta} J(\\theta)$$\n\n$$r=\\gamma r + (1-\\gamma) g \\odot g$$\n\n$$g'_t=\\sqrt{\\frac{\\Delta x_{t-1} +\\epsilon}{r+\\epsilon}}\\odot g$$                   # 使用**状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$**\n\n$$\\theta_{t+1}=\\theta_{t}-g'_t$$\n\n$$\\Delta x_t=\\gamma \\Delta x_{t-1}+(1-\\gamma)g'_t\\odot g'_t $$   # 使用$\\Delta x_{t-1}$记录自变量变化量$g′_t$按元素平方的指数加权移动平均\n\n优点：\n\n- 不再依赖学习率，使用梯度平方的指数加权累积得到状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$\n- 训练初中期，加速效果好\n- 训练后期，反复在局部最小值附近抖动\n\n#### RMSProp\n\n**累积指数加权的平方梯度**\n\n$$E[g^2]_t=\\gamma E[g^2]_{t-1}+(1-\\gamma)g_t^2$$          # 梯度平方的滑动平均\n\n$$\\theta_{t-1}=\\theta_{t} - \\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\\odot g_t$$\n\n$\\gamma=0.9, \\eta=0.001$\n\n\n\n- RMSProp 是 Adagrad 的一种发展，和 Adadelta 的变体，效果趋于二者之间，**降低了 Adagrad 中学习速率衰减过快**的问题\n- 适合处理非平稳目标（RNN）\n\n接下来，整合前面所有方法，就得到 Adam。SGD-Momentum 在 SGD 的基础上增加了一阶动量，AdaGrad 和 AdaDelta 在 SGD 的基础上增加了二阶动量。结合一阶动量和二阶动量，就是 Adam (Adaptive+Momentum). 再加上 Neterov，就是 Nadam。\n\n#### Adam\n\nAdaptive Moment Estimation(Adam)\n\n**累积指数加权的梯度和平方梯度**\n\n$$m_t=\\beta_1 m_{t-1} + (1-\\beta_1)g_t$$   # 一阶累积\n\n$$r_t = \\beta_2 r_{t-1} + (1-\\beta_2)g_{t}^2$$　　# 二阶累积\n\n$$\\hat{m_t}=\\frac{m_t}{1-\\beta_1^t}$$　　　　　　　　　# 校正因子，$m_t$接近与０(初始0, $\\beta$ 接近１)\n\n$$\\hat{v_t}=\\frac{v_t}{1-\\beta_2^t}$$\n\n$$\\theta_{t+1}=\\theta_t - \\eta\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t} + \\epsilon}}$$\n\n$\\beta_1=0.9,\\beta_2=0.999,\\epsilon=10^{-8}$\n\n#### Nadam\n\n$$g_t=\\nabla_{\\theta_t} J(\\theta_t - m_t)$$\n\n\n\n优点：\n\n- 结合 Adagrad 善于处理稀疏梯度和 RMSProp 善于处理非平稳目标的问题\n- 适用于大数据集和高维空间\n\n缺点：\n\n- 二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得 ![[公式]](optimization/equation.svg) 可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。\n- 可能错过全局最优解\n\n\n\n*cs231n: The two recommended updates to use are either SGD+Nesterov Momentum or Adam*\n\n### 各种优化方法动态图\n\n![SGD without momentum](http://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif)\n\n Adagrad、Adadelta与RMSprop在损失曲面上能够立即转移到正确的移动方向上达到快速的收敛。而Momentum 与NAG会导致偏离(off-track)。同时NAG能够在偏离之后快速修正其路线，因为其根据梯度修正来提高响应性\n\n![saddle_point_evaluation_optimizers](optimization/20160909001936276)\n\n从上图可以看出，在鞍点（saddle points）处(即某些维度上梯度为零，某些维度上梯度不为零)，SGD、Momentum与NAG一直在鞍点梯度为零的方向上振荡，很难打破鞍点位置的对称性；Adagrad、RMSprop与Adadelta能够很快地向梯度不为零的方向上转移。\n   从上面两幅图可以看出，自适应学习速率方法(Adagrad、Adadelta、RMSprop与Adam)在这些场景下具有更好的收敛速度与收敛性。\n\n\n\nReferences:\n\n1. [An overview of gradient descent optimization algorithms](<http://ruder.io/optimizing-gradient-descent/index.html>)\n2. [梯度下降优化算法综述(1的翻译)](<https://blog.csdn.net/heyongluoyao8/article/details/52478715>)\n3. [一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - Juliuszh的文章 - 知乎](\n   https://zhuanlan.zhihu.com/p/32230623)\n\n","slug":"deep-learning/optimization","published":1,"updated":"2019-07-01T17:32:15.314Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdarm0018u09oy7tx6efx","content":"<h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><ul>\n<li><a href=\"#Optimization\">Optimization</a></li>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\">损失函数</a><ul>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-Loss-function--%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0-Cost-function\">损失函数 Loss function / 代价函数 Cost function</a></li>\n<li><a href=\"#%E5%9D%87%E6%96%B9%E6%8D%9F%E5%A4%B1\">均方损失</a></li>\n<li><a href=\"#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1cross-entropy-loss\">交叉熵损失（cross-entropy loss)</a></li>\n<li><a href=\"#Softmax-%E5%87%BD%E6%95%B0\">Softmax 函数</a></li>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96\">损失函数可视化</a></li>\n</ul>\n</li>\n<li><a href=\"#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">梯度下降</a><ul>\n<li><a href=\"#%E5%85%A8%E5%B1%80%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Batch-Gradient-Descent\">全局梯度下降　Batch Gradient Descent</a></li>\n<li><a href=\"#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DSGD-Stochastic-Gradient-Descent\">随机梯度下降SGD　Stochastic Gradient Descent</a></li>\n<li><a href=\"#%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%EF%BC%ADini-batch-Gradient-Descent\">小批量梯度下降　Ｍini-batch Gradient Descent</a></li>\n<li><a href=\"#Challange\">Challange</a></li>\n</ul>\n</li>\n<li><a href=\"#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95\">优化算法</a><ul>\n<li><a href=\"#%E7%89%9B%E9%A1%BF%E6%B3%95\">牛顿法</a></li>\n<li><a href=\"#BFGS-L-BFGS\">BFGS, L-BFGS</a></li>\n<li><a href=\"#%E6%A2%AF%E5%BA%A6%E8%A1%B0%E5%87%8F%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB\">梯度衰减(模拟退火)</a></li>\n<li><a href=\"#%EF%BC%ADomentum\">Ｍomentum</a></li>\n<li><a href=\"#NAG-Neterov-Accelerated-Gradient\">NAG Neterov Accelerated Gradient</a></li>\n<li><a href=\"#Adagrad\">Adagrad</a></li>\n<li><a href=\"#Adadelta\">Adadelta</a></li>\n<li><a href=\"#RMSProp\">RMSProp</a></li>\n<li><a href=\"#Adam\">Adam</a></li>\n<li><a href=\"#Nadam\">Nadam</a><ul>\n<li><a href=\"#%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%8A%A8%E6%80%81%E5%9B%BE\">各种优化方法动态图</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a>损失函数</h2><h4 id=\"损失函数-Loss-function-代价函数-Cost-function\"><a href=\"#损失函数-Loss-function-代价函数-Cost-function\" class=\"headerlink\" title=\"损失函数 Loss function / 代价函数 Cost function\"></a>损失函数 Loss function / 代价函数 Cost function</h4><p><img src=\"/2019/06/17/deep-learning/optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png\" alt=\"img\"></p>\n<h4 id=\"均方损失\"><a href=\"#均方损失\" class=\"headerlink\" title=\"均方损失\"></a>均方损失</h4><p>$$L(x)=\\sum_{i}(y_i - y_j)^2$$</p>\n<h4 id=\"交叉熵损失（cross-entropy-loss\"><a href=\"#交叉熵损失（cross-entropy-loss\" class=\"headerlink\" title=\"交叉熵损失（cross-entropy loss)\"></a>交叉熵损失（cross-entropy loss)</h4><p>$$L(x)=\\sum_{i}p_i\\log \\frac{1}{q_i}$$</p>\n<p>交叉熵作为代价函数可以避免均方代价函数带来的学习减速(nelson)</p>\n<h4 id=\"Softmax-函数\"><a href=\"#Softmax-函数\" class=\"headerlink\" title=\"Softmax 函数\"></a>Softmax 函数</h4><p><img src=\"/2019/06/17/deep-learning/optimization/1561034699845.png\" alt=\"1561034699845\"></p>\n<p>$$y_i=\\frac{e^{z_i}}{\\sum_{i}{e^{z_i}}}$$</p>\n<p>Softmax 分类器为每一个分类都提供了“可能性（概率）”</p>\n<p>输出值$z_i$ =&gt; 概率$y_i$</p>\n<p><strong>决策函数</strong>：$$\\hat{y}=argmax_{i}(y=y_i|Z)$$  (y所属类别$\\hat{y}$)</p>\n<h4 id=\"损失函数可视化\"><a href=\"#损失函数可视化\" class=\"headerlink\" title=\"损失函数可视化\"></a>损失函数可视化</h4><p>颜色越深，损失函数越小</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png\" alt=\"img\"></p>\n<h2 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a>梯度下降</h2><p>损失函数 L 的 3D 图：</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561035128653.png\" alt=\"1561035128653\"></p>\n<p>Gradient: 损失函数 L 在某一点的梯度（斜率，一阶导数）</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561035151992.png\" alt=\"1561035151992\"></p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg\" alt=\"preview\"></p>\n<p>梯度下降法：某一点沿着斜坡在当前点梯度最大的方向($f’(x)​$)移动一个步长(learning rate)，在下一次更新中就会更接近最小点。</p>\n<p>$$w = w - \\eta dw$$</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg\" alt=\"img\"></p>\n<p>白箭头为（负梯度方向），是损失函数下降最陡峭的方向。沿着梯度方向逐步下降更新参数，就是深度学习中的梯度下降学习方法。</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561186124221.png\" alt=\"1561186124221\"></p>\n<h4 id=\"全局梯度下降-Batch-Gradient-Descent\"><a href=\"#全局梯度下降-Batch-Gradient-Descent\" class=\"headerlink\" title=\"全局梯度下降　Batch Gradient Descent\"></a>全局梯度下降　Batch Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta)$$</p>\n<p>优点：保证每次更新梯度都朝着正确的方向进行，保证收敛到局部最小点</p>\n<p>缺点：每次需计算整个训练集数据，成本比较高</p>\n<h4 id=\"随机梯度下降SGD-Stochastic-Gradient-Descent\"><a href=\"#随机梯度下降SGD-Stochastic-Gradient-Descent\" class=\"headerlink\" title=\"随机梯度下降SGD　Stochastic Gradient Descent\"></a>随机梯度下降SGD　Stochastic Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_i,y_i)$$</p>\n<p>优点：每次只选择一个样本来学习，成本低，可以进行在线更新; 不容易陷入某个局部</p>\n<p>缺点：优化过程中波动较大，收敛速度慢；可能在沟壑两边持续震荡，停留在一个局部最优点</p>\n<h4 id=\"小批量梯度下降-Mini-batch-Gradient-Descent\"><a href=\"#小批量梯度下降-Mini-batch-Gradient-Descent\" class=\"headerlink\" title=\"小批量梯度下降　Ｍini-batch Gradient Descent\"></a>小批量梯度下降　Ｍini-batch Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_{i:i+n},y_{i,i+n})$$</p>\n<p>n的大小通常为50-256</p>\n<p>优点：相对于随机梯度下降(SGD)，降低收敛波动性（降低参数更新的方差），使得收敛过程更加稳定。相对于全量梯度下降，提高了每次学习的速度。</p>\n<h4 id=\"Challange\"><a href=\"#Challange\" class=\"headerlink\" title=\"Challange\"></a>Challange</h4><ul>\n<li><strong>学习速率</strong>的选择，过小则收敛很慢，过大则在极值点附近震荡</li>\n<li>学习速率调整（模拟退火）一般使用事先设定的策略或者每次迭代中衰减一个阈值。都需要事先固定设置，无法<strong>自适应</strong>数据集的特点</li>\n<li>所有的<strong>参数每次更新都使用相同的学习速率</strong>。如果数据特征稀疏或者取值空间分布不同，就不应该使用同样的学习速率，对于很少出现的特征应该使用一个较大的学习速率</li>\n<li>对于非凸损失函数，容易陷入局部最小点，更严重的问题在于<strong>鞍点</strong>，附近点的梯度在所有维度上都接近于０</li>\n</ul>\n<h2 id=\"优化算法\"><a href=\"#优化算法\" class=\"headerlink\" title=\"优化算法\"></a>优化算法</h2><h4 id=\"牛顿法\"><a href=\"#牛顿法\" class=\"headerlink\" title=\"牛顿法\"></a>牛顿法</h4><p>$x = x -[Hf(x)]^{-1}\\nabla f(x)$</p>\n<p>$Hf(x)$: Hessian 矩阵，描述损失函数的局部曲率</p>\n<p>$[Hf(x)]^{-1}$让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进</p>\n<p>而且，没有学习率这个超参数</p>\n<p>但是，Hessian矩阵计算成本很高</p>\n<h4 id=\"BFGS-L-BFGS\"><a href=\"#BFGS-L-BFGS\" class=\"headerlink\" title=\"BFGS, L-BFGS\"></a>BFGS, L-BFGS</h4><h4 id=\"梯度衰减-模拟退火\"><a href=\"#梯度衰减-模拟退火\" class=\"headerlink\" title=\"梯度衰减(模拟退火)\"></a>梯度衰减(模拟退火)</h4><ul>\n<li><p>随步数减半：没５个周期减半，每20个周期减少到之前0.1</p>\n</li>\n<li><p>指数衰减：$\\alpha=\\alpha_{0}e^{-kt}$</p>\n</li>\n<li>1/t衰减：$\\alpha=\\frac{\\alpha_0}{1+kt}$</li>\n</ul>\n<h4 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Ｍomentum\"></a>Ｍomentum</h4><p>累积之前的下降方向，并略微偏向当前时刻的下降方向</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561186187105.png\" alt=\"1561186187105\"></p>\n<p>引入动量，<strong>累积之前的动量(梯度的指数衰减)</strong>，速度越来越快。</p>\n<p>$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$$</p>\n<p>$$\\theta = \\theta - v_t$$</p>\n<p>$$\\gamma$$通常使用0.9</p>\n<p>加上动量后，就像从山顶往下滚的球。更新过程中，与上一次梯度方向相同的参数更新加强，在这个方向下降更快；与上一次梯度方向不同的参数更新减弱，在这个方向下降减慢。因此获得更快的收敛速度并减少震荡。</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561196522519.png\" alt=\"1561196522519\"></p>\n<h4 id=\"NAG-Neterov-Accelerated-Gradient\"><a href=\"#NAG-Neterov-Accelerated-Gradient\" class=\"headerlink\" title=\"NAG Neterov Accelerated Gradient\"></a>NAG Neterov Accelerated Gradient</h4><p>往标准动量方法添加一个修正因子(当前梯度衰减$\\eta v_{t-1}$)，阻止过快更新</p>\n<p>$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta-\\gamma v_{t-1})$$</p>\n<p>$$\\theta = \\theta - v_t$$</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/nesterov_update_vector.png\" alt=\"SGD fluctuation\"></p>\n<p>核心思路：</p>\n<p>当参数向量位于某个位置ｘ时，动量部分衰减$\\gamma v_{t-1}$，向前一步$\\theta-\\gamma v_{t-1}$得到下一步要到达的位置，<strong>向前看</strong>在<strong>下一步</strong>的位置计算梯度。<img src=\"/2019/06/17/deep-learning/optimization/412afb713ddcff0ba9165ab026563304_hd.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_ahead = x + mu * v</span><br><span class=\"line\"><span class=\"comment\"># 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)</span></span><br><span class=\"line\">v = mu * v - learning_rate * dx_ahead</span><br><span class=\"line\">x += v</span><br></pre></td></tr></table></figure>\n<p><strong>通过上面的两种方法，可以做到每次学习过程中能够根据损失函数的斜率做到自适应更新来加速SGD的收敛</strong>。</p>\n<p>接下来引入二阶动量，希望同时解决<strong>不同参数应该使用不同学习速率的问题</strong>。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</p>\n<p>怎么样去度量历史更新频率呢？</p>\n<p>那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：</p>\n<p>$$V_t=\\sum_{\\tau=1}^{t} g_{\\tau}^2$$</p>\n<h4 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h4><p><strong>累积平方梯度</strong></p>\n<p>$$g_{t} = \\nabla_{\\theta} J(\\theta)$$</p>\n<p>$$r=r + g \\odot g$$</p>\n<p>$$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{r+\\epsilon}}\\odot g$$</p>\n<p>优点：</p>\n<ul>\n<li><p>适合处理稀疏梯度。自适应不同的学习速率，对稀疏特征，得到更大的学习更新；对非稀疏特征，得到更小的学习更新　　特征出现越多，累积平方梯度ｒ越大，分母$\\sqrt{r+\\epsilon}$越大，更新越慢</p>\n</li>\n<li><p>前期$g_t$较小，校正因子较大，能够放大梯度，累积势越小，更新越快</p>\n</li>\n<li><p>后期$g_t$较大，校正因子较大，能够约束梯度，累积势越大，更新越慢</p>\n</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>依赖学习速率</li>\n<li>学习速率$\\eta$不能过大，否则导致对梯度调节过大</li>\n<li>单调的学习率被证明通常<strong>过于激进且过早停止学习</strong>。后期如果梯度的平方累积($r$)过大，导致更新很小，接近于０，使得训练提前结束</li>\n</ul>\n<p>由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。</p>\n<p>引入指数移动平均值：</p>\n<p>$$r_t=\\gamma r_{t-1}+(1-\\gamma)g_{t}^2$$</p>\n<h4 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h4><p>对Adagrad的扩展</p>\n<p>$$g_{t} = \\nabla_{\\theta} J(\\theta)$$</p>\n<p>$$r=\\gamma r + (1-\\gamma) g \\odot g$$</p>\n<p>$$g’<em>t=\\sqrt{\\frac{\\Delta x</em>{t-1} +\\epsilon}{r+\\epsilon}}\\odot g$$                   # 使用<strong>状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$</strong></p>\n<p>$$\\theta_{t+1}=\\theta_{t}-g’_t$$</p>\n<p>$$\\Delta x_t=\\gamma \\Delta x_{t-1}+(1-\\gamma)g’_t\\odot g’<em>t $$   # 使用$\\Delta x</em>{t-1}$记录自变量变化量$g′_t$按元素平方的指数加权移动平均</p>\n<p>优点：</p>\n<ul>\n<li>不再依赖学习率，使用梯度平方的指数加权累积得到状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$</li>\n<li>训练初中期，加速效果好</li>\n<li>训练后期，反复在局部最小值附近抖动</li>\n</ul>\n<h4 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h4><p><strong>累积指数加权的平方梯度</strong></p>\n<p>$$E[g^2]<em>t=\\gamma E[g^2]</em>{t-1}+(1-\\gamma)g_t^2$$          # 梯度平方的滑动平均</p>\n<p>$$\\theta_{t-1}=\\theta_{t} - \\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\\odot g_t$$</p>\n<p>$\\gamma=0.9, \\eta=0.001$</p>\n<ul>\n<li>RMSProp 是 Adagrad 的一种发展，和 Adadelta 的变体，效果趋于二者之间，<strong>降低了 Adagrad 中学习速率衰减过快</strong>的问题</li>\n<li>适合处理非平稳目标（RNN）</li>\n</ul>\n<p>接下来，整合前面所有方法，就得到 Adam。SGD-Momentum 在 SGD 的基础上增加了一阶动量，AdaGrad 和 AdaDelta 在 SGD 的基础上增加了二阶动量。结合一阶动量和二阶动量，就是 Adam (Adaptive+Momentum). 再加上 Neterov，就是 Nadam。</p>\n<h4 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h4><p>Adaptive Moment Estimation(Adam)</p>\n<p><strong>累积指数加权的梯度和平方梯度</strong></p>\n<p>$$m_t=\\beta_1 m_{t-1} + (1-\\beta_1)g_t$$   # 一阶累积</p>\n<p>$$r_t = \\beta_2 r_{t-1} + (1-\\beta_2)g_{t}^2$$　　# 二阶累积</p>\n<p>$$\\hat{m_t}=\\frac{m_t}{1-\\beta_1^t}$$　　　　　　　　　# 校正因子，$m_t$接近与０(初始0, $\\beta$ 接近１)</p>\n<p>$$\\hat{v_t}=\\frac{v_t}{1-\\beta_2^t}$$</p>\n<p>$$\\theta_{t+1}=\\theta_t - \\eta\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t} + \\epsilon}}$$</p>\n<p>$\\beta_1=0.9,\\beta_2=0.999,\\epsilon=10^{-8}$</p>\n<h4 id=\"Nadam\"><a href=\"#Nadam\" class=\"headerlink\" title=\"Nadam\"></a>Nadam</h4><p>$$g_t=\\nabla_{\\theta_t} J(\\theta_t - m_t)$$</p>\n<p>优点：</p>\n<ul>\n<li>结合 Adagrad 善于处理稀疏梯度和 RMSProp 善于处理非平稳目标的问题</li>\n<li>适用于大数据集和高维空间</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得 <img src=\"/2019/06/17/deep-learning/optimization/equation.svg\" alt=\"[公式]\"> 可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。</li>\n<li>可能错过全局最优解</li>\n</ul>\n<p><em>cs231n: The two recommended updates to use are either SGD+Nesterov Momentum or Adam</em></p>\n<h3 id=\"各种优化方法动态图\"><a href=\"#各种优化方法动态图\" class=\"headerlink\" title=\"各种优化方法动态图\"></a>各种优化方法动态图</h3><p><img src=\"http://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif\" alt=\"SGD without momentum\"></p>\n<p> Adagrad、Adadelta与RMSprop在损失曲面上能够立即转移到正确的移动方向上达到快速的收敛。而Momentum 与NAG会导致偏离(off-track)。同时NAG能够在偏离之后快速修正其路线，因为其根据梯度修正来提高响应性</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/20160909001936276\" alt=\"saddle_point_evaluation_optimizers\"></p>\n<p>从上图可以看出，在鞍点（saddle points）处(即某些维度上梯度为零，某些维度上梯度不为零)，SGD、Momentum与NAG一直在鞍点梯度为零的方向上振荡，很难打破鞍点位置的对称性；Adagrad、RMSprop与Adadelta能够很快地向梯度不为零的方向上转移。<br>   从上面两幅图可以看出，自适应学习速率方法(Adagrad、Adadelta、RMSprop与Adam)在这些场景下具有更好的收敛速度与收敛性。</p>\n<p>References:</p>\n<ol>\n<li><a href=\"http://ruder.io/optimizing-gradient-descent/index.html\" target=\"_blank\" rel=\"noopener\">An overview of gradient descent optimization algorithms</a></li>\n<li><a href=\"https://blog.csdn.net/heyongluoyao8/article/details/52478715\" target=\"_blank\" rel=\"noopener\">梯度下降优化算法综述(1的翻译)</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/32230623\" target=\"_blank\" rel=\"noopener\">一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - Juliuszh的文章 - 知乎</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Optimization\"><a href=\"#Optimization\" class=\"headerlink\" title=\"Optimization\"></a>Optimization</h2><ul>\n<li><a href=\"#Optimization\">Optimization</a></li>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0\">损失函数</a><ul>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0-Loss-function--%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0-Cost-function\">损失函数 Loss function / 代价函数 Cost function</a></li>\n<li><a href=\"#%E5%9D%87%E6%96%B9%E6%8D%9F%E5%A4%B1\">均方损失</a></li>\n<li><a href=\"#%E4%BA%A4%E5%8F%89%E7%86%B5%E6%8D%9F%E5%A4%B1cross-entropy-loss\">交叉熵损失（cross-entropy loss)</a></li>\n<li><a href=\"#Softmax-%E5%87%BD%E6%95%B0\">Softmax 函数</a></li>\n<li><a href=\"#%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%8F%AF%E8%A7%86%E5%8C%96\">损失函数可视化</a></li>\n</ul>\n</li>\n<li><a href=\"#%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D\">梯度下降</a><ul>\n<li><a href=\"#%E5%85%A8%E5%B1%80%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-Batch-Gradient-Descent\">全局梯度下降　Batch Gradient Descent</a></li>\n<li><a href=\"#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8DSGD-Stochastic-Gradient-Descent\">随机梯度下降SGD　Stochastic Gradient Descent</a></li>\n<li><a href=\"#%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D-%EF%BC%ADini-batch-Gradient-Descent\">小批量梯度下降　Ｍini-batch Gradient Descent</a></li>\n<li><a href=\"#Challange\">Challange</a></li>\n</ul>\n</li>\n<li><a href=\"#%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95\">优化算法</a><ul>\n<li><a href=\"#%E7%89%9B%E9%A1%BF%E6%B3%95\">牛顿法</a></li>\n<li><a href=\"#BFGS-L-BFGS\">BFGS, L-BFGS</a></li>\n<li><a href=\"#%E6%A2%AF%E5%BA%A6%E8%A1%B0%E5%87%8F%E6%A8%A1%E6%8B%9F%E9%80%80%E7%81%AB\">梯度衰减(模拟退火)</a></li>\n<li><a href=\"#%EF%BC%ADomentum\">Ｍomentum</a></li>\n<li><a href=\"#NAG-Neterov-Accelerated-Gradient\">NAG Neterov Accelerated Gradient</a></li>\n<li><a href=\"#Adagrad\">Adagrad</a></li>\n<li><a href=\"#Adadelta\">Adadelta</a></li>\n<li><a href=\"#RMSProp\">RMSProp</a></li>\n<li><a href=\"#Adam\">Adam</a></li>\n<li><a href=\"#Nadam\">Nadam</a><ul>\n<li><a href=\"#%E5%90%84%E7%A7%8D%E4%BC%98%E5%8C%96%E6%96%B9%E6%B3%95%E5%8A%A8%E6%80%81%E5%9B%BE\">各种优化方法动态图</a></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"损失函数\"><a href=\"#损失函数\" class=\"headerlink\" title=\"损失函数\"></a>损失函数</h2><h4 id=\"损失函数-Loss-function-代价函数-Cost-function\"><a href=\"#损失函数-Loss-function-代价函数-Cost-function\" class=\"headerlink\" title=\"损失函数 Loss function / 代价函数 Cost function\"></a>损失函数 Loss function / 代价函数 Cost function</h4><p><img src=\"/2019/06/17/deep-learning/optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png\" alt=\"img\"></p>\n<h4 id=\"均方损失\"><a href=\"#均方损失\" class=\"headerlink\" title=\"均方损失\"></a>均方损失</h4><p>$$L(x)=\\sum_{i}(y_i - y_j)^2$$</p>\n<h4 id=\"交叉熵损失（cross-entropy-loss\"><a href=\"#交叉熵损失（cross-entropy-loss\" class=\"headerlink\" title=\"交叉熵损失（cross-entropy loss)\"></a>交叉熵损失（cross-entropy loss)</h4><p>$$L(x)=\\sum_{i}p_i\\log \\frac{1}{q_i}$$</p>\n<p>交叉熵作为代价函数可以避免均方代价函数带来的学习减速(nelson)</p>\n<h4 id=\"Softmax-函数\"><a href=\"#Softmax-函数\" class=\"headerlink\" title=\"Softmax 函数\"></a>Softmax 函数</h4><p><img src=\"/2019/06/17/deep-learning/optimization/1561034699845.png\" alt=\"1561034699845\"></p>\n<p>$$y_i=\\frac{e^{z_i}}{\\sum_{i}{e^{z_i}}}$$</p>\n<p>Softmax 分类器为每一个分类都提供了“可能性（概率）”</p>\n<p>输出值$z_i$ =&gt; 概率$y_i$</p>\n<p><strong>决策函数</strong>：$$\\hat{y}=argmax_{i}(y=y_i|Z)$$  (y所属类别$\\hat{y}$)</p>\n<h4 id=\"损失函数可视化\"><a href=\"#损失函数可视化\" class=\"headerlink\" title=\"损失函数可视化\"></a>损失函数可视化</h4><p>颜色越深，损失函数越小</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png\" alt=\"img\"></p>\n<h2 id=\"梯度下降\"><a href=\"#梯度下降\" class=\"headerlink\" title=\"梯度下降\"></a>梯度下降</h2><p>损失函数 L 的 3D 图：</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561035128653.png\" alt=\"1561035128653\"></p>\n<p>Gradient: 损失函数 L 在某一点的梯度（斜率，一阶导数）</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561035151992.png\" alt=\"1561035151992\"></p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg\" alt=\"preview\"></p>\n<p>梯度下降法：某一点沿着斜坡在当前点梯度最大的方向($f’(x)​$)移动一个步长(learning rate)，在下一次更新中就会更接近最小点。</p>\n<p>$$w = w - \\eta dw$$</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg\" alt=\"img\"></p>\n<p>白箭头为（负梯度方向），是损失函数下降最陡峭的方向。沿着梯度方向逐步下降更新参数，就是深度学习中的梯度下降学习方法。</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561186124221.png\" alt=\"1561186124221\"></p>\n<h4 id=\"全局梯度下降-Batch-Gradient-Descent\"><a href=\"#全局梯度下降-Batch-Gradient-Descent\" class=\"headerlink\" title=\"全局梯度下降　Batch Gradient Descent\"></a>全局梯度下降　Batch Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta)$$</p>\n<p>优点：保证每次更新梯度都朝着正确的方向进行，保证收敛到局部最小点</p>\n<p>缺点：每次需计算整个训练集数据，成本比较高</p>\n<h4 id=\"随机梯度下降SGD-Stochastic-Gradient-Descent\"><a href=\"#随机梯度下降SGD-Stochastic-Gradient-Descent\" class=\"headerlink\" title=\"随机梯度下降SGD　Stochastic Gradient Descent\"></a>随机梯度下降SGD　Stochastic Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_i,y_i)$$</p>\n<p>优点：每次只选择一个样本来学习，成本低，可以进行在线更新; 不容易陷入某个局部</p>\n<p>缺点：优化过程中波动较大，收敛速度慢；可能在沟壑两边持续震荡，停留在一个局部最优点</p>\n<h4 id=\"小批量梯度下降-Mini-batch-Gradient-Descent\"><a href=\"#小批量梯度下降-Mini-batch-Gradient-Descent\" class=\"headerlink\" title=\"小批量梯度下降　Ｍini-batch Gradient Descent\"></a>小批量梯度下降　Ｍini-batch Gradient Descent</h4><p>$$\\theta = \\theta-\\eta \\nabla_{\\theta} J(\\theta;x_{i:i+n},y_{i,i+n})$$</p>\n<p>n的大小通常为50-256</p>\n<p>优点：相对于随机梯度下降(SGD)，降低收敛波动性（降低参数更新的方差），使得收敛过程更加稳定。相对于全量梯度下降，提高了每次学习的速度。</p>\n<h4 id=\"Challange\"><a href=\"#Challange\" class=\"headerlink\" title=\"Challange\"></a>Challange</h4><ul>\n<li><strong>学习速率</strong>的选择，过小则收敛很慢，过大则在极值点附近震荡</li>\n<li>学习速率调整（模拟退火）一般使用事先设定的策略或者每次迭代中衰减一个阈值。都需要事先固定设置，无法<strong>自适应</strong>数据集的特点</li>\n<li>所有的<strong>参数每次更新都使用相同的学习速率</strong>。如果数据特征稀疏或者取值空间分布不同，就不应该使用同样的学习速率，对于很少出现的特征应该使用一个较大的学习速率</li>\n<li>对于非凸损失函数，容易陷入局部最小点，更严重的问题在于<strong>鞍点</strong>，附近点的梯度在所有维度上都接近于０</li>\n</ul>\n<h2 id=\"优化算法\"><a href=\"#优化算法\" class=\"headerlink\" title=\"优化算法\"></a>优化算法</h2><h4 id=\"牛顿法\"><a href=\"#牛顿法\" class=\"headerlink\" title=\"牛顿法\"></a>牛顿法</h4><p>$x = x -[Hf(x)]^{-1}\\nabla f(x)$</p>\n<p>$Hf(x)$: Hessian 矩阵，描述损失函数的局部曲率</p>\n<p>$[Hf(x)]^{-1}$让最优化过程在曲率小的时候大步前进，在曲率大的时候小步前进</p>\n<p>而且，没有学习率这个超参数</p>\n<p>但是，Hessian矩阵计算成本很高</p>\n<h4 id=\"BFGS-L-BFGS\"><a href=\"#BFGS-L-BFGS\" class=\"headerlink\" title=\"BFGS, L-BFGS\"></a>BFGS, L-BFGS</h4><h4 id=\"梯度衰减-模拟退火\"><a href=\"#梯度衰减-模拟退火\" class=\"headerlink\" title=\"梯度衰减(模拟退火)\"></a>梯度衰减(模拟退火)</h4><ul>\n<li><p>随步数减半：没５个周期减半，每20个周期减少到之前0.1</p>\n</li>\n<li><p>指数衰减：$\\alpha=\\alpha_{0}e^{-kt}$</p>\n</li>\n<li>1/t衰减：$\\alpha=\\frac{\\alpha_0}{1+kt}$</li>\n</ul>\n<h4 id=\"Momentum\"><a href=\"#Momentum\" class=\"headerlink\" title=\"Ｍomentum\"></a>Ｍomentum</h4><p>累积之前的下降方向，并略微偏向当前时刻的下降方向</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561186187105.png\" alt=\"1561186187105\"></p>\n<p>引入动量，<strong>累积之前的动量(梯度的指数衰减)</strong>，速度越来越快。</p>\n<p>$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta)$$</p>\n<p>$$\\theta = \\theta - v_t$$</p>\n<p>$$\\gamma$$通常使用0.9</p>\n<p>加上动量后，就像从山顶往下滚的球。更新过程中，与上一次梯度方向相同的参数更新加强，在这个方向下降更快；与上一次梯度方向不同的参数更新减弱，在这个方向下降减慢。因此获得更快的收敛速度并减少震荡。</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/1561196522519.png\" alt=\"1561196522519\"></p>\n<h4 id=\"NAG-Neterov-Accelerated-Gradient\"><a href=\"#NAG-Neterov-Accelerated-Gradient\" class=\"headerlink\" title=\"NAG Neterov Accelerated Gradient\"></a>NAG Neterov Accelerated Gradient</h4><p>往标准动量方法添加一个修正因子(当前梯度衰减$\\eta v_{t-1}$)，阻止过快更新</p>\n<p>$$v_t = \\gamma v_{t-1} + \\eta \\nabla_\\theta J(\\theta-\\gamma v_{t-1})$$</p>\n<p>$$\\theta = \\theta - v_t$$</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/nesterov_update_vector.png\" alt=\"SGD fluctuation\"></p>\n<p>核心思路：</p>\n<p>当参数向量位于某个位置ｘ时，动量部分衰减$\\gamma v_{t-1}$，向前一步$\\theta-\\gamma v_{t-1}$得到下一步要到达的位置，<strong>向前看</strong>在<strong>下一步</strong>的位置计算梯度。<img src=\"/2019/06/17/deep-learning/optimization/412afb713ddcff0ba9165ab026563304_hd.png\" alt=\"img\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">x_ahead = x + mu * v</span><br><span class=\"line\"><span class=\"comment\"># 计算dx_ahead(在x_ahead处的梯度，而不是在x处的梯度)</span></span><br><span class=\"line\">v = mu * v - learning_rate * dx_ahead</span><br><span class=\"line\">x += v</span><br></pre></td></tr></table></figure>\n<p><strong>通过上面的两种方法，可以做到每次学习过程中能够根据损失函数的斜率做到自适应更新来加速SGD的收敛</strong>。</p>\n<p>接下来引入二阶动量，希望同时解决<strong>不同参数应该使用不同学习速率的问题</strong>。对于经常更新的参数，我们已经积累了大量关于它的知识，不希望被单个样本影响太大，希望学习速率慢一些；对于偶尔更新的参数，我们了解的信息太少，希望能从每个偶然出现的样本身上多学一些，即学习速率大一些。</p>\n<p>怎么样去度量历史更新频率呢？</p>\n<p>那就是二阶动量——该维度上，迄今为止所有梯度值的平方和：</p>\n<p>$$V_t=\\sum_{\\tau=1}^{t} g_{\\tau}^2$$</p>\n<h4 id=\"Adagrad\"><a href=\"#Adagrad\" class=\"headerlink\" title=\"Adagrad\"></a>Adagrad</h4><p><strong>累积平方梯度</strong></p>\n<p>$$g_{t} = \\nabla_{\\theta} J(\\theta)$$</p>\n<p>$$r=r + g \\odot g$$</p>\n<p>$$\\theta_{t+1}=\\theta_{t}-\\frac{\\eta}{\\sqrt{r+\\epsilon}}\\odot g$$</p>\n<p>优点：</p>\n<ul>\n<li><p>适合处理稀疏梯度。自适应不同的学习速率，对稀疏特征，得到更大的学习更新；对非稀疏特征，得到更小的学习更新　　特征出现越多，累积平方梯度ｒ越大，分母$\\sqrt{r+\\epsilon}$越大，更新越慢</p>\n</li>\n<li><p>前期$g_t$较小，校正因子较大，能够放大梯度，累积势越小，更新越快</p>\n</li>\n<li><p>后期$g_t$较大，校正因子较大，能够约束梯度，累积势越大，更新越慢</p>\n</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>依赖学习速率</li>\n<li>学习速率$\\eta$不能过大，否则导致对梯度调节过大</li>\n<li>单调的学习率被证明通常<strong>过于激进且过早停止学习</strong>。后期如果梯度的平方累积($r$)过大，导致更新很小，接近于０，使得训练提前结束</li>\n</ul>\n<p>由于AdaGrad单调递减的学习率变化过于激进，我们考虑一个改变二阶动量计算方法的策略：不累积全部历史梯度，而只关注过去一段时间窗口的下降梯度。这也就是AdaDelta名称中Delta的来历。</p>\n<p>引入指数移动平均值：</p>\n<p>$$r_t=\\gamma r_{t-1}+(1-\\gamma)g_{t}^2$$</p>\n<h4 id=\"Adadelta\"><a href=\"#Adadelta\" class=\"headerlink\" title=\"Adadelta\"></a>Adadelta</h4><p>对Adagrad的扩展</p>\n<p>$$g_{t} = \\nabla_{\\theta} J(\\theta)$$</p>\n<p>$$r=\\gamma r + (1-\\gamma) g \\odot g$$</p>\n<p>$$g’<em>t=\\sqrt{\\frac{\\Delta x</em>{t-1} +\\epsilon}{r+\\epsilon}}\\odot g$$                   # 使用<strong>状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$</strong></p>\n<p>$$\\theta_{t+1}=\\theta_{t}-g’_t$$</p>\n<p>$$\\Delta x_t=\\gamma \\Delta x_{t-1}+(1-\\gamma)g’_t\\odot g’<em>t $$   # 使用$\\Delta x</em>{t-1}$记录自变量变化量$g′_t$按元素平方的指数加权移动平均</p>\n<p>优点：</p>\n<ul>\n<li>不再依赖学习率，使用梯度平方的指数加权累积得到状态变量$\\Delta x_{t-1}$替代学习速率$\\eta$</li>\n<li>训练初中期，加速效果好</li>\n<li>训练后期，反复在局部最小值附近抖动</li>\n</ul>\n<h4 id=\"RMSProp\"><a href=\"#RMSProp\" class=\"headerlink\" title=\"RMSProp\"></a>RMSProp</h4><p><strong>累积指数加权的平方梯度</strong></p>\n<p>$$E[g^2]<em>t=\\gamma E[g^2]</em>{t-1}+(1-\\gamma)g_t^2$$          # 梯度平方的滑动平均</p>\n<p>$$\\theta_{t-1}=\\theta_{t} - \\frac{\\eta}{\\sqrt{E[g^2]_t+\\epsilon}}\\odot g_t$$</p>\n<p>$\\gamma=0.9, \\eta=0.001$</p>\n<ul>\n<li>RMSProp 是 Adagrad 的一种发展，和 Adadelta 的变体，效果趋于二者之间，<strong>降低了 Adagrad 中学习速率衰减过快</strong>的问题</li>\n<li>适合处理非平稳目标（RNN）</li>\n</ul>\n<p>接下来，整合前面所有方法，就得到 Adam。SGD-Momentum 在 SGD 的基础上增加了一阶动量，AdaGrad 和 AdaDelta 在 SGD 的基础上增加了二阶动量。结合一阶动量和二阶动量，就是 Adam (Adaptive+Momentum). 再加上 Neterov，就是 Nadam。</p>\n<h4 id=\"Adam\"><a href=\"#Adam\" class=\"headerlink\" title=\"Adam\"></a>Adam</h4><p>Adaptive Moment Estimation(Adam)</p>\n<p><strong>累积指数加权的梯度和平方梯度</strong></p>\n<p>$$m_t=\\beta_1 m_{t-1} + (1-\\beta_1)g_t$$   # 一阶累积</p>\n<p>$$r_t = \\beta_2 r_{t-1} + (1-\\beta_2)g_{t}^2$$　　# 二阶累积</p>\n<p>$$\\hat{m_t}=\\frac{m_t}{1-\\beta_1^t}$$　　　　　　　　　# 校正因子，$m_t$接近与０(初始0, $\\beta$ 接近１)</p>\n<p>$$\\hat{v_t}=\\frac{v_t}{1-\\beta_2^t}$$</p>\n<p>$$\\theta_{t+1}=\\theta_t - \\eta\\frac{\\hat{m_t}}{\\sqrt{\\hat{v_t} + \\epsilon}}$$</p>\n<p>$\\beta_1=0.9,\\beta_2=0.999,\\epsilon=10^{-8}$</p>\n<h4 id=\"Nadam\"><a href=\"#Nadam\" class=\"headerlink\" title=\"Nadam\"></a>Nadam</h4><p>$$g_t=\\nabla_{\\theta_t} J(\\theta_t - m_t)$$</p>\n<p>优点：</p>\n<ul>\n<li>结合 Adagrad 善于处理稀疏梯度和 RMSProp 善于处理非平稳目标的问题</li>\n<li>适用于大数据集和高维空间</li>\n</ul>\n<p>缺点：</p>\n<ul>\n<li>二阶动量是固定时间窗口内的累积，随着时间窗口的变化，遇到的数据可能发生巨变，使得 <img src=\"/2019/06/17/deep-learning/optimization/equation.svg\" alt=\"[公式]\"> 可能会时大时小，不是单调变化。这就可能在训练后期引起学习率的震荡，导致模型无法收敛。</li>\n<li>可能错过全局最优解</li>\n</ul>\n<p><em>cs231n: The two recommended updates to use are either SGD+Nesterov Momentum or Adam</em></p>\n<h3 id=\"各种优化方法动态图\"><a href=\"#各种优化方法动态图\" class=\"headerlink\" title=\"各种优化方法动态图\"></a>各种优化方法动态图</h3><p><img src=\"http://ruder.io/content/images/2016/09/contours_evaluation_optimizers.gif\" alt=\"SGD without momentum\"></p>\n<p> Adagrad、Adadelta与RMSprop在损失曲面上能够立即转移到正确的移动方向上达到快速的收敛。而Momentum 与NAG会导致偏离(off-track)。同时NAG能够在偏离之后快速修正其路线，因为其根据梯度修正来提高响应性</p>\n<p><img src=\"/2019/06/17/deep-learning/optimization/20160909001936276\" alt=\"saddle_point_evaluation_optimizers\"></p>\n<p>从上图可以看出，在鞍点（saddle points）处(即某些维度上梯度为零，某些维度上梯度不为零)，SGD、Momentum与NAG一直在鞍点梯度为零的方向上振荡，很难打破鞍点位置的对称性；Adagrad、RMSprop与Adadelta能够很快地向梯度不为零的方向上转移。<br>   从上面两幅图可以看出，自适应学习速率方法(Adagrad、Adadelta、RMSprop与Adam)在这些场景下具有更好的收敛速度与收敛性。</p>\n<p>References:</p>\n<ol>\n<li><a href=\"http://ruder.io/optimizing-gradient-descent/index.html\" target=\"_blank\" rel=\"noopener\">An overview of gradient descent optimization algorithms</a></li>\n<li><a href=\"https://blog.csdn.net/heyongluoyao8/article/details/52478715\" target=\"_blank\" rel=\"noopener\">梯度下降优化算法综述(1的翻译)</a></li>\n<li><a href=\"https://zhuanlan.zhihu.com/p/32230623\" target=\"_blank\" rel=\"noopener\">一个框架看懂优化算法之异同 SGD/AdaGrad/Adam - Juliuszh的文章 - 知乎</a></li>\n</ol>\n"},{"title":"Statistic","date":"2019-01-06T15:18:46.000Z","mathjax":true,"_content":"\n### Beyes\n\n$$P(H|D) = \\frac{P(H) \\cdot P(D|H)}{P(D)}​$$\n\nH: hyposis 假设事件，D: data 数据\n\n- $P(H|D)$ : 后验概率, the probability of observing event H given that D is true\n- $P(H)​$ : 先验概率, the probability of observing event H\n- $P(D|H)$: 似然度　\n- $P(D)$ :   the probability of data D\n\n例：在判断垃圾邮件的算法中:\n  $P(H)​$ : 所有邮件中，垃圾邮件的概率。\n  $P(D)​$ : 出现某个单词的概率。\n  $P(D|H)​$ : 垃圾邮件中，出现某个单词的概率。\n  $P(H|D)​$ : 出现某个单词的邮件，是垃圾邮件的概率。\n\n\n\n\n\n","source":"_posts/statitics/Statistics.md","raw":"---\ntitle: Statistic\ndate: 2019-01-06 23:18:46\ntags:\nmathjax: true\n---\n\n### Beyes\n\n$$P(H|D) = \\frac{P(H) \\cdot P(D|H)}{P(D)}​$$\n\nH: hyposis 假设事件，D: data 数据\n\n- $P(H|D)$ : 后验概率, the probability of observing event H given that D is true\n- $P(H)​$ : 先验概率, the probability of observing event H\n- $P(D|H)$: 似然度　\n- $P(D)$ :   the probability of data D\n\n例：在判断垃圾邮件的算法中:\n  $P(H)​$ : 所有邮件中，垃圾邮件的概率。\n  $P(D)​$ : 出现某个单词的概率。\n  $P(D|H)​$ : 垃圾邮件中，出现某个单词的概率。\n  $P(H|D)​$ : 出现某个单词的邮件，是垃圾邮件的概率。\n\n\n\n\n\n","slug":"statitics/Statistics","published":1,"updated":"2019-04-29T14:43:59.497Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdarn001au09opgv8cvjo","content":"<h3 id=\"Beyes\"><a href=\"#Beyes\" class=\"headerlink\" title=\"Beyes\"></a>Beyes</h3><p>$$P(H|D) = \\frac{P(H) \\cdot P(D|H)}{P(D)}​$$</p>\n<p>H: hyposis 假设事件，D: data 数据</p>\n<ul>\n<li>$P(H|D)$ : 后验概率, the probability of observing event H given that D is true</li>\n<li>$P(H)​$ : 先验概率, the probability of observing event H</li>\n<li>$P(D|H)$: 似然度　</li>\n<li>$P(D)$ :   the probability of data D</li>\n</ul>\n<p>例：在判断垃圾邮件的算法中:<br>  $P(H)​$ : 所有邮件中，垃圾邮件的概率。<br>  $P(D)​$ : 出现某个单词的概率。<br>  $P(D|H)​$ : 垃圾邮件中，出现某个单词的概率。<br>  $P(H|D)​$ : 出现某个单词的邮件，是垃圾邮件的概率。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"Beyes\"><a href=\"#Beyes\" class=\"headerlink\" title=\"Beyes\"></a>Beyes</h3><p>$$P(H|D) = \\frac{P(H) \\cdot P(D|H)}{P(D)}​$$</p>\n<p>H: hyposis 假设事件，D: data 数据</p>\n<ul>\n<li>$P(H|D)$ : 后验概率, the probability of observing event H given that D is true</li>\n<li>$P(H)​$ : 先验概率, the probability of observing event H</li>\n<li>$P(D|H)$: 似然度　</li>\n<li>$P(D)$ :   the probability of data D</li>\n</ul>\n<p>例：在判断垃圾邮件的算法中:<br>  $P(H)​$ : 所有邮件中，垃圾邮件的概率。<br>  $P(D)​$ : 出现某个单词的概率。<br>  $P(D|H)​$ : 垃圾邮件中，出现某个单词的概率。<br>  $P(H|D)​$ : 出现某个单词的邮件，是垃圾邮件的概率。</p>\n"},{"_content":"重构：改善既有代码的设计\n------------------------------------\n\n## Chapter 1\n\n如果你要给程序添加一个特性，但发现代码因缺乏**良好的结构**而**不易于进行更改**，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。\n\n重构前，先检查自己是否有一套可靠的测试集。这些测试必须有自我检验能力。进行重构时，我需要依赖测试。我将测试视为bug检测器，它们能保护我不被自己犯的错误所困扰。通过测试对当前工作进行二次确认。\n\n**重构技术就是以微小的步伐修改程序。如果你犯下错误，很容易便可发现它。**\n\n傻瓜都能写出计算机可以理解的代码。唯有能写出**人类容易理解的代码**的，才是优秀的程序员。\n\n好代码的检验标准就是人们是否能轻而易举地修改它。小的步子可以更快前进，请保持代码永远处于可工作状态，小步修改累积起来也能大大改善系统的设计。\n\n## Chapter 2\n\n\n\n\n\n## Chapter 4 测试\n\n#### WHY\n\n- 编写代码的时间仅占所有时间中很少的一部分。有些时间用来决定下一步干什么，有些时间花在设计上，但是，**花费在调试上的时间是最多的**\n\n- 修复bug通常是比较快的，但**找出bug所在却是一场噩梦**。当修复一个bug时，常常会引起另一个bug，却在很久之后才会注意到它。那时，你又要花上大把时间去定位问题。\n\n- 一套测试就是一个强大的bug侦测器，能够大大缩减查找bug所需的时间\n- 除非体会到**编写测试是如何提升编程速度**，否则自测试似乎就没有什么意义\n- **编写未臻完善的测试**并经常运行，好过对完美测试的无尽等待。\n\n- **一个测试语句中最好只有一个验证语句**，否则测试可能在进行第一个验证时就失败，这通常会掩盖一些重要的错误信息，不利于你了解测试失败的原因。\n\n#### 错误，脏数据\n\n**直接 assert**\n\n如果这个错误会导致脏数据在应用中到处传递，或是产生一些很难调试的失败，我可能会用**引入断言**（302）手法，使代码不满足预设条件时快速失败。我不会为这样的失败断言添加测试，它们本身就是一种测试的形式。\n\n#### 探测边界条件\n\n- 目前为止我的测试都聚焦于正常的行为上，这通常也被称为“正常路径”（happy path），它指的是一切工作正常、用户使用方式也最符合规范的那种场景。同时，把测试推到这些条件的边界处也是不错的实践，这可以检查操作出错时软件的表现。\n- 考虑**可能出错的边界条件**，把测试火力集中在那儿。\n\n#### 你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\n\n- 不要因为测试无法捕捉所有的bug就不写测试，因为测试的确可以捕捉到大多数bug\n\n#### 单元测试\n\n负责测试一小块代码，运行速度足够快。它们是自测试代码的支柱，是一个系统中占绝大多数的测试类型\n\n#### 测试三问\n\n与编程的许多方面类似，测试也是一种**迭代**式的活动。除非你技能非常纯熟，或者非常幸运，否则你很难第一次就把测试写对。我发觉我持续地在测试集上工作，就与我在主代码库上的工作一样多。很自然，这意味着我在增加新特性时也要同时添加测试。\n\n有时还需要回顾已有的测试：它们足够清晰吗？我需要重构它们，以帮助我更好地理解吗？我拥有的测试是有价值的吗？\n\n代码足够清晰吗？我需要重构它们，以帮助我更好地理解吗？\n\n#### 什么时候应该添加测试\n\n每当你收到bug报告，请先写一个**单元测试来暴露这个bug**。\n\n","source":"_posts/coding/重构.md","raw":"重构：改善既有代码的设计\n------------------------------------\n\n## Chapter 1\n\n如果你要给程序添加一个特性，但发现代码因缺乏**良好的结构**而**不易于进行更改**，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。\n\n重构前，先检查自己是否有一套可靠的测试集。这些测试必须有自我检验能力。进行重构时，我需要依赖测试。我将测试视为bug检测器，它们能保护我不被自己犯的错误所困扰。通过测试对当前工作进行二次确认。\n\n**重构技术就是以微小的步伐修改程序。如果你犯下错误，很容易便可发现它。**\n\n傻瓜都能写出计算机可以理解的代码。唯有能写出**人类容易理解的代码**的，才是优秀的程序员。\n\n好代码的检验标准就是人们是否能轻而易举地修改它。小的步子可以更快前进，请保持代码永远处于可工作状态，小步修改累积起来也能大大改善系统的设计。\n\n## Chapter 2\n\n\n\n\n\n## Chapter 4 测试\n\n#### WHY\n\n- 编写代码的时间仅占所有时间中很少的一部分。有些时间用来决定下一步干什么，有些时间花在设计上，但是，**花费在调试上的时间是最多的**\n\n- 修复bug通常是比较快的，但**找出bug所在却是一场噩梦**。当修复一个bug时，常常会引起另一个bug，却在很久之后才会注意到它。那时，你又要花上大把时间去定位问题。\n\n- 一套测试就是一个强大的bug侦测器，能够大大缩减查找bug所需的时间\n- 除非体会到**编写测试是如何提升编程速度**，否则自测试似乎就没有什么意义\n- **编写未臻完善的测试**并经常运行，好过对完美测试的无尽等待。\n\n- **一个测试语句中最好只有一个验证语句**，否则测试可能在进行第一个验证时就失败，这通常会掩盖一些重要的错误信息，不利于你了解测试失败的原因。\n\n#### 错误，脏数据\n\n**直接 assert**\n\n如果这个错误会导致脏数据在应用中到处传递，或是产生一些很难调试的失败，我可能会用**引入断言**（302）手法，使代码不满足预设条件时快速失败。我不会为这样的失败断言添加测试，它们本身就是一种测试的形式。\n\n#### 探测边界条件\n\n- 目前为止我的测试都聚焦于正常的行为上，这通常也被称为“正常路径”（happy path），它指的是一切工作正常、用户使用方式也最符合规范的那种场景。同时，把测试推到这些条件的边界处也是不错的实践，这可以检查操作出错时软件的表现。\n- 考虑**可能出错的边界条件**，把测试火力集中在那儿。\n\n#### 你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\n\n- 不要因为测试无法捕捉所有的bug就不写测试，因为测试的确可以捕捉到大多数bug\n\n#### 单元测试\n\n负责测试一小块代码，运行速度足够快。它们是自测试代码的支柱，是一个系统中占绝大多数的测试类型\n\n#### 测试三问\n\n与编程的许多方面类似，测试也是一种**迭代**式的活动。除非你技能非常纯熟，或者非常幸运，否则你很难第一次就把测试写对。我发觉我持续地在测试集上工作，就与我在主代码库上的工作一样多。很自然，这意味着我在增加新特性时也要同时添加测试。\n\n有时还需要回顾已有的测试：它们足够清晰吗？我需要重构它们，以帮助我更好地理解吗？我拥有的测试是有价值的吗？\n\n代码足够清晰吗？我需要重构它们，以帮助我更好地理解吗？\n\n#### 什么时候应该添加测试\n\n每当你收到bug报告，请先写一个**单元测试来暴露这个bug**。\n\n","slug":"coding/重构","published":1,"date":"2019-07-02T15:27:40.333Z","updated":"2019-07-02T15:27:40.333Z","title":"","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdarn001cu09otwage026","content":"<h2 id=\"重构：改善既有代码的设计\"><a href=\"#重构：改善既有代码的设计\" class=\"headerlink\" title=\"重构：改善既有代码的设计\"></a>重构：改善既有代码的设计</h2><h2 id=\"Chapter-1\"><a href=\"#Chapter-1\" class=\"headerlink\" title=\"Chapter 1\"></a>Chapter 1</h2><p>如果你要给程序添加一个特性，但发现代码因缺乏<strong>良好的结构</strong>而<strong>不易于进行更改</strong>，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。</p>\n<p>重构前，先检查自己是否有一套可靠的测试集。这些测试必须有自我检验能力。进行重构时，我需要依赖测试。我将测试视为bug检测器，它们能保护我不被自己犯的错误所困扰。通过测试对当前工作进行二次确认。</p>\n<p><strong>重构技术就是以微小的步伐修改程序。如果你犯下错误，很容易便可发现它。</strong></p>\n<p>傻瓜都能写出计算机可以理解的代码。唯有能写出<strong>人类容易理解的代码</strong>的，才是优秀的程序员。</p>\n<p>好代码的检验标准就是人们是否能轻而易举地修改它。小的步子可以更快前进，请保持代码永远处于可工作状态，小步修改累积起来也能大大改善系统的设计。</p>\n<h2 id=\"Chapter-2\"><a href=\"#Chapter-2\" class=\"headerlink\" title=\"Chapter 2\"></a>Chapter 2</h2><h2 id=\"Chapter-4-测试\"><a href=\"#Chapter-4-测试\" class=\"headerlink\" title=\"Chapter 4 测试\"></a>Chapter 4 测试</h2><h4 id=\"WHY\"><a href=\"#WHY\" class=\"headerlink\" title=\"WHY\"></a>WHY</h4><ul>\n<li><p>编写代码的时间仅占所有时间中很少的一部分。有些时间用来决定下一步干什么，有些时间花在设计上，但是，<strong>花费在调试上的时间是最多的</strong></p>\n</li>\n<li><p>修复bug通常是比较快的，但<strong>找出bug所在却是一场噩梦</strong>。当修复一个bug时，常常会引起另一个bug，却在很久之后才会注意到它。那时，你又要花上大把时间去定位问题。</p>\n</li>\n<li><p>一套测试就是一个强大的bug侦测器，能够大大缩减查找bug所需的时间</p>\n</li>\n<li>除非体会到<strong>编写测试是如何提升编程速度</strong>，否则自测试似乎就没有什么意义</li>\n<li><p><strong>编写未臻完善的测试</strong>并经常运行，好过对完美测试的无尽等待。</p>\n</li>\n<li><p><strong>一个测试语句中最好只有一个验证语句</strong>，否则测试可能在进行第一个验证时就失败，这通常会掩盖一些重要的错误信息，不利于你了解测试失败的原因。</p>\n</li>\n</ul>\n<h4 id=\"错误，脏数据\"><a href=\"#错误，脏数据\" class=\"headerlink\" title=\"错误，脏数据\"></a>错误，脏数据</h4><p><strong>直接 assert</strong></p>\n<p>如果这个错误会导致脏数据在应用中到处传递，或是产生一些很难调试的失败，我可能会用<strong>引入断言</strong>（302）手法，使代码不满足预设条件时快速失败。我不会为这样的失败断言添加测试，它们本身就是一种测试的形式。</p>\n<h4 id=\"探测边界条件\"><a href=\"#探测边界条件\" class=\"headerlink\" title=\"探测边界条件\"></a>探测边界条件</h4><ul>\n<li>目前为止我的测试都聚焦于正常的行为上，这通常也被称为“正常路径”（happy path），它指的是一切工作正常、用户使用方式也最符合规范的那种场景。同时，把测试推到这些条件的边界处也是不错的实践，这可以检查操作出错时软件的表现。</li>\n<li>考虑<strong>可能出错的边界条件</strong>，把测试火力集中在那儿。</li>\n</ul>\n<h4 id=\"你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\"><a href=\"#你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\" class=\"headerlink\" title=\"你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\"></a>你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。</h4><ul>\n<li>不要因为测试无法捕捉所有的bug就不写测试，因为测试的确可以捕捉到大多数bug</li>\n</ul>\n<h4 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h4><p>负责测试一小块代码，运行速度足够快。它们是自测试代码的支柱，是一个系统中占绝大多数的测试类型</p>\n<h4 id=\"测试三问\"><a href=\"#测试三问\" class=\"headerlink\" title=\"测试三问\"></a>测试三问</h4><p>与编程的许多方面类似，测试也是一种<strong>迭代</strong>式的活动。除非你技能非常纯熟，或者非常幸运，否则你很难第一次就把测试写对。我发觉我持续地在测试集上工作，就与我在主代码库上的工作一样多。很自然，这意味着我在增加新特性时也要同时添加测试。</p>\n<p>有时还需要回顾已有的测试：它们足够清晰吗？我需要重构它们，以帮助我更好地理解吗？我拥有的测试是有价值的吗？</p>\n<p>代码足够清晰吗？我需要重构它们，以帮助我更好地理解吗？</p>\n<h4 id=\"什么时候应该添加测试\"><a href=\"#什么时候应该添加测试\" class=\"headerlink\" title=\"什么时候应该添加测试\"></a>什么时候应该添加测试</h4><p>每当你收到bug报告，请先写一个<strong>单元测试来暴露这个bug</strong>。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"重构：改善既有代码的设计\"><a href=\"#重构：改善既有代码的设计\" class=\"headerlink\" title=\"重构：改善既有代码的设计\"></a>重构：改善既有代码的设计</h2><h2 id=\"Chapter-1\"><a href=\"#Chapter-1\" class=\"headerlink\" title=\"Chapter 1\"></a>Chapter 1</h2><p>如果你要给程序添加一个特性，但发现代码因缺乏<strong>良好的结构</strong>而<strong>不易于进行更改</strong>，那就先重构那个程序，使其比较容易添加该特性，然后再添加该特性。</p>\n<p>重构前，先检查自己是否有一套可靠的测试集。这些测试必须有自我检验能力。进行重构时，我需要依赖测试。我将测试视为bug检测器，它们能保护我不被自己犯的错误所困扰。通过测试对当前工作进行二次确认。</p>\n<p><strong>重构技术就是以微小的步伐修改程序。如果你犯下错误，很容易便可发现它。</strong></p>\n<p>傻瓜都能写出计算机可以理解的代码。唯有能写出<strong>人类容易理解的代码</strong>的，才是优秀的程序员。</p>\n<p>好代码的检验标准就是人们是否能轻而易举地修改它。小的步子可以更快前进，请保持代码永远处于可工作状态，小步修改累积起来也能大大改善系统的设计。</p>\n<h2 id=\"Chapter-2\"><a href=\"#Chapter-2\" class=\"headerlink\" title=\"Chapter 2\"></a>Chapter 2</h2><h2 id=\"Chapter-4-测试\"><a href=\"#Chapter-4-测试\" class=\"headerlink\" title=\"Chapter 4 测试\"></a>Chapter 4 测试</h2><h4 id=\"WHY\"><a href=\"#WHY\" class=\"headerlink\" title=\"WHY\"></a>WHY</h4><ul>\n<li><p>编写代码的时间仅占所有时间中很少的一部分。有些时间用来决定下一步干什么，有些时间花在设计上，但是，<strong>花费在调试上的时间是最多的</strong></p>\n</li>\n<li><p>修复bug通常是比较快的，但<strong>找出bug所在却是一场噩梦</strong>。当修复一个bug时，常常会引起另一个bug，却在很久之后才会注意到它。那时，你又要花上大把时间去定位问题。</p>\n</li>\n<li><p>一套测试就是一个强大的bug侦测器，能够大大缩减查找bug所需的时间</p>\n</li>\n<li>除非体会到<strong>编写测试是如何提升编程速度</strong>，否则自测试似乎就没有什么意义</li>\n<li><p><strong>编写未臻完善的测试</strong>并经常运行，好过对完美测试的无尽等待。</p>\n</li>\n<li><p><strong>一个测试语句中最好只有一个验证语句</strong>，否则测试可能在进行第一个验证时就失败，这通常会掩盖一些重要的错误信息，不利于你了解测试失败的原因。</p>\n</li>\n</ul>\n<h4 id=\"错误，脏数据\"><a href=\"#错误，脏数据\" class=\"headerlink\" title=\"错误，脏数据\"></a>错误，脏数据</h4><p><strong>直接 assert</strong></p>\n<p>如果这个错误会导致脏数据在应用中到处传递，或是产生一些很难调试的失败，我可能会用<strong>引入断言</strong>（302）手法，使代码不满足预设条件时快速失败。我不会为这样的失败断言添加测试，它们本身就是一种测试的形式。</p>\n<h4 id=\"探测边界条件\"><a href=\"#探测边界条件\" class=\"headerlink\" title=\"探测边界条件\"></a>探测边界条件</h4><ul>\n<li>目前为止我的测试都聚焦于正常的行为上，这通常也被称为“正常路径”（happy path），它指的是一切工作正常、用户使用方式也最符合规范的那种场景。同时，把测试推到这些条件的边界处也是不错的实践，这可以检查操作出错时软件的表现。</li>\n<li>考虑<strong>可能出错的边界条件</strong>，把测试火力集中在那儿。</li>\n</ul>\n<h4 id=\"你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\"><a href=\"#你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\" class=\"headerlink\" title=\"你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。\"></a>你应该把测试集中在可能出错的地方。观察代码，看哪儿变得复杂；观察函数，思考哪些地方可能出错。</h4><ul>\n<li>不要因为测试无法捕捉所有的bug就不写测试，因为测试的确可以捕捉到大多数bug</li>\n</ul>\n<h4 id=\"单元测试\"><a href=\"#单元测试\" class=\"headerlink\" title=\"单元测试\"></a>单元测试</h4><p>负责测试一小块代码，运行速度足够快。它们是自测试代码的支柱，是一个系统中占绝大多数的测试类型</p>\n<h4 id=\"测试三问\"><a href=\"#测试三问\" class=\"headerlink\" title=\"测试三问\"></a>测试三问</h4><p>与编程的许多方面类似，测试也是一种<strong>迭代</strong>式的活动。除非你技能非常纯熟，或者非常幸运，否则你很难第一次就把测试写对。我发觉我持续地在测试集上工作，就与我在主代码库上的工作一样多。很自然，这意味着我在增加新特性时也要同时添加测试。</p>\n<p>有时还需要回顾已有的测试：它们足够清晰吗？我需要重构它们，以帮助我更好地理解吗？我拥有的测试是有价值的吗？</p>\n<p>代码足够清晰吗？我需要重构它们，以帮助我更好地理解吗？</p>\n<h4 id=\"什么时候应该添加测试\"><a href=\"#什么时候应该添加测试\" class=\"headerlink\" title=\"什么时候应该添加测试\"></a>什么时候应该添加测试</h4><p>每当你收到bug报告，请先写一个<strong>单元测试来暴露这个bug</strong>。</p>\n"},{"title":"Batch Normalization","date":"2019-06-18T16:00:00.000Z","mathjax":true,"_content":"\n\n\n## Batch Normalization\n\n批量归一化可以理解为在网络的每一层之前都做预处理，减少之前网络权重对数据的影响，保持每一层输出数据的分布（均值和标准差），使输出适应下一层网络，也使得每一层数据相对独立。\n\n![1560779540116](batch_normalization/1560779540116.png)\n\n## Internal Co-variate Shift\n\nReference: [Batch Normalization原理与实战](<https://zhuanlan.zhihu.com/p/34879333>)\n\n随着训练的进行，网络中的参数也随着梯度下降在不停更新。一方面，当底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；另一方面，参数的变化导致每一层的输入分布会发生改变，进而下一层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。\n\n原作定义：在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。\n\n随着梯度下降的进行，每一层的参数$W^{[l]}$与$b^{[l]}$都会被更新，那么$Z^{[l]}$的分布也就发生了改变，进而$A^{[l]}$也同样出现分布的改变。而$A^{[l]}$作为第 $l+1$ 层的输入，意味着 $l+1$ 层需要去不停适应这种数据分布的变化，这一过程叫做 Interval Covariate Shift.\n\n### 带来的问题：\n\n1. 上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低\n2. 网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（sigmoid, tanh）。 $Z^{[l]}$会逐渐更新并变大，陷入梯度饱和区。可以通过Normalization 使得激活函数输入分布在一个稳定的空间来避免他们陷入梯度饱和区。\n\n### 如何减缓 Interval Covariate Shift\n\n1. 白化。成本高，改变了网络每一层分布导致数据表达的特征信息丢失\n\n   - 使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1\n   - 去除特征之间的相关性\n\n2. Batch Normalization   简化加改进版的白化\n\n   - 简化。让每个特征都有均值为0，方差为1的分布就OK。\n   - 白化操作减弱了网络中每一层输入数据表达能力，那我就再加个线性变换操作，让这些数据再能够尽可能恢复本身的表达能力就好了。\n\n\n##　算法\n\n   ![1560779531173](batch_normalization/1560779531173.png)\n\nBN 引入了两个可学习的参数 $\\gamma$ 和 $\\beta$（**变换重构**）。这两个参数的引入是为了恢复数据本身的表达能力，对规范后的数据进行线性变换，即**$y_i = \\gamma \\hat{x_i} + \\beta_i$**。 特别的，当 $\\gamma^2=\\sigma ^2$（方差）, $\\beta = \\mu$ （均值）时，可以实现等价变换并且保留原始输入特征的分布信息。\n\n### Batch Normalization 的作用\n\n1. 使得网络中每层输入数据的分布相对稳定，加快模型学习速度\n\n2. 使得模型对参数不那么敏感，减小初始化参数对模型学习的影响，可以选择更大的初始化值，学习率选择范围更大\n\n   当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛。但是使用BN的网络将不会受到参数数值大小的影响。BN抑制了参数微小变化随着网络层数加深被放大的问题，使得网络对参数大小的适应能力更强\n\n3. 缓解梯度消失的问题\n\n4. 正则化效果，mini-batch 的mean/variance 作为总体样本的抽样估计，引入随机噪声\n\n**BN通过将每一层网络的输入进行normalization，保证输入分布的均值与方差固定在一定范围内，减少了网络中的Internal Covariate Shift问题，并在一定程度上缓解了梯度消失，加速了模型收敛；并且BN使得网络对参数、激活函数更加具有鲁棒性，降低了神经网络模型训练和调参的复杂度；最后BN训练过程中由于使用mini-batch的mean/variance作为总体样本统计量估计，引入了随机噪声，在一定程度上对模型起到了正则化的效果。**\n\n### 前向传播\n\n```python\n\ndef batchnorm_forward(x, gamma, beta, bn_param):\n    \"\"\"\n    Forward pass for batch normalization.\n\n    running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n    running_var = momentum * running_var + (1 - momentum) * sample_var\n\n    Input:\n    - x: Data of shape (N, D)\n    - gamma: Scale parameter of shape (D,)\n    - beta: Shift paremeter of shape (D,)\n    - bn_param: Dictionary with the following keys:\n      - mode: 'train' or 'test'; required\n      - eps: Constant for numeric stability\n      - momentum: Constant for running mean / variance.\n      - running_mean: Array of shape (D,) giving running mean of features\n      - running_var Array of shape (D,) giving running variance of features\n\n    Returns a tuple of:\n    - out: of shape (N, D)\n    - cache: A tuple of values needed in the backward pass\n    \"\"\"\n    mode = bn_param['mode']\n    eps = bn_param.get('eps', 1e-5)\n    momentum = bn_param.get('momentum', 0.9)\n\n    N, D = x.shape\n    running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype))\n    running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype))\n\n    out, cache = None, None\n    if mode == 'train':\n        ##########################################\n        mu = np.mean(x, axis=0)\n        var = np.var(x, axis=0)\n        x_norm = (x - mu) / np.sqrt(var + eps)\n        out = gamma * x_norm + beta\n        ##########################################\n\n        cache = (x, mu, var, eps, x_norm, gamma, beta, out)\n        \n        running_mean = momentum * running_mean + (1 - momentum) * mu\n        running_var  = momentum * running_var  + (1 - momentum) * var\n    elif mode == 'test':\n        x_norm = (x - running_mean) / np.sqrt(running_var + eps)\n       \n    \t# 训练超参数 gamma/beta，重构数据分布\n    \tout = gamma * x_norm + beta\n    else:\n        raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n\n    # Store the updated running means back into bn_param\n    bn_param['running_mean'] = running_mean\n    bn_param['running_var'] = running_var\n\n    return out, cache\n```\n\n\n\n#### 反向传播指示图\n\n![BNcircuit](batch_normalization/BNcircuit-1561283729951.png)\n\n![1560779531173](batch_normalization/1560779531173.png)\n\n损失函数对$y_i$的梯度为 $\\frac{\\partial L}{\\partial y_i}$，由　$y_i = \\gamma \\hat{x_i} + \\beta$ 得到：\n\n$$\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i}$$\n\n$$\\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i} \\hat{x_i}​$$\n\n$$\\frac{\\partial L}{\\partial \\hat{x_i}} = \\frac{\\partial L}{\\partial y_i} \\gamma$$\n\n\n\n$$\\frac{\\partial L}{\\partial \\mu} = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\mu} +  \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial {\\sigma^2}}{\\partial \\mu}  \\\\  =  -\\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} (- \\frac{2}{N} \\sum_{i=1}^{N} (x_i-\\mu)) $$\n\n$$\\frac{\\partial L}{\\partial \\sigma^2} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\sigma^2} \\\\  = \\frac{\\partial L}{\\partial \\hat{x_i}} (-\\frac{1}{2} )({\\sigma^2+\\epsilon})^{-\\frac{3}{2}}$$\n\n$$\\frac{\\partial L}{\\partial x_i} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial {x_i}} +   \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial \\sigma^2}{\\partial {x_i}} + \\frac{\\partial L}{\\partial \\mu}\\frac{\\partial \\mu}{\\partial x_i} \\\\ = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} \\frac{2(x_i - \\mu)}{N}  + \\frac{\\partial L}{\\partial \\mu} \\frac{1}{N} $$\n\n```python\ndef batchnorm_backward_alt(dout, cache):\n    \"\"\"\n    Alternative backward pass for batch normalization.     \n    \"\"\"\n    (x, mu, var, eps, x_norm, gamma, beta, out) = cache\n    N,D = dout.shape\n    \n    dx_norm = dout * gamma\n    dgamma = np.sum(dout * x_norm, axis=0)\n    dbeta  = np.sum(dout, axis=0)\n\n    dvar = np.sum(dx_norm * (x - mu) * (-0.5) * np.power(var + eps, -3/2), axis=0)\n    dmu = -np.sum(dx_norm / np.sqrt(var + eps), axis=0) + dvar * (-2) * np.sum(x - mu, axis=0) / N\n    dx  =  dx_norm / np.sqrt(var + eps) + dvar * 2 * (x - mu) / N  + dmu / N     \n\n    return dx, dgamma, dbeta\n```\n\n\n\n\n\n分步计算损失函数梯度的方法参考 Reference 2\n\n\n\nRefereces:\n\n1. <https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm>\n2. <https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html>","source":"_posts/deep-learning/batch_normalization.md","raw":"---\ntitle: Batch Normalization\ndate: 2019-06-19\nmathjax: true\ncategories:\n  - dl\ntag:\n  - dl\n  - hexo-asset-image\n---\n\n\n\n## Batch Normalization\n\n批量归一化可以理解为在网络的每一层之前都做预处理，减少之前网络权重对数据的影响，保持每一层输出数据的分布（均值和标准差），使输出适应下一层网络，也使得每一层数据相对独立。\n\n![1560779540116](batch_normalization/1560779540116.png)\n\n## Internal Co-variate Shift\n\nReference: [Batch Normalization原理与实战](<https://zhuanlan.zhihu.com/p/34879333>)\n\n随着训练的进行，网络中的参数也随着梯度下降在不停更新。一方面，当底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；另一方面，参数的变化导致每一层的输入分布会发生改变，进而下一层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。\n\n原作定义：在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。\n\n随着梯度下降的进行，每一层的参数$W^{[l]}$与$b^{[l]}$都会被更新，那么$Z^{[l]}$的分布也就发生了改变，进而$A^{[l]}$也同样出现分布的改变。而$A^{[l]}$作为第 $l+1$ 层的输入，意味着 $l+1$ 层需要去不停适应这种数据分布的变化，这一过程叫做 Interval Covariate Shift.\n\n### 带来的问题：\n\n1. 上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低\n2. 网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（sigmoid, tanh）。 $Z^{[l]}$会逐渐更新并变大，陷入梯度饱和区。可以通过Normalization 使得激活函数输入分布在一个稳定的空间来避免他们陷入梯度饱和区。\n\n### 如何减缓 Interval Covariate Shift\n\n1. 白化。成本高，改变了网络每一层分布导致数据表达的特征信息丢失\n\n   - 使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1\n   - 去除特征之间的相关性\n\n2. Batch Normalization   简化加改进版的白化\n\n   - 简化。让每个特征都有均值为0，方差为1的分布就OK。\n   - 白化操作减弱了网络中每一层输入数据表达能力，那我就再加个线性变换操作，让这些数据再能够尽可能恢复本身的表达能力就好了。\n\n\n##　算法\n\n   ![1560779531173](batch_normalization/1560779531173.png)\n\nBN 引入了两个可学习的参数 $\\gamma$ 和 $\\beta$（**变换重构**）。这两个参数的引入是为了恢复数据本身的表达能力，对规范后的数据进行线性变换，即**$y_i = \\gamma \\hat{x_i} + \\beta_i$**。 特别的，当 $\\gamma^2=\\sigma ^2$（方差）, $\\beta = \\mu$ （均值）时，可以实现等价变换并且保留原始输入特征的分布信息。\n\n### Batch Normalization 的作用\n\n1. 使得网络中每层输入数据的分布相对稳定，加快模型学习速度\n\n2. 使得模型对参数不那么敏感，减小初始化参数对模型学习的影响，可以选择更大的初始化值，学习率选择范围更大\n\n   当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛。但是使用BN的网络将不会受到参数数值大小的影响。BN抑制了参数微小变化随着网络层数加深被放大的问题，使得网络对参数大小的适应能力更强\n\n3. 缓解梯度消失的问题\n\n4. 正则化效果，mini-batch 的mean/variance 作为总体样本的抽样估计，引入随机噪声\n\n**BN通过将每一层网络的输入进行normalization，保证输入分布的均值与方差固定在一定范围内，减少了网络中的Internal Covariate Shift问题，并在一定程度上缓解了梯度消失，加速了模型收敛；并且BN使得网络对参数、激活函数更加具有鲁棒性，降低了神经网络模型训练和调参的复杂度；最后BN训练过程中由于使用mini-batch的mean/variance作为总体样本统计量估计，引入了随机噪声，在一定程度上对模型起到了正则化的效果。**\n\n### 前向传播\n\n```python\n\ndef batchnorm_forward(x, gamma, beta, bn_param):\n    \"\"\"\n    Forward pass for batch normalization.\n\n    running_mean = momentum * running_mean + (1 - momentum) * sample_mean\n    running_var = momentum * running_var + (1 - momentum) * sample_var\n\n    Input:\n    - x: Data of shape (N, D)\n    - gamma: Scale parameter of shape (D,)\n    - beta: Shift paremeter of shape (D,)\n    - bn_param: Dictionary with the following keys:\n      - mode: 'train' or 'test'; required\n      - eps: Constant for numeric stability\n      - momentum: Constant for running mean / variance.\n      - running_mean: Array of shape (D,) giving running mean of features\n      - running_var Array of shape (D,) giving running variance of features\n\n    Returns a tuple of:\n    - out: of shape (N, D)\n    - cache: A tuple of values needed in the backward pass\n    \"\"\"\n    mode = bn_param['mode']\n    eps = bn_param.get('eps', 1e-5)\n    momentum = bn_param.get('momentum', 0.9)\n\n    N, D = x.shape\n    running_mean = bn_param.get('running_mean', np.zeros(D, dtype=x.dtype))\n    running_var = bn_param.get('running_var', np.zeros(D, dtype=x.dtype))\n\n    out, cache = None, None\n    if mode == 'train':\n        ##########################################\n        mu = np.mean(x, axis=0)\n        var = np.var(x, axis=0)\n        x_norm = (x - mu) / np.sqrt(var + eps)\n        out = gamma * x_norm + beta\n        ##########################################\n\n        cache = (x, mu, var, eps, x_norm, gamma, beta, out)\n        \n        running_mean = momentum * running_mean + (1 - momentum) * mu\n        running_var  = momentum * running_var  + (1 - momentum) * var\n    elif mode == 'test':\n        x_norm = (x - running_mean) / np.sqrt(running_var + eps)\n       \n    \t# 训练超参数 gamma/beta，重构数据分布\n    \tout = gamma * x_norm + beta\n    else:\n        raise ValueError('Invalid forward batchnorm mode \"%s\"' % mode)\n\n    # Store the updated running means back into bn_param\n    bn_param['running_mean'] = running_mean\n    bn_param['running_var'] = running_var\n\n    return out, cache\n```\n\n\n\n#### 反向传播指示图\n\n![BNcircuit](batch_normalization/BNcircuit-1561283729951.png)\n\n![1560779531173](batch_normalization/1560779531173.png)\n\n损失函数对$y_i$的梯度为 $\\frac{\\partial L}{\\partial y_i}$，由　$y_i = \\gamma \\hat{x_i} + \\beta$ 得到：\n\n$$\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i}$$\n\n$$\\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i} \\hat{x_i}​$$\n\n$$\\frac{\\partial L}{\\partial \\hat{x_i}} = \\frac{\\partial L}{\\partial y_i} \\gamma$$\n\n\n\n$$\\frac{\\partial L}{\\partial \\mu} = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\mu} +  \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial {\\sigma^2}}{\\partial \\mu}  \\\\  =  -\\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} (- \\frac{2}{N} \\sum_{i=1}^{N} (x_i-\\mu)) $$\n\n$$\\frac{\\partial L}{\\partial \\sigma^2} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\sigma^2} \\\\  = \\frac{\\partial L}{\\partial \\hat{x_i}} (-\\frac{1}{2} )({\\sigma^2+\\epsilon})^{-\\frac{3}{2}}$$\n\n$$\\frac{\\partial L}{\\partial x_i} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial {x_i}} +   \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial \\sigma^2}{\\partial {x_i}} + \\frac{\\partial L}{\\partial \\mu}\\frac{\\partial \\mu}{\\partial x_i} \\\\ = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} \\frac{2(x_i - \\mu)}{N}  + \\frac{\\partial L}{\\partial \\mu} \\frac{1}{N} $$\n\n```python\ndef batchnorm_backward_alt(dout, cache):\n    \"\"\"\n    Alternative backward pass for batch normalization.     \n    \"\"\"\n    (x, mu, var, eps, x_norm, gamma, beta, out) = cache\n    N,D = dout.shape\n    \n    dx_norm = dout * gamma\n    dgamma = np.sum(dout * x_norm, axis=0)\n    dbeta  = np.sum(dout, axis=0)\n\n    dvar = np.sum(dx_norm * (x - mu) * (-0.5) * np.power(var + eps, -3/2), axis=0)\n    dmu = -np.sum(dx_norm / np.sqrt(var + eps), axis=0) + dvar * (-2) * np.sum(x - mu, axis=0) / N\n    dx  =  dx_norm / np.sqrt(var + eps) + dvar * 2 * (x - mu) / N  + dmu / N     \n\n    return dx, dgamma, dbeta\n```\n\n\n\n\n\n分步计算损失函数梯度的方法参考 Reference 2\n\n\n\nRefereces:\n\n1. <https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm>\n2. <https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html>","slug":"deep-learning/batch_normalization","published":1,"updated":"2019-07-02T17:14:38.478Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjyegdasp001hu09onjxfgh70","content":"<h2 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h2><p>批量归一化可以理解为在网络的每一层之前都做预处理，减少之前网络权重对数据的影响，保持每一层输出数据的分布（均值和标准差），使输出适应下一层网络，也使得每一层数据相对独立。</p>\n<p><img src=\"/2019/06/19/deep-learning/batch_normalization/1560779540116.png\" alt=\"1560779540116\"></p>\n<h2 id=\"Internal-Co-variate-Shift\"><a href=\"#Internal-Co-variate-Shift\" class=\"headerlink\" title=\"Internal Co-variate Shift\"></a>Internal Co-variate Shift</h2><p>Reference: <a href=\"https://zhuanlan.zhihu.com/p/34879333\" target=\"_blank\" rel=\"noopener\">Batch Normalization原理与实战</a></p>\n<p>随着训练的进行，网络中的参数也随着梯度下降在不停更新。一方面，当底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；另一方面，参数的变化导致每一层的输入分布会发生改变，进而下一层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。</p>\n<p>原作定义：在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。</p>\n<p>随着梯度下降的进行，每一层的参数$W^{[l]}$与$b^{[l]}$都会被更新，那么$Z^{[l]}$的分布也就发生了改变，进而$A^{[l]}$也同样出现分布的改变。而$A^{[l]}$作为第 $l+1$ 层的输入，意味着 $l+1$ 层需要去不停适应这种数据分布的变化，这一过程叫做 Interval Covariate Shift.</p>\n<h3 id=\"带来的问题：\"><a href=\"#带来的问题：\" class=\"headerlink\" title=\"带来的问题：\"></a>带来的问题：</h3><ol>\n<li>上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低</li>\n<li>网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（sigmoid, tanh）。 $Z^{[l]}$会逐渐更新并变大，陷入梯度饱和区。可以通过Normalization 使得激活函数输入分布在一个稳定的空间来避免他们陷入梯度饱和区。</li>\n</ol>\n<h3 id=\"如何减缓-Interval-Covariate-Shift\"><a href=\"#如何减缓-Interval-Covariate-Shift\" class=\"headerlink\" title=\"如何减缓 Interval Covariate Shift\"></a>如何减缓 Interval Covariate Shift</h3><ol>\n<li><p>白化。成本高，改变了网络每一层分布导致数据表达的特征信息丢失</p>\n<ul>\n<li>使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1</li>\n<li>去除特征之间的相关性</li>\n</ul>\n</li>\n<li><p>Batch Normalization   简化加改进版的白化</p>\n<ul>\n<li>简化。让每个特征都有均值为0，方差为1的分布就OK。</li>\n<li>白化操作减弱了网络中每一层输入数据表达能力，那我就再加个线性变换操作，让这些数据再能够尽可能恢复本身的表达能力就好了。</li>\n</ul>\n</li>\n</ol>\n<p>##　算法</p>\n<p>   <img src=\"/2019/06/19/deep-learning/batch_normalization/1560779531173.png\" alt=\"1560779531173\"></p>\n<p>BN 引入了两个可学习的参数 $\\gamma$ 和 $\\beta$（<strong>变换重构</strong>）。这两个参数的引入是为了恢复数据本身的表达能力，对规范后的数据进行线性变换，即<strong>$y_i = \\gamma \\hat{x_i} + \\beta_i$</strong>。 特别的，当 $\\gamma^2=\\sigma ^2$（方差）, $\\beta = \\mu$ （均值）时，可以实现等价变换并且保留原始输入特征的分布信息。</p>\n<h3 id=\"Batch-Normalization-的作用\"><a href=\"#Batch-Normalization-的作用\" class=\"headerlink\" title=\"Batch Normalization 的作用\"></a>Batch Normalization 的作用</h3><ol>\n<li><p>使得网络中每层输入数据的分布相对稳定，加快模型学习速度</p>\n</li>\n<li><p>使得模型对参数不那么敏感，减小初始化参数对模型学习的影响，可以选择更大的初始化值，学习率选择范围更大</p>\n<p>当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛。但是使用BN的网络将不会受到参数数值大小的影响。BN抑制了参数微小变化随着网络层数加深被放大的问题，使得网络对参数大小的适应能力更强</p>\n</li>\n<li><p>缓解梯度消失的问题</p>\n</li>\n<li><p>正则化效果，mini-batch 的mean/variance 作为总体样本的抽样估计，引入随机噪声</p>\n</li>\n</ol>\n<p><strong>BN通过将每一层网络的输入进行normalization，保证输入分布的均值与方差固定在一定范围内，减少了网络中的Internal Covariate Shift问题，并在一定程度上缓解了梯度消失，加速了模型收敛；并且BN使得网络对参数、激活函数更加具有鲁棒性，降低了神经网络模型训练和调参的复杂度；最后BN训练过程中由于使用mini-batch的mean/variance作为总体样本统计量估计，引入了随机噪声，在一定程度上对模型起到了正则化的效果。</strong></p>\n<h3 id=\"前向传播\"><a href=\"#前向传播\" class=\"headerlink\" title=\"前向传播\"></a>前向传播</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">batchnorm_forward</span><span class=\"params\">(x, gamma, beta, bn_param)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Forward pass for batch normalization.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></span><br><span class=\"line\"><span class=\"string\">    running_var = momentum * running_var + (1 - momentum) * sample_var</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Input:</span></span><br><span class=\"line\"><span class=\"string\">    - x: Data of shape (N, D)</span></span><br><span class=\"line\"><span class=\"string\">    - gamma: Scale parameter of shape (D,)</span></span><br><span class=\"line\"><span class=\"string\">    - beta: Shift paremeter of shape (D,)</span></span><br><span class=\"line\"><span class=\"string\">    - bn_param: Dictionary with the following keys:</span></span><br><span class=\"line\"><span class=\"string\">      - mode: 'train' or 'test'; required</span></span><br><span class=\"line\"><span class=\"string\">      - eps: Constant for numeric stability</span></span><br><span class=\"line\"><span class=\"string\">      - momentum: Constant for running mean / variance.</span></span><br><span class=\"line\"><span class=\"string\">      - running_mean: Array of shape (D,) giving running mean of features</span></span><br><span class=\"line\"><span class=\"string\">      - running_var Array of shape (D,) giving running variance of features</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns a tuple of:</span></span><br><span class=\"line\"><span class=\"string\">    - out: of shape (N, D)</span></span><br><span class=\"line\"><span class=\"string\">    - cache: A tuple of values needed in the backward pass</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    mode = bn_param[<span class=\"string\">'mode'</span>]</span><br><span class=\"line\">    eps = bn_param.get(<span class=\"string\">'eps'</span>, <span class=\"number\">1e-5</span>)</span><br><span class=\"line\">    momentum = bn_param.get(<span class=\"string\">'momentum'</span>, <span class=\"number\">0.9</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    N, D = x.shape</span><br><span class=\"line\">    running_mean = bn_param.get(<span class=\"string\">'running_mean'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class=\"line\">    running_var = bn_param.get(<span class=\"string\">'running_var'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class=\"line\"></span><br><span class=\"line\">    out, cache = <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> mode == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">        <span class=\"comment\">##########################################</span></span><br><span class=\"line\">        mu = np.mean(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        var = np.var(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        x_norm = (x - mu) / np.sqrt(var + eps)</span><br><span class=\"line\">        out = gamma * x_norm + beta</span><br><span class=\"line\">        <span class=\"comment\">##########################################</span></span><br><span class=\"line\"></span><br><span class=\"line\">        cache = (x, mu, var, eps, x_norm, gamma, beta, out)</span><br><span class=\"line\">        </span><br><span class=\"line\">        running_mean = momentum * running_mean + (<span class=\"number\">1</span> - momentum) * mu</span><br><span class=\"line\">        running_var  = momentum * running_var  + (<span class=\"number\">1</span> - momentum) * var</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> mode == <span class=\"string\">'test'</span>:</span><br><span class=\"line\">        x_norm = (x - running_mean) / np.sqrt(running_var + eps)</span><br><span class=\"line\">       </span><br><span class=\"line\">    \t<span class=\"comment\"># 训练超参数 gamma/beta，重构数据分布</span></span><br><span class=\"line\">    \tout = gamma * x_norm + beta</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'Invalid forward batchnorm mode \"%s\"'</span> % mode)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Store the updated running means back into bn_param</span></span><br><span class=\"line\">    bn_param[<span class=\"string\">'running_mean'</span>] = running_mean</span><br><span class=\"line\">    bn_param[<span class=\"string\">'running_var'</span>] = running_var</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br></pre></td></tr></table></figure>\n<h4 id=\"反向传播指示图\"><a href=\"#反向传播指示图\" class=\"headerlink\" title=\"反向传播指示图\"></a>反向传播指示图</h4><p><img src=\"/2019/06/19/deep-learning/batch_normalization/BNcircuit-1561283729951.png\" alt=\"BNcircuit\"></p>\n<p><img src=\"/2019/06/19/deep-learning/batch_normalization/1560779531173.png\" alt=\"1560779531173\"></p>\n<p>损失函数对$y_i$的梯度为 $\\frac{\\partial L}{\\partial y_i}$，由　$y_i = \\gamma \\hat{x_i} + \\beta$ 得到：</p>\n<p>$$\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i}$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i} \\hat{x_i}​$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\hat{x_i}} = \\frac{\\partial L}{\\partial y_i} \\gamma$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\mu} = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\mu} +  \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial {\\sigma^2}}{\\partial \\mu}  \\  =  -\\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} (- \\frac{2}{N} \\sum_{i=1}^{N} (x_i-\\mu)) $$</p>\n<p>$$\\frac{\\partial L}{\\partial \\sigma^2} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\sigma^2} \\  = \\frac{\\partial L}{\\partial \\hat{x_i}} (-\\frac{1}{2} )({\\sigma^2+\\epsilon})^{-\\frac{3}{2}}$$</p>\n<p>$$\\frac{\\partial L}{\\partial x_i} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial {x_i}} +   \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial \\sigma^2}{\\partial {x_i}} + \\frac{\\partial L}{\\partial \\mu}\\frac{\\partial \\mu}{\\partial x_i} \\ = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} \\frac{2(x_i - \\mu)}{N}  + \\frac{\\partial L}{\\partial \\mu} \\frac{1}{N} $$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">batchnorm_backward_alt</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Alternative backward pass for batch normalization.     </span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    (x, mu, var, eps, x_norm, gamma, beta, out) = cache</span><br><span class=\"line\">    N,D = dout.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    dx_norm = dout * gamma</span><br><span class=\"line\">    dgamma = np.sum(dout * x_norm, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    dbeta  = np.sum(dout, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    dvar = np.sum(dx_norm * (x - mu) * (<span class=\"number\">-0.5</span>) * np.power(var + eps, <span class=\"number\">-3</span>/<span class=\"number\">2</span>), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    dmu = -np.sum(dx_norm / np.sqrt(var + eps), axis=<span class=\"number\">0</span>) + dvar * (<span class=\"number\">-2</span>) * np.sum(x - mu, axis=<span class=\"number\">0</span>) / N</span><br><span class=\"line\">    dx  =  dx_norm / np.sqrt(var + eps) + dvar * <span class=\"number\">2</span> * (x - mu) / N  + dmu / N     </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure>\n<p>分步计算损失函数梯度的方法参考 Reference 2</p>\n<p>Refereces:</p>\n<ol>\n<li><a href=\"https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm\" target=\"_blank\" rel=\"noopener\">https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm</a></li>\n<li><a href=\"https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\" target=\"_blank\" rel=\"noopener\">https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Batch-Normalization\"><a href=\"#Batch-Normalization\" class=\"headerlink\" title=\"Batch Normalization\"></a>Batch Normalization</h2><p>批量归一化可以理解为在网络的每一层之前都做预处理，减少之前网络权重对数据的影响，保持每一层输出数据的分布（均值和标准差），使输出适应下一层网络，也使得每一层数据相对独立。</p>\n<p><img src=\"/2019/06/19/deep-learning/batch_normalization/1560779540116.png\" alt=\"1560779540116\"></p>\n<h2 id=\"Internal-Co-variate-Shift\"><a href=\"#Internal-Co-variate-Shift\" class=\"headerlink\" title=\"Internal Co-variate Shift\"></a>Internal Co-variate Shift</h2><p>Reference: <a href=\"https://zhuanlan.zhihu.com/p/34879333\" target=\"_blank\" rel=\"noopener\">Batch Normalization原理与实战</a></p>\n<p>随着训练的进行，网络中的参数也随着梯度下降在不停更新。一方面，当底层网络中参数发生微弱变化时，由于每一层中的线性变换与非线性激活映射，这些微弱变化随着网络层数的加深而被放大（类似蝴蝶效应）；另一方面，参数的变化导致每一层的输入分布会发生改变，进而下一层的网络需要不停地去适应这些分布变化，使得我们的模型训练变得困难。上述这一现象叫做Internal Covariate Shift。</p>\n<p>原作定义：在深层网络训练的过程中，由于网络中参数变化而引起内部结点数据分布发生变化的这一过程被称作Internal Covariate Shift。</p>\n<p>随着梯度下降的进行，每一层的参数$W^{[l]}$与$b^{[l]}$都会被更新，那么$Z^{[l]}$的分布也就发生了改变，进而$A^{[l]}$也同样出现分布的改变。而$A^{[l]}$作为第 $l+1$ 层的输入，意味着 $l+1$ 层需要去不停适应这种数据分布的变化，这一过程叫做 Interval Covariate Shift.</p>\n<h3 id=\"带来的问题：\"><a href=\"#带来的问题：\" class=\"headerlink\" title=\"带来的问题：\"></a>带来的问题：</h3><ol>\n<li>上层网络需要不停调整来适应输入数据分布的变化，导致网络学习速度的降低</li>\n<li>网络的训练过程容易陷入梯度饱和区，减缓网络收敛速度（sigmoid, tanh）。 $Z^{[l]}$会逐渐更新并变大，陷入梯度饱和区。可以通过Normalization 使得激活函数输入分布在一个稳定的空间来避免他们陷入梯度饱和区。</li>\n</ol>\n<h3 id=\"如何减缓-Interval-Covariate-Shift\"><a href=\"#如何减缓-Interval-Covariate-Shift\" class=\"headerlink\" title=\"如何减缓 Interval Covariate Shift\"></a>如何减缓 Interval Covariate Shift</h3><ol>\n<li><p>白化。成本高，改变了网络每一层分布导致数据表达的特征信息丢失</p>\n<ul>\n<li>使得输入特征分布具有相同的均值与方差。其中PCA白化保证了所有特征分布均值为0，方差为1</li>\n<li>去除特征之间的相关性</li>\n</ul>\n</li>\n<li><p>Batch Normalization   简化加改进版的白化</p>\n<ul>\n<li>简化。让每个特征都有均值为0，方差为1的分布就OK。</li>\n<li>白化操作减弱了网络中每一层输入数据表达能力，那我就再加个线性变换操作，让这些数据再能够尽可能恢复本身的表达能力就好了。</li>\n</ul>\n</li>\n</ol>\n<p>##　算法</p>\n<p>   <img src=\"/2019/06/19/deep-learning/batch_normalization/1560779531173.png\" alt=\"1560779531173\"></p>\n<p>BN 引入了两个可学习的参数 $\\gamma$ 和 $\\beta$（<strong>变换重构</strong>）。这两个参数的引入是为了恢复数据本身的表达能力，对规范后的数据进行线性变换，即<strong>$y_i = \\gamma \\hat{x_i} + \\beta_i$</strong>。 特别的，当 $\\gamma^2=\\sigma ^2$（方差）, $\\beta = \\mu$ （均值）时，可以实现等价变换并且保留原始输入特征的分布信息。</p>\n<h3 id=\"Batch-Normalization-的作用\"><a href=\"#Batch-Normalization-的作用\" class=\"headerlink\" title=\"Batch Normalization 的作用\"></a>Batch Normalization 的作用</h3><ol>\n<li><p>使得网络中每层输入数据的分布相对稳定，加快模型学习速度</p>\n</li>\n<li><p>使得模型对参数不那么敏感，减小初始化参数对模型学习的影响，可以选择更大的初始化值，学习率选择范围更大</p>\n<p>当学习率设置太高时，会使得参数更新步伐过大，容易出现震荡和不收敛。但是使用BN的网络将不会受到参数数值大小的影响。BN抑制了参数微小变化随着网络层数加深被放大的问题，使得网络对参数大小的适应能力更强</p>\n</li>\n<li><p>缓解梯度消失的问题</p>\n</li>\n<li><p>正则化效果，mini-batch 的mean/variance 作为总体样本的抽样估计，引入随机噪声</p>\n</li>\n</ol>\n<p><strong>BN通过将每一层网络的输入进行normalization，保证输入分布的均值与方差固定在一定范围内，减少了网络中的Internal Covariate Shift问题，并在一定程度上缓解了梯度消失，加速了模型收敛；并且BN使得网络对参数、激活函数更加具有鲁棒性，降低了神经网络模型训练和调参的复杂度；最后BN训练过程中由于使用mini-batch的mean/variance作为总体样本统计量估计，引入了随机噪声，在一定程度上对模型起到了正则化的效果。</strong></p>\n<h3 id=\"前向传播\"><a href=\"#前向传播\" class=\"headerlink\" title=\"前向传播\"></a>前向传播</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">batchnorm_forward</span><span class=\"params\">(x, gamma, beta, bn_param)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Forward pass for batch normalization.</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    running_mean = momentum * running_mean + (1 - momentum) * sample_mean</span></span><br><span class=\"line\"><span class=\"string\">    running_var = momentum * running_var + (1 - momentum) * sample_var</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Input:</span></span><br><span class=\"line\"><span class=\"string\">    - x: Data of shape (N, D)</span></span><br><span class=\"line\"><span class=\"string\">    - gamma: Scale parameter of shape (D,)</span></span><br><span class=\"line\"><span class=\"string\">    - beta: Shift paremeter of shape (D,)</span></span><br><span class=\"line\"><span class=\"string\">    - bn_param: Dictionary with the following keys:</span></span><br><span class=\"line\"><span class=\"string\">      - mode: 'train' or 'test'; required</span></span><br><span class=\"line\"><span class=\"string\">      - eps: Constant for numeric stability</span></span><br><span class=\"line\"><span class=\"string\">      - momentum: Constant for running mean / variance.</span></span><br><span class=\"line\"><span class=\"string\">      - running_mean: Array of shape (D,) giving running mean of features</span></span><br><span class=\"line\"><span class=\"string\">      - running_var Array of shape (D,) giving running variance of features</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">    Returns a tuple of:</span></span><br><span class=\"line\"><span class=\"string\">    - out: of shape (N, D)</span></span><br><span class=\"line\"><span class=\"string\">    - cache: A tuple of values needed in the backward pass</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    mode = bn_param[<span class=\"string\">'mode'</span>]</span><br><span class=\"line\">    eps = bn_param.get(<span class=\"string\">'eps'</span>, <span class=\"number\">1e-5</span>)</span><br><span class=\"line\">    momentum = bn_param.get(<span class=\"string\">'momentum'</span>, <span class=\"number\">0.9</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    N, D = x.shape</span><br><span class=\"line\">    running_mean = bn_param.get(<span class=\"string\">'running_mean'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class=\"line\">    running_var = bn_param.get(<span class=\"string\">'running_var'</span>, np.zeros(D, dtype=x.dtype))</span><br><span class=\"line\"></span><br><span class=\"line\">    out, cache = <span class=\"keyword\">None</span>, <span class=\"keyword\">None</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> mode == <span class=\"string\">'train'</span>:</span><br><span class=\"line\">        <span class=\"comment\">##########################################</span></span><br><span class=\"line\">        mu = np.mean(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        var = np.var(x, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">        x_norm = (x - mu) / np.sqrt(var + eps)</span><br><span class=\"line\">        out = gamma * x_norm + beta</span><br><span class=\"line\">        <span class=\"comment\">##########################################</span></span><br><span class=\"line\"></span><br><span class=\"line\">        cache = (x, mu, var, eps, x_norm, gamma, beta, out)</span><br><span class=\"line\">        </span><br><span class=\"line\">        running_mean = momentum * running_mean + (<span class=\"number\">1</span> - momentum) * mu</span><br><span class=\"line\">        running_var  = momentum * running_var  + (<span class=\"number\">1</span> - momentum) * var</span><br><span class=\"line\">    <span class=\"keyword\">elif</span> mode == <span class=\"string\">'test'</span>:</span><br><span class=\"line\">        x_norm = (x - running_mean) / np.sqrt(running_var + eps)</span><br><span class=\"line\">       </span><br><span class=\"line\">    \t<span class=\"comment\"># 训练超参数 gamma/beta，重构数据分布</span></span><br><span class=\"line\">    \tout = gamma * x_norm + beta</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"keyword\">raise</span> ValueError(<span class=\"string\">'Invalid forward batchnorm mode \"%s\"'</span> % mode)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\"># Store the updated running means back into bn_param</span></span><br><span class=\"line\">    bn_param[<span class=\"string\">'running_mean'</span>] = running_mean</span><br><span class=\"line\">    bn_param[<span class=\"string\">'running_var'</span>] = running_var</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> out, cache</span><br></pre></td></tr></table></figure>\n<h4 id=\"反向传播指示图\"><a href=\"#反向传播指示图\" class=\"headerlink\" title=\"反向传播指示图\"></a>反向传播指示图</h4><p><img src=\"/2019/06/19/deep-learning/batch_normalization/BNcircuit-1561283729951.png\" alt=\"BNcircuit\"></p>\n<p><img src=\"/2019/06/19/deep-learning/batch_normalization/1560779531173.png\" alt=\"1560779531173\"></p>\n<p>损失函数对$y_i$的梯度为 $\\frac{\\partial L}{\\partial y_i}$，由　$y_i = \\gamma \\hat{x_i} + \\beta$ 得到：</p>\n<p>$$\\frac{\\partial L}{\\partial \\beta} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i}$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\gamma} = \\sum_{i=1}^{N} \\frac{\\partial L}{\\partial y_i} \\hat{x_i}​$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\hat{x_i}} = \\frac{\\partial L}{\\partial y_i} \\gamma$$</p>\n<p>$$\\frac{\\partial L}{\\partial \\mu} = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\mu} +  \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial {\\sigma^2}}{\\partial \\mu}  \\  =  -\\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} (- \\frac{2}{N} \\sum_{i=1}^{N} (x_i-\\mu)) $$</p>\n<p>$$\\frac{\\partial L}{\\partial \\sigma^2} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial \\sigma^2} \\  = \\frac{\\partial L}{\\partial \\hat{x_i}} (-\\frac{1}{2} )({\\sigma^2+\\epsilon})^{-\\frac{3}{2}}$$</p>\n<p>$$\\frac{\\partial L}{\\partial x_i} =  \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{\\partial \\hat{x_i}}{\\partial {x_i}} +   \\frac{\\partial L}{\\partial \\sigma^2} \\frac{\\partial \\sigma^2}{\\partial {x_i}} + \\frac{\\partial L}{\\partial \\mu}\\frac{\\partial \\mu}{\\partial x_i} \\ = \\frac{\\partial L}{\\partial \\hat{x_i}} \\frac{1}{\\sqrt{\\sigma^2 + \\epsilon}} + \\frac{\\partial L}{\\partial \\sigma^2} \\frac{2(x_i - \\mu)}{N}  + \\frac{\\partial L}{\\partial \\mu} \\frac{1}{N} $$</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">batchnorm_backward_alt</span><span class=\"params\">(dout, cache)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">    Alternative backward pass for batch normalization.     </span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    (x, mu, var, eps, x_norm, gamma, beta, out) = cache</span><br><span class=\"line\">    N,D = dout.shape</span><br><span class=\"line\">    </span><br><span class=\"line\">    dx_norm = dout * gamma</span><br><span class=\"line\">    dgamma = np.sum(dout * x_norm, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    dbeta  = np.sum(dout, axis=<span class=\"number\">0</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    dvar = np.sum(dx_norm * (x - mu) * (<span class=\"number\">-0.5</span>) * np.power(var + eps, <span class=\"number\">-3</span>/<span class=\"number\">2</span>), axis=<span class=\"number\">0</span>)</span><br><span class=\"line\">    dmu = -np.sum(dx_norm / np.sqrt(var + eps), axis=<span class=\"number\">0</span>) + dvar * (<span class=\"number\">-2</span>) * np.sum(x - mu, axis=<span class=\"number\">0</span>) / N</span><br><span class=\"line\">    dx  =  dx_norm / np.sqrt(var + eps) + dvar * <span class=\"number\">2</span> * (x - mu) / N  + dmu / N     </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> dx, dgamma, dbeta</span><br></pre></td></tr></table></figure>\n<p>分步计算损失函数梯度的方法参考 Reference 2</p>\n<p>Refereces:</p>\n<ol>\n<li><a href=\"https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm\" target=\"_blank\" rel=\"noopener\">https://www.adityaagrawal.net/blog/deep_learning/bprop_batch_norm</a></li>\n<li><a href=\"https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html\" target=\"_blank\" rel=\"noopener\">https://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html</a></li>\n</ol>\n"}],"PostAsset":[{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560779531173.png","slug":"1560779531173.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561034699845.png","slug":"1561034699845.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/ccb56c1fb267bc632d6d88459eb14ace_hd.png","slug":"ccb56c1fb267bc632d6d88459eb14ace_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/63fcf4cc655cb04f21a37e86aca333cf_hd.png","slug":"63fcf4cc655cb04f21a37e86aca333cf_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561186187105.png","slug":"1561186187105.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561185046719.png","slug":"1561185046719.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561185066736.png","slug":"1561185066736.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561186187105.png","slug":"1561186187105.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/LSTM3-chain.png","slug":"LSTM3-chain.png","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/back_propagation/1561185066736.png","slug":"1561185066736.png","post":"cjyegdapq0002u09o8q0bp9cn","modified":0,"renderable":0},{"_id":"source/_posts/statitics/entropy/1562775971102.png","slug":"1562775971102.png","post":"cjyegdaq1000cu09o0b5fsndl","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/cnn/641c8846abcb02d35938660cf96cef1b_hd.jpg","slug":"641c8846abcb02d35938660cf96cef1b_hd.jpg","post":"cjyegdapx0007u09oliz9chab","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/cnn/90af0bd67ba498239688c81fd61bbc66_hd.jpg","slug":"90af0bd67ba498239688c81fd61bbc66_hd.jpg","post":"cjyegdapx0007u09oliz9chab","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/cnn/dd62e1d75bda9b592dabb91627d68aa6_hd.jpg","slug":"dd62e1d75bda9b592dabb91627d68aa6_hd.jpg","post":"cjyegdapx0007u09oliz9chab","modified":0,"renderable":0},{"_id":"source/_posts/machine-learning/decision-tree/1548940093157.png","slug":"1548940093157.png","post":"cjyegdapx0008u09o63k4cdc4","modified":0,"renderable":0},{"_id":"source/_posts/machine-learning/decision-tree/1548940125578.png","slug":"1548940125578.png","post":"cjyegdapx0008u09o63k4cdc4","modified":0,"renderable":0},{"_id":"source/_posts/machine-learning/decision-tree/1548940132559.png","slug":"1548940132559.png","post":"cjyegdapx0008u09o63k4cdc4","modified":0,"renderable":0},{"_id":"source/_posts/machine-learning/decision-tree/feature-space.png","slug":"feature-space.png","post":"cjyegdapx0008u09o63k4cdc4","modified":0,"renderable":0},{"_id":"source/_posts/machine-learning/decision-tree/tree_basic.png","slug":"tree_basic.png","post":"cjyegdapx0008u09o63k4cdc4","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/1562068950392.png","slug":"1562068950392.png","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/2256672-3b20294694c3904b.png","slug":"2256672-3b20294694c3904b.png","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/lstm.png","slug":"lstm.png","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/v2-3884f344d71e92d70ec3c44d2795141f_hd.jpg","slug":"v2-3884f344d71e92d70ec3c44d2795141f_hd.jpg","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/v2-71652d6a1eee9def631c18ea5e3c7605_hd.jpg","slug":"v2-71652d6a1eee9def631c18ea5e3c7605_hd.jpg","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/rnn/v2-b0175ebd3419f9a11a3d0d8b00e28675_hd.jpg","slug":"v2-b0175ebd3419f9a11a3d0d8b00e28675_hd.jpg","post":"cjyegdapw0006u09oe0gc4rdy","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/03b3eccf18ee3760e219f9f95ec14305_hd.png","slug":"03b3eccf18ee3760e219f9f95ec14305_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560776135809.png","slug":"1560776135809.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560776449074.png","slug":"1560776449074.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1560779540116.png","slug":"1560779540116.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561035128653.png","slug":"1561035128653.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561035151992.png","slug":"1561035151992.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561037588255.png","slug":"1561037588255.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/1561186124221.png","slug":"1561186124221.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/3.1.1.5.png","slug":"3.1.1.5.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/42.png","slug":"42.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/677187e96671a4cac9c95352743b3806_hd.png","slug":"677187e96671a4cac9c95352743b3806_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/8608c06086fc196228f4dda78499a2d9_hd.png","slug":"8608c06086fc196228f4dda78499a2d9_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/aae11de6e6a29f50d46b9ea106fbb02a_hd.png","slug":"aae11de6e6a29f50d46b9ea106fbb02a_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/d0cbce2f2654b8e70fe201fec2982c7d_hd.png","slug":"d0cbce2f2654b8e70fe201fec2982c7d_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/e743b6777775b1671c3b5503d7afbbc4_hd.png","slug":"e743b6777775b1671c3b5503d7afbbc4_hd.png","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/nn_cs231n_note/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","slug":"v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","post":"cjyegdapt0003u09ot2248n1q","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/03b3eccf18ee3760e219f9f95ec14305_hd.png","slug":"03b3eccf18ee3760e219f9f95ec14305_hd.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561034699845.png","slug":"1561034699845.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561035128653.png","slug":"1561035128653.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561035151992.png","slug":"1561035151992.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561186124221.png","slug":"1561186124221.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561191915813.png","slug":"1561191915813.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/1561196522519.png","slug":"1561196522519.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/20160909001936276","slug":"20160909001936276","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/412afb713ddcff0ba9165ab026563304_hd.png","slug":"412afb713ddcff0ba9165ab026563304_hd.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/94dd0714f65ef94b3cbfff4780b1988d_hd.png","slug":"94dd0714f65ef94b3cbfff4780b1988d_hd.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/contours_evaluation_optimizers.gif","slug":"contours_evaluation_optimizers.gif","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/d8b52b9b9ca31e2132c436c39af2943c_hd.jpg","slug":"d8b52b9b9ca31e2132c436c39af2943c_hd.jpg","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/equation.svg","slug":"equation.svg","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/nesterov_update_vector.png","slug":"nesterov_update_vector.png","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/optimization/v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","slug":"v2-bcdf4fdd7d2f7a8784a2cfe098f14a8c_r-1561050312112.jpg","post":"cjyegdarm0018u09oy7tx6efx","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/batch_normalization/1560779531173.png","slug":"1560779531173.png","post":"cjyegdasp001hu09onjxfgh70","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/batch_normalization/1560779540116.png","slug":"1560779540116.png","post":"cjyegdasp001hu09onjxfgh70","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/batch_normalization/BNcircuit-1561283729951.png","slug":"BNcircuit-1561283729951.png","post":"cjyegdasp001hu09onjxfgh70","modified":0,"renderable":0},{"_id":"source/_posts/deep-learning/batch_normalization/alg1.png","slug":"alg1.png","post":"cjyegdasp001hu09onjxfgh70","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjyegdapx0007u09oliz9chab","category_id":"cjyegdapv0004u09oa0pgy0m2","_id":"cjyegdaq2000du09o2nb35oo3"},{"post_id":"cjyegdapq0002u09o8q0bp9cn","category_id":"cjyegdapv0004u09oa0pgy0m2","_id":"cjyegdaq2000gu09o6yhfm7ma"},{"post_id":"cjyegdapx0008u09o63k4cdc4","category_id":"cjyegdaq3000iu09ozc5ndmxv","_id":"cjyegdaq4000ru09ozeixxqhp"},{"post_id":"cjyegdarm0018u09oy7tx6efx","category_id":"cjyegdapv0004u09oa0pgy0m2","_id":"cjyegdaro001fu09ong5ti68f"},{"post_id":"cjyegdasp001hu09onjxfgh70","category_id":"cjyegdapv0004u09oa0pgy0m2","_id":"cjyegdass001ku09o0t40j61m"}],"PostTag":[{"post_id":"cjyegdapq0002u09o8q0bp9cn","tag_id":"cjyegdapw0005u09oj74f13je","_id":"cjyegdaq3000hu09on2q5bkk5"},{"post_id":"cjyegdapq0002u09o8q0bp9cn","tag_id":"cjyegdapy000au09oinueobl0","_id":"cjyegdaq3000ku09os5cowi76"},{"post_id":"cjyegdapx0007u09oliz9chab","tag_id":"cjyegdapw0005u09oj74f13je","_id":"cjyegdaq6000yu09ojuhbuyqx"},{"post_id":"cjyegdapx0007u09oliz9chab","tag_id":"cjyegdapy000au09oinueobl0","_id":"cjyegdaq6000zu09ok9xsyahd"},{"post_id":"cjyegdapx0008u09o63k4cdc4","tag_id":"cjyegdaq6000xu09o0zmg6j2i","_id":"cjyegdaq70012u09om202wy09"},{"post_id":"cjyegdapx0008u09o63k4cdc4","tag_id":"cjyegdapy000au09oinueobl0","_id":"cjyegdaq70013u09o4e6tmyke"},{"post_id":"cjyegdapz000bu09o5pbeavbz","tag_id":"cjyegdaq60011u09omj0h6t3j","_id":"cjyegdaq70015u09oyhiz8o74"},{"post_id":"cjyegdarm0018u09oy7tx6efx","tag_id":"cjyegdapw0005u09oj74f13je","_id":"cjyegdaro001eu09on7e7r6s9"},{"post_id":"cjyegdarm0018u09oy7tx6efx","tag_id":"cjyegdapy000au09oinueobl0","_id":"cjyegdarq001gu09omqmox07a"},{"post_id":"cjyegdasp001hu09onjxfgh70","tag_id":"cjyegdapw0005u09oj74f13je","_id":"cjyegdasq001iu09ovprwte98"},{"post_id":"cjyegdasp001hu09onjxfgh70","tag_id":"cjyegdapy000au09oinueobl0","_id":"cjyegdass001ju09o0qqufuyc"}],"Tag":[{"name":"dl","_id":"cjyegdapw0005u09oj74f13je"},{"name":"hexo-asset-image","_id":"cjyegdapy000au09oinueobl0"},{"name":"ml","_id":"cjyegdaq6000xu09o0zmg6j2i"},{"name":"statistics","_id":"cjyegdaq60011u09omj0h6t3j"},{"name":"math","_id":"cjyegdaq70014u09oj4oanci2"}]}}